My Langchain Crew 1/
    .env

Content of C:/AI PROJECT/My Langchain Crew 1\.env:
# API Keys
OPENAI_API_KEY=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
TAVILY_API_KEY=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

# Configuration overrides
TEAM_AGENTS_GENERAL__LOG_LEVEL=INFO
--------------------------------------------------------------------------------
    config.yaml

Content of C:/AI PROJECT/My Langchain Crew 1\config.yaml:
# Team Agents Configuration

# General settings
general:
  data_dir: "data"
  output_dir: "output"
  log_level: "INFO"
  verbose: true

# LLM settings
llm:
  default_model: "gpt-4o"
  research_model: "gpt-4o"
  planning_model: "gpt-4o"
  coordination_model: "gpt-4o"
  specialist_model: "gpt-4o"
  execution_model: "gpt-3.5-turbo"
  review_model: "gpt-4o"
  default_temperature: 0.2
  api_request_timeout: 30

# Agent factory settings
agent_factory:
  default_model: "gpt-4o"
  max_iterations: 10
  verbose: true

# Team manager settings
team_manager:
  analysis_model: "gpt-4o"
  agent_factory:
    default_model: "gpt-4o"

# Agent coordinator settings
agent_coordinator:
  coordination_model: "gpt-4o"
  max_coordination_retries: 3
  task_scheduler:
    max_parallel_tasks: 3
    prioritize_by_complexity: true

# Knowledge repository settings
knowledge_repository:
  data_dir: "data"
  embedding_model: "text-embedding-3-small"
  chunk_size: 1000
  chunk_overlap: 100

# Task scheduler settings
task_scheduler:
  max_parallel_tasks: 3
  prioritize_by_complexity: true

# Agents settings
agents:
  base_agent:
    max_retries: 3
    retry_delay: 2
    max_history: 10
  research_agent:
    auto_save_results: true
    max_search_results: 5
    include_sources: true
  specialist_agent:
    domain_knowledge: {}
    best_practices: []
  planner_agent:
    planning_depth: "medium"
    include_contingencies: true
  executor_agent:
    execution_timeout: 120
    validate_results: true
  reviewer_agent:
    review_criteria:
      - "correctness"
      - "completeness"
      - "efficiency"
      - "maintainability"

# Tools settings
tools:
  web_search:
    search_provider: "tavily"
    max_results: 5
  code_generation:
    language_support:
      - "python"
      - "javascript"
      - "java"
      - "csharp"
      - "apex"
  knowledge_retrieval:
    max_results: 5
    similarity_threshold: 0.7
  file_manager:
    allowed_extensions:
      - "txt"
      - "json"
      - "yaml"
      - "yml"
      - "csv"
      - "md"
      - "py"
      - "js"
      - "html"
    max_file_size: 10485760  # 10 MB
  communication:
    max_message_history: 100
    enable_agent_tagging: true
--------------------------------------------------------------------------------
    file_contents_log.txt

Content of C:/AI PROJECT/My Langchain Crew 1\file_contents_log.txt:
My Langchain Crew 1/
    .env

Content of C:/AI PROJECT/My Langchain Crew 1\.env:
# API Keys
OPENAI_API_KEY=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
TAVILY_API_KEY=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

# Configuration overrides
TEAM_AGENTS_GENERAL__LOG_LEVEL=INFO
--------------------------------------------------------------------------------
    config.yaml

Content of C:/AI PROJECT/My Langchain Crew 1\config.yaml:
# Team Agents Configuration

# General settings
general:
  data_dir: "data"
  output_dir: "output"
  log_level: "INFO"
  verbose: true

# LLM settings
llm:
  default_model: "gpt-4o"
  research_model: "gpt-4o"
  planning_model: "gpt-4o"
  coordination_model: "gpt-4o"
  specialist_model: "gpt-4o"
  execution_model: "gpt-3.5-turbo"
  review_model: "gpt-4o"
  default_temperature: 0.2
  api_request_timeout: 30

# Agent factory settings
agent_factory:
  default_model: "gpt-4o"
  max_iterations: 10
  verbose: true

# Team manager settings
team_manager:
  analysis_model: "gpt-4o"
  agent_factory:
    default_model: "gpt-4o"

# Agent coordinator settings
agent_coordinator:
  coordination_model: "gpt-4o"
  max_coordination_retries: 3
  task_scheduler:
    max_parallel_tasks: 3
    prioritize_by_complexity: true

# Knowledge repository settings
knowledge_repository:
  data_dir: "data"
  embedding_model: "text-embedding-3-small"
  chunk_size: 1000
  chunk_overlap: 100

# Task scheduler settings
task_scheduler:
  max_parallel_tasks: 3
  prioritize_by_complexity: true

# Agents settings
agents:
  base_agent:
    max_retries: 3
    retry_delay: 2
    max_history: 10
  research_agent:
    auto_save_results: true
    max_search_results: 5
    include_sources: true
  specialist_agent:
    domain_knowledge: {}
    best_practices: []
  planner_agent:
    planning_depth: "medium"
    include_contingencies: true
  executor_agent:
    execution_timeout: 120
    validate_results: true
  reviewer_agent:
    review_criteria:
      - "correctness"
      - "completeness"
      - "efficiency"
      - "maintainability"

# Tools settings
tools:
  web_search:
    search_provider: "tavily"
    max_results: 5
  code_generation:
    language_support:
      - "python"
      - "javascript"
      - "java"
      - "csharp"
      - "apex"
  knowledge_retrieval:
    max_results: 5
    similarity_threshold: 0.7
  file_manager:
    allowed_extensions:
      - "txt"
      - "json"
      - "yaml"
      - "yml"
      - "csv"
      - "md"
      - "py"
      - "js"
      - "html"
    max_file_size: 10485760  # 10 MB
  communication:
    max_message_history: 100
    enable_agent_tagging: true
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
    listfiles2.py

Content of C:/AI PROJECT/My Langchain Crew 1\listfiles2.py:
import os
def list_files_and_directories(startpath, log_file, excluded_dirs=None, max_size=10 * 1024 * 1024):
    """
    Liste les fichiers et répertoires à partir d'un chemin de départ et écrit leur contenu dans un fichier log.
    
    Args:
        startpath (str): Chemin de départ pour l'analyse
        log_file (str): Nom du fichier de log
        excluded_dirs (list): Liste des noms de répertoires à exclure de l'analyse
        max_size (int): Taille maximale du fichier de log (en octets)
    """
    # Si excluded_dirs n'est pas spécifié, initialiser une liste vide
    if excluded_dirs is None:
        excluded_dirs = []
    
    current_log_file = log_file
    file_count = 1
    
    # Ouvrir le premier fichier de log
    log = open(current_log_file, 'w', encoding='utf-8')
    
    try:
        for root, dirs, files in os.walk(startpath):
            # Filtrer les répertoires à exclure
            dirs[:] = [d for d in dirs if d not in excluded_dirs]
            
            level = root.replace(startpath, '').count(os.sep)
            indent = ' ' * 4 * level
            log.write(f"{indent}{os.path.basename(root)}/\n")
            subindent = ' ' * 4 * (level + 1)
            
            for f in files:
                    continue
                    
                file_path = os.path.join(root, f)
                log.write(f"{subindent}{f}\n")
                
                try:
                    # Vérifier si le fichier est trop grand pour être lu
                    file_size = os.path.getsize(file_path)
                    if file_size > max_size:
                        log.write(f"{subindent}Fichier trop volumineux pour être analysé ({file_size} octets)\n")
                        continue
                        
                    with open(file_path, 'r', encoding='utf-8') as file:
                        content = file.read()
                        if content.strip():  # Vérifie si le contenu n'est pas vide ou seulement des espaces
                            filtered_content = "\n".join(
                            )
                            if filtered_content.strip():  # Vérifie si le contenu filtré n'est pas vide
                                log.write(f"\nContent of {file_path}:\n")
                                log.write(filtered_content)
                                log.write("\n" + "-" * 80 + "\n")
                except Exception as e:
                    log.write(f"Error reading {file_path}: {e}\n")
                
                # Vérifie si le fichier de log dépasse la taille maximale
                log.flush()  # S'assurer que toutes les données sont écrites
                if os.path.getsize(current_log_file) > max_size:
                    # Fermer le fichier actuel avant de créer un nouveau
                    log.close()
                    
                    # Préparer le nom du nouveau fichier de log
                    file_parts = log_file.split('.')
                    if len(file_parts) > 1:
                        new_log_file = f"{file_parts[0]}_part{file_count+1}.{file_parts[1]}"
                    else:
                        new_log_file = f"{log_file}_part{file_count+1}"
                    
                    file_count += 1
                    current_log_file = new_log_file
                    
                    # Ouvrir le nouveau fichier de log
                    log = open(current_log_file, 'w', encoding='utf-8')
    finally:
        # S'assurer que le fichier est fermé correctement, même en cas d'erreur
        if not log.closed:
            log.close()

# Chemin de départ et fichier de log
startpath = "C:/AI PROJECT/My Langchain Crew 1"
log_file = "file_contents_log.txt"
# Liste des répertoires à exclure de l'analyse
excluded_dirs = [".git", "__pycache__", "venv", "node_modules", "books","vector_store"]
# Appel de la fonction pour lister les fichiers et dossiers et extraire les contenus
list_files_and_directories(startpath, log_file, excluded_dirs)
--------------------------------------------------------------------------------
    main.py

Content of C:/AI PROJECT/My Langchain Crew 1\main.py:
#!/usr/bin/env python3
"""
Main entry point for the Team Agents application.
This script handles user input and orchestrates the creation and execution of agent teams.
"""

import os
import argparse
import logging
from typing import Dict, Any, List, Optional
import patch_agents

from dotenv import load_dotenv

# Core components
from core.team_manager import TeamManager
from core.agent_coordinator import AgentCoordinator
from core.knowledge_repository import KnowledgeRepository

# Utils
from utils.config import Config
from utils.logging_utils import setup_logging


def parse_arguments():
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(description="Create and manage dynamic teams of AI agents.")
    parser.add_argument("task", type=str, nargs="?", help="The task description for the agent team")
    parser.add_argument("--config", type=str, default="config.yaml", help="Path to configuration file")
    parser.add_argument("--verbose", "-v", action="store_true", help="Enable verbose logging")
    parser.add_argument("--output", "-o", type=str, default="output", help="Output directory for generated files")
    parser.add_argument("--interactive", "-i", action="store_true", help="Run in interactive mode")
    parser.add_argument("--use-team", type=str, help="ID of an existing team to use")
    parser.add_argument("--list-teams", action="store_true", help="List all available teams")
    
    return parser.parse_args()


def initialize_system(config_path: str, verbose: bool = False) -> Dict[str, Any]:
    """
    Initialize the system components based on configuration.
    
    Args:
        config_path: Path to the configuration file
        verbose: Whether to enable verbose logging
    
    Returns:
        Dictionary containing initialized system components
    """
    # Load environment variables
    load_dotenv()
    
    # Setup logging
    log_level = logging.DEBUG if verbose else logging.INFO
    setup_logging(log_level)
    logger = logging.getLogger(__name__)
    logger.info("Initializing Team Agents system...")
    
    # Load configuration
    config = Config(config_path)
    logger.debug(f"Loaded configuration from {config_path}")
    
    # Create tools manually
    from langchain.tools.base import Tool
    tools = [
        Tool(
            name="empty_tool",
            description="A placeholder tool that does nothing",
            func=lambda x: "This tool does nothing"
        )
    ]
    
    # Initialize core components
    knowledge_repo = KnowledgeRepository(config.get("knowledge_repository", {}))
    
    # Modify the team_manager config to include tools
    team_manager_config = config.get("team_manager", {})
    if "agent_factory" not in team_manager_config:
        team_manager_config["agent_factory"] = {}
    
    # Add tools directly to agent_factory config
    team_manager_config["agent_factory"]["tools"] = tools
    
    team_manager = TeamManager(team_manager_config, knowledge_repo)
    agent_coordinator = AgentCoordinator(config.get("agent_coordinator", {}), knowledge_repo)
    
    return {
        "config": config,
        "knowledge_repository": knowledge_repo,
        "team_manager": team_manager,
        "agent_coordinator": agent_coordinator,
        "logger": logger
    }


def process_task(task: str, system_components: Dict[str, Any], team_id: Optional[str] = None) -> Dict[str, Any]:
    """
    Process a task by creating and executing an agent team.
    
    Args:
        task: The task description
        system_components: Dictionary containing system components
        team_id: Optional ID of an existing team to use
    
    Returns:
        Dictionary containing the results
    """
    logger = system_components["logger"]
    team_manager = system_components["team_manager"]
    agent_coordinator = system_components["agent_coordinator"]
    
    logger.info(f"Processing task: {task}")
    
    # Utiliser une équipe existante ou en créer une nouvelle
    if team_id:
        agent_team = team_manager.get_team(team_id)
        if not agent_team:
            logger.error(f"Team with ID {team_id} not found")
            return {"error": f"Team with ID {team_id} not found"}
        logger.info(f"Using existing team with ID {team_id}")
    else:
        # Analyze task and determine required team composition
        team_composition = team_manager.analyze_task(task)
        logger.info(f"Determined team composition: {', '.join([agent['role'] for agent in team_composition])}")
        
        # Create the team of agents
        agent_team = team_manager.create_team(team_composition)
        logger.info(f"Created agent team with {len(agent_team)} members")
    
    # Execute the task with the team
    results = agent_coordinator.execute_task(task, agent_team)
    logger.info("Task execution completed")
    
    return results


def interactive_mode(system_components: Dict[str, Any]) -> None:
    """
    Run the system in interactive mode, accepting user input continuously.
    
    Args:
        system_components: Dictionary containing system components
    """
    logger = system_components["logger"]
    logger.info("Starting interactive mode. Type 'exit' to quit.")
    
    while True:
        task = input("\nEnter your task (or 'exit' to quit): ")
        if task.lower() == 'exit':
            logger.info("Exiting interactive mode")
            break
            
        try:
            results = process_task(task, system_components)
            print("\n--- Results ---")
            print(results.get("summary", "No summary available"))
            
            # Display agent contributions if available
            if "agent_contributions" in results:
                print("\n--- Agent Contributions ---")
                for agent, contribution in results["agent_contributions"].items():
                    print(f"\n{agent}:")
                    print(contribution)
                    
            # Handle any output files
            if "output_files" in results and results["output_files"]:
                print("\n--- Generated Files ---")
                for file_path in results["output_files"]:
                    print(f"- {file_path}")
        
        except Exception as e:
            logger.error(f"Error processing task: {str(e)}")
            print(f"An error occurred: {str(e)}")


def list_available_teams(system_components: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    List all available teams in the knowledge repository.
    
    Args:
        system_components: Dictionary containing system components
    
    Returns:
        List of team information dictionaries
    """
    knowledge_repository = system_components["knowledge_repository"]
    
    # Filtrer uniquement les team_compositions
    teams = []
    recent_tasks = knowledge_repository.list_recent_tasks(limit=100)
    
    for task in recent_tasks:
        if task["type"] == "team_composition":
            team_id = task["task_id"]
            team_data = knowledge_repository.get_team_composition(team_id)
            
            if team_data:
                teams.append({
                    "id": team_id,
                    "name": team_data.get("team_name", "Unnamed Team"),
                    "description": team_data.get("team_goal", "No description"),
                    "created_at": team_data.get("timestamp", "Unknown"),
                    "agent_specs": team_data.get("agent_specs", [])
                })
    
    return teams


def main():
    """Main entry point for the application."""
    args = parse_arguments()
    
    # Initialize system components
    system_components = initialize_system(args.config, args.verbose)
    logger = system_components["logger"]
    
    # Create output directory if it doesn't exist
    if not os.path.exists(args.output):
        os.makedirs(args.output)
        logger.debug(f"Created output directory: {args.output}")
    
    # Set output directory in system components
    system_components["output_dir"] = args.output
    
    try:
        if args.list_teams:
            # Afficher toutes les équipes disponibles
            knowledge_repo = system_components["knowledge_repository"]
            teams = knowledge_repo.get_all_teams()
            
            if not teams:
                print("No teams found.")
                return
            
            print("\n--- Available Teams ---")
            for team_id, team in teams.items():
                print(f"ID: {team_id}")
                print(f"Name: {team['name']}")
                print(f"Description: {team['description']}")
                print(f"Created: {team['created_at']}")
                print(f"Agents: {len(team['agent_specs'])}")
                print("---")
            return

        if args.interactive:
            # Run in interactive mode
            interactive_mode(system_components)
        elif args.task:
            # Process a single task from command line
            if args.use_team:
                results = process_task(args.task, system_components, args.use_team)
            else:
                results = process_task(args.task, system_components)
            
            # Display results
            print("\n--- Results ---")
            print(results.get("summary", "No summary available"))
            
            if "output_files" in results and results["output_files"]:
                print("\n--- Generated Files ---")
                for file_path in results["output_files"]:
                    print(f"- {file_path}")
        else:
            # No task provided, show help
            print("No task provided. Use --interactive mode or provide a task description.")
            print("Example: python main.py 'Create a team of Salesforce developers'")
    
    except KeyboardInterrupt:
        logger.info("Operation interrupted by user")
        print("\nOperation cancelled by user")
    except Exception as e:
        logger.error(f"Unhandled exception: {str(e)}", exc_info=True)
        print(f"An error occurred: {str(e)}")
    
    logger.info("Application shutting down")


if __name__ == "__main__":
    main()
--------------------------------------------------------------------------------
    patch_agents.py

Content of C:/AI PROJECT/My Langchain Crew 1\patch_agents.py:
from langchain.tools.base import Tool

# Create a simple dummy tool
dummy_tool = Tool(
    name="dummy_tool",
    description="A dummy tool that does nothing",
    func=lambda x: "This tool does nothing"
)

# Create a list of tools
tools = [dummy_tool]

# Import the agent factory
from core.agent_factory import AgentFactory

# Save the original method
original_create_agent = AgentFactory.create_agent

# Define a patched version
def patched_create_agent(self, *args, **kwargs):
    # Add tools to kwargs
    if 'tools' not in kwargs:
        kwargs['tools'] = tools
    return original_create_agent(self, *args, **kwargs)

# Apply the patch
AgentFactory.create_agent = patched_create_agent

print("Agent factory patched successfully!")
--------------------------------------------------------------------------------
    readme.md

Content of C:/AI PROJECT/My Langchain Crew 1\readme.md:
# Team Agents System

A flexible framework for creating and managing dynamic teams of AI agents that collaborate to solve complex tasks.

## Overview

This system enables the creation of specialized AI agent teams that work together to accomplish tasks. The framework:

1. Analyzes a task to determine the required team composition
2. Assembles a team of specialized agents (researchers, planners, specialists, executors, reviewers)
3. Coordinates the agents' work to complete the task
4. Produces consolidated results and artifacts

## Directory Structure

```
team_agents/
├── agents/           # Agent implementations for different roles
├── core/             # Core system components
├── memory/           # Memory and persistence components
├── output/           # Generated outputs and artifacts
├── tools/            # Tools used by agents
├── utils/            # Utility functions and helpers
├── data/             # Persistent data storage
├── config.yaml       # System configuration
├── main.py           # Main entry point
└── README.md         # This file
```

## Setup Instructions

1. Clone this repository
2. Install dependencies:
   ```
   pip install -r requirements.txt
   ```
3. Create a `.env` file with your API keys:
   ```
   OPENAI_API_KEY=your_openai_api_key_here
   TAVILY_API_KEY=your_tavily_api_key_here
   ```
4. Run the setup script to create necessary directories:
   ```
   python create_directories.py
   ```

## Usage

You can use the system in two ways:

### 1. Command Line Interface

```
python main.py "Your task description here"
```

### 2. Interactive Mode

```
python main.py --interactive
```

### Example

Try running the example script:

```
python example_usage.py
```

## Configuration

The system is configured through `config.yaml`. You can modify this file to customize:

- Models used for different agent roles
- Task scheduling parameters
- Knowledge repository settings
- Tool configurations

## Extending the System

### Adding New Agent Types

Create a new agent class in the `agents/` directory that inherits from `BaseAgent`.

### Adding New Tools

Implement new tools in the `tools/` directory following the existing pattern.

## License

[Specify license information here]
--------------------------------------------------------------------------------
    README.TXT

Content of C:/AI PROJECT/My Langchain Crew 1\README.TXT:
# Plan d'application pour une équipe d'agents dynamique

Je vais vous proposer une structure d'application permettant de créer dynamiquement une équipe d'agents spécialisés en fonction des besoins spécifiés par l'utilisateur. Voici comment l'application pourrait être organisée pour répondre à votre exemple d'une "équipe de développeurs Salesforce".

## Architecture globale

L'architecture sera basée sur un système modularisé avec plusieurs composants qui interagissent entre eux:

### Structure des dossiers

```
team_agents/
├── core/
│   ├── __init__.py
│   ├── agent_factory.py
│   ├── agent_coordinator.py
│   ├── team_manager.py
│   ├── task_scheduler.py
│   └── knowledge_repository.py
├── agents/
│   ├── __init__.py
│   ├── base_agent.py
│   ├── research_agent.py
│   ├── specialist_agent.py
│   ├── planner_agent.py
│   ├── executor_agent.py
│   └── reviewer_agent.py
├── tools/
│   ├── __init__.py
│   ├── web_search.py
│   ├── code_generation.py
│   ├── knowledge_retrieval.py
│   ├── file_manager.py
│   └── communication.py
├── memory/
│   ├── __init__.py
│   ├── team_memory.py
│   ├── vector_store.py
│   └── conversation_history.py
├── utils/
│   ├── __init__.py
│   ├── prompt_templates.py
│   ├── config.py
│   └── logging_utils.py
├── main.py
├── requirements.txt
└── .env
```

## Fonctionnement général

### 1. Processus principal

L'application suivra un flux de travail en plusieurs étapes:

1. **Analyse de la demande utilisateur** - Un agent principal analyse la demande pour déterminer quels types d'experts sont nécessaires
2. **Constitution de l'équipe** - Création dynamique des agents spécialisés selon les besoins identifiés
3. **Collecte d'informations** - Les agents de recherche rassemblent les informations pertinentes
4. **Planification** - L'agent planificateur organise le travail et distribue les tâches
5. **Exécution** - Les agents spécialistes exécutent leurs tâches respectives
6. **Revue et intégration** - Les résultats sont vérifiés et consolidés
7. **Livraison** - Présentation des résultats à l'utilisateur

### 2. Description des composants clés

#### Fichiers principaux

1. **main.py**
   - Point d'entrée de l'application
   - Gère l'interface utilisateur et lance le processus de création de l'équipe
   - Exemple d'utilisation: `python main.py "j'aimerais une équipe de développeurs salesforce"`

#### Core

1. **agent_factory.py**
   - Responsable de la création des différents types d'agents
   - Utilise des modèles de LLM appropriés selon la spécialisation requise

2. **agent_coordinator.py**
   - Coordonne les interactions entre les agents
   - Gère le flux de travail et la communication inter-agents

3. **team_manager.py**
   - Gère la composition de l'équipe
   - Détermine quels experts sont nécessaires en fonction de la demande

4. **task_scheduler.py**
   - Organise les tâches et leur priorisation
   - Gère les dépendances entre les tâches

5. **knowledge_repository.py**
   - Centralise les connaissances collectées
   - Offre des méthodes d'accès et de mise à jour des informations

#### Agents

1. **base_agent.py**
   - Classe abstraite définissant les fonctionnalités communes à tous les agents
   - Implémente les méthodes de communication et d'accès aux outils

2. **research_agent.py**
   - Spécialisé dans la recherche d'informations
   - Utilise des outils de recherche web et de documentation

3. **specialist_agent.py**
   - Agent expert dans un domaine spécifique (Salesforce, développement, etc.)
   - Possède des connaissances spécialisées et des capacités adaptées

4. **planner_agent.py**
   - Conçoit le plan d'action global
   - Décompose le problème en tâches assignables

5. **executor_agent.py**
   - Exécute les tâches concrètes (génération de code, configuration, etc.)
   - Utilise des outils spécifiques selon la tâche

6. **reviewer_agent.py**
   - Vérifie la qualité du travail effectué
   - Suggère des améliorations et identifie les problèmes

#### Tools

1. **web_search.py**
   - Outil pour effectuer des recherches sur le web
   - Pourrait utiliser des API comme Tavily, Google Search, etc.

2. **code_generation.py**
   - Outil pour générer du code à partir de spécifications
   - Interface avec les modèles LLM pour la génération de code

3. **knowledge_retrieval.py**
   - Outil d'accès à la base de connaissances interne
   - Utilise RAG (Retrieval Augmented Generation) pour des réponses précises

4. **file_manager.py**
   - Outil pour gérer les fichiers (création, lecture, écriture)
   - Gère le système de fichiers pour les projets générés

5. **communication.py**
   - Outils pour la communication entre agents
   - Facilite l'échange d'informations structurées

#### Memory

1. **team_memory.py**
   - Gère la mémoire partagée de l'équipe
   - Stocke le contexte global du projet

2. **vector_store.py**
   - Implémente le stockage vectoriel pour la recherche sémantique
   - Utilise des embeddings pour stocker et récupérer les informations

3. **conversation_history.py**
   - Gère l'historique des conversations
   - Permet de maintenir le contexte à travers les interactions

#### Utils

1. **prompt_templates.py**
   - Contient les templates de prompts utilisés par les agents
   - Facilite la standardisation des communications avec les LLMs

2. **config.py**
   - Gère la configuration de l'application
   - Charge les variables d'environnement et les paramètres

3. **logging_utils.py**
   - Fonctions pour le logging et le suivi des opérations
   - Permet de déboguer et d'analyser le comportement du système

## Exemple de fonctionnement concret

Pour l'exemple "j'aimerais une équipe de développeurs salesforce":

1. L'utilisateur soumet sa demande via `main.py`
2. Le `team_manager.py` analyse la demande et détermine qu'il faut constituer une équipe avec:
   - Un expert Salesforce Admin
   - Un développeur Apex
   - Un spécialiste en intégration Salesforce
   - Un expert en UI/Lightning
   - Un testeur QA Salesforce

3. `agent_factory.py` crée ces agents spécialisés avec des prompts et des connaissances appropriés
4. Le `research_agent.py` collecte les informations récentes sur Salesforce, les meilleures pratiques, etc.
5. Le `planner_agent.py` élabore un plan d'action détaillé pour répondre au besoin
6. Les agents spécialistes exécutent leurs tâches respectives (création de code, configuration, etc.)
7. Le `reviewer_agent.py` vérifie la qualité et la cohérence des résultats
8. Le `agent_coordinator.py` assemble les résultats et les présente à l'utilisateur

## Technologies et dépendances 

- **LangChain** pour l'orchestration des agents et des chaînes
- **OpenAI GPT** pour les modèles de langage (via langchain_openai)
- **ChromaDB** pour le stockage vectoriel
- **Tavily** pour la recherche web
- **BeautifulSoup** pour le scraping web si nécessaire

Cette architecture est modulaire et extensible, permettant d'ajouter facilement de nouveaux types d'agents ou d'outils selon les besoins.

Voulez-vous que nous commencions par développer un fichier spécifique de cette architecture?
--------------------------------------------------------------------------------
    requirements.txt

Content of C:/AI PROJECT/My Langchain Crew 1\requirements.txt:
# Core dependencies
langchain>=0.1.4
langchain-openai>=0.0.4
langchain-community>=0.0.12
langchain-core>=0.1.14
openai>=1.3.0

# Utility libraries
python-dotenv>=1.0.0
pyyaml>=6.0
pydantic>=2.5.0

# Vector databases
chromadb>=0.4.18

# Tools dependencies
requests>=2.31.0
beautifulsoup4>=4.12.2
tavily-python>=0.2.6   # Optional, for web search

# Optional components
huggingface-hub>=0.19.4  # For alternative embeddings
sentence-transformers>=2.2.2  # For alternative embeddings

# Development and testing
pytest>=7.4.3
black>=23.11.0
--------------------------------------------------------------------------------
    agents/
        base_agent.py

Content of C:/AI PROJECT/My Langchain Crew 1\agents\base_agent.py:
"""
Base Agent Module

This module defines the BaseAgent class, which provides the foundation for all
specialized agents in the system. It encapsulates common functionality and interfaces
that all agents should implement.
"""

import logging
import time
from typing import Dict, Any, List, Optional, Union
from abc import ABC, abstractmethod

from langchain.agents import AgentExecutor
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage

from core.knowledge_repository import KnowledgeRepository

logger = logging.getLogger(__name__)

class BaseAgent(ABC):
    """
    Base class for all agent implementations in the system.
    
    This abstract class defines the interface and common functionality
    that all specialized agents should implement.
    """
    
    def __init__(
        self, 
        agent_executor: AgentExecutor,
        role: str,
        config: Dict[str, Any],
        knowledge_repository: Optional[KnowledgeRepository] = None
    ):
        """
        Initialize the base agent.
        
        Args:
            agent_executor: The LangChain agent executor
            role: The role of this agent (e.g., "researcher", "planner")
            config: Configuration dictionary with agent settings
            knowledge_repository: Optional knowledge repository for accessing shared information
        """
        self.agent_executor = agent_executor
        self.role = role
        self.config = config
        self.knowledge_repository = knowledge_repository
        self.max_retries = config.get("max_retries", 3)
        self.retry_delay = config.get("retry_delay", 2)
        self.execution_history = []
        
        logger.debug(f"Initialized BaseAgent with role: {role}")
    
    def execute_task(self, task_input: Union[str, Dict[str, Any]]) -> Dict[str, Any]:
        """
        Execute a task with this agent.
        
        Args:
            task_input: The task input, either a string or a dictionary
            
        Returns:
            Dictionary containing the execution results
        """
        # Convert string input to dictionary
        if isinstance(task_input, str):
            task_input = {"input": task_input}
        
        # Record start time
        start_time = time.time()
        
        # Get relevant knowledge if available
        context = self._get_relevant_context(task_input)
        if context:
            # Incorporate context into the input
            if "input" in task_input:
                task_input["input"] = self._format_input_with_context(task_input["input"], context)
        
        # Execute with retries
        result = self._execute_with_retries(task_input)
        
        # Record execution time
        execution_time = time.time() - start_time
        
        # Process the result
        processed_result = self._process_result(result)
        
        # Log execution
        self._log_execution(task_input, processed_result, execution_time)
        
        return processed_result
    
    def _execute_with_retries(self, task_input: Dict[str, Any]) -> Dict[str, Any]:
        """
        Execute a task with retries in case of failures.
        
        Args:
            task_input: The task input
            
        Returns:
            Execution result
        """
        attempts = 0
        last_error = None
        
        while attempts < self.max_retries:
            try:
                # Execute task
                result = self.agent_executor.invoke(task_input)
                return result
            
            except Exception as e:
                attempts += 1
                last_error = e
                logger.warning(f"Error executing task (attempt {attempts}/{self.max_retries}): {str(e)}")
                
                # Wait before retrying
                if attempts < self.max_retries:
                    time.sleep(self.retry_delay)
        
        # All retries failed
        logger.error(f"Task execution failed after {self.max_retries} attempts: {str(last_error)}")
        
        # Return error result
        return {
            "output": f"Error: {str(last_error)}",
            "error": str(last_error)
        }
    
    def _get_relevant_context(self, task_input: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Get relevant context for the task from the knowledge repository.
        
        Args:
            task_input: The task input
            
        Returns:
            List of relevant context items
        """
        if not self.knowledge_repository:
            return []
        
        try:
            # Extract the main input text
            input_text = task_input.get("input", "")
            
            # Get relevant knowledge
            relevant_items = self.knowledge_repository.get_relevant_knowledge(input_text, k=3)
            
            # Also get agent-specific knowledge
            agent_knowledge = self.knowledge_repository.get_agent_knowledge(self.role, k=2)
            
            # Combine and return
            return relevant_items + agent_knowledge
            
        except Exception as e:
            logger.error(f"Error retrieving context: {str(e)}")
            return []
    
    def _format_input_with_context(self, input_text: str, context: List[Dict[str, Any]]) -> str:
        """
        Format the input text with the relevant context.
        
        Args:
            input_text: The original input text
            context: List of context items
            
        Returns:
            Formatted input text with context
        """
        if not context:
            return input_text
        
        # Format context items
        context_text = []
        for item in context:
            content = item.get("content", "")
            metadata = item.get("metadata", {})
            source = metadata.get("source", "Unknown source")
            
            context_text.append(f"--- From {source} ---")
            context_text.append(content)
        
        # Combine with input
        formatted_input = [
            "Here is some relevant information that might help with this task:",
            "\n".join(context_text),
            "\nYour task:",
            input_text
        ]
        
        return "\n\n".join(formatted_input)
    
    def _process_result(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """
        Process the execution result.
        
        This method can be overridden by subclasses to perform specialized processing.
        
        Args:
            result: The raw execution result
            
        Returns:
            Processed result
        """
        # This base implementation just ensures standard fields are present
        processed = result.copy()
        
        # Ensure output field exists
        if "output" not in processed:
            if "return_values" in processed:
                processed["output"] = processed["return_values"]
            elif "response" in processed:
                processed["output"] = processed["response"]
            else:
                # Fallback to string representation
                processed["output"] = str(processed)
        
        # Add metadata
        if "metadata" not in processed:
            processed["metadata"] = {}
        
        processed["metadata"]["agent_role"] = self.role
        
        return processed
    
    def _log_execution(
        self, 
        task_input: Dict[str, Any], 
        result: Dict[str, Any], 
        execution_time: float
    ):
        """
        Log the execution details for record keeping.
        
        Args:
            task_input: The task input
            result: The execution result
            execution_time: Execution time in seconds
        """
        # Create execution record
        execution_record = {
            "timestamp": time.time(),
            "agent_role": self.role,
            "task_input": task_input,
            "result": result,
            "execution_time": execution_time
        }
        
        # Add to history
        self.execution_history.append(execution_record)
        
        # Limit history size
        max_history = self.config.get("max_history", 10)
        if len(self.execution_history) > max_history:
            self.execution_history = self.execution_history[-max_history:]
        
        logger.info(f"Agent {self.role} executed task in {execution_time:.2f} seconds")
    
    def get_execution_history(self) -> List[Dict[str, Any]]:
        """
        Get the execution history for this agent.
        
        Returns:
            List of execution records
        """
        return self.execution_history
    
    def clear_history(self):
        """Clear the execution history."""
        self.execution_history = []
        logger.debug(f"Cleared execution history for agent {self.role}")
    
    @abstractmethod
    def get_capabilities(self) -> List[str]:
        """
        Get the list of capabilities this agent has.
        
        This abstract method must be implemented by all subclasses.
        
        Returns:
            List of capability descriptions
        """
        pass
    
    def get_role_description(self) -> str:
        """
        Get a description of this agent's role.
        
        Returns:
            Description of the agent's role
        """
        # This can be overridden by subclasses for more specific descriptions
        return f"I am a {self.role} agent that can help with tasks related to this domain."
    
    def __str__(self) -> str:
        """String representation of the agent."""
        return f"{self.role} Agent"
    
    def __repr__(self) -> str:
        """Representation of the agent."""
        return f"<{self.__class__.__name__} role={self.role}>"
--------------------------------------------------------------------------------
        executor_agent.py

Content of C:/AI PROJECT/My Langchain Crew 1\agents\executor_agent.py:
"""
Executor Agent Module

This module implements the ExecutorAgent class, which specializes in executing
concrete tasks and implementing solutions based on plans and specifications provided
by other agents in the team.
"""

import logging
import os
import time
from typing import Dict, Any, List, Optional, Union
import json

from agents.base_agent import BaseAgent
from core.knowledge_repository import KnowledgeRepository

logger = logging.getLogger(__name__)

class ExecutorAgent(BaseAgent):
    """
    Agent specialized in execution and implementation of concrete tasks.
    
    This agent takes plans and specifications and turns them into actual
    implementations, including code generation, configurations, or other
    executable solutions.
    """
    
    def __init__(
        self, 
        agent_executor,
        role: str = "executor",
        config: Dict[str, Any] = None,
        knowledge_repository: Optional[KnowledgeRepository] = None
    ):
        """
        Initialize the executor agent.
        
        Args:
            agent_executor: The LangChain agent executor
            role: The specific role of this executor agent
            config: Configuration dictionary with agent settings
            knowledge_repository: Knowledge repository for accessing shared information
        """
        config = config or {}
        super().__init__(agent_executor, role, config, knowledge_repository)
        
        # Executor-specific configuration
        self.execution_timeout = config.get("execution_timeout", 120)
        self.validate_results = config.get("validate_results", True)
        self.output_dir = config.get("output_dir", "output")
        
        # Ensure output directory exists
        os.makedirs(self.output_dir, exist_ok=True)
        
        logger.debug(f"Initialized ExecutorAgent with role: {role}")
    
    def get_capabilities(self) -> List[str]:
        """
        Get the list of capabilities this agent has.
        
        Returns:
            List of capability descriptions
        """
        return [
            "Implementation of solutions from specifications",
            "Code generation and scripting",
            "System configuration and setup",
            "File and resource management",
            "Command execution and automation",
            "Integration between components",
            "Testing and validation"
        ]
    
    def execute_implementation(
        self, 
        specifications: Dict[str, Any], 
        context: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Execute a task based on provided specifications.
        
        Args:
            specifications: Detailed specifications for the implementation
            context: Optional additional context
            
        Returns:
            Dictionary containing implementation results
        """
        # Combine specifications and context into a prompt
        implementation_prompt = self._create_implementation_prompt(specifications, context)
        
        # Start the execution timer
        start_time = time.time()
        
        # Execute the implementation
        result = self.execute_task(implementation_prompt)
        
        # Calculate execution time
        execution_time = time.time() - start_time
        logger.info(f"Implementation executed in {execution_time:.2f} seconds")
        
        # Process the result and extract artifacts
        processed_result = self._process_implementation_result(result, specifications)
        
        # Validate the result if configured
        if self.validate_results:
            validation_result = self._validate_implementation(processed_result, specifications)
            processed_result["validation"] = validation_result
        
        return processed_result
    
    def _create_implementation_prompt(
        self, 
        specifications: Dict[str, Any], 
        context: Optional[str] = None
    ) -> str:
        """
        Create an implementation prompt based on specifications.
        
        Args:
            specifications: The specifications for the implementation
            context: Optional additional context
            
        Returns:
            Formatted implementation prompt
        """
        # Extract key information from specifications
        task_type = specifications.get("type", "general")
        description = specifications.get("description", "Implement the solution")
        requirements = specifications.get("requirements", [])
        deliverables = specifications.get("deliverables", [])
        constraints = specifications.get("constraints", [])
        
        # Build the prompt
        prompt_parts = [
            f"Task: {description}",
            "",
            "Implementation Specifications:"
        ]
        
        # Add requirements if any
        if requirements:
            prompt_parts.append("\nRequirements:")
            for i, req in enumerate(requirements, 1):
                prompt_parts.append(f"{i}. {req}")
        
        # Add deliverables if any
        if deliverables:
            prompt_parts.append("\nDeliverables:")
            for i, deliv in enumerate(deliverables, 1):
                prompt_parts.append(f"{i}. {deliv}")
        
        # Add constraints if any
        if constraints:
            prompt_parts.append("\nConstraints:")
            for i, constraint in enumerate(constraints, 1):
                prompt_parts.append(f"{i}. {constraint}")
        
        # Add additional context if provided
        if context:
            prompt_parts.append("\nAdditional Context:")
            prompt_parts.append(context)
        
        # Add task-specific instructions
        prompt_parts.append("\nImplementation Instructions:")
        
        if task_type == "code_generation":
            prompt_parts.append(
                "Please implement the code according to the specifications. "
                "Include clear comments, error handling, and follow best practices. "
                "Format your response with the actual code, followed by a brief explanation of how it works."
            )
        elif task_type == "configuration":
            prompt_parts.append(
                "Please provide the configuration settings and files according to the specifications. "
                "Include clear instructions on how to apply the configuration. "
                "Format your response with the configuration content, followed by implementation steps."
            )
        elif task_type == "documentation":
            prompt_parts.append(
                "Please create the documentation according to the specifications. "
                "Format your response as complete documentation ready for use."
            )
        else:
            prompt_parts.append(
                "Please implement the solution according to the specifications. "
                "Provide a complete and detailed implementation that can be directly used."
            )
        
        # Add format instructions for output
        prompt_parts.append("\nFormat your response as follows:")
        prompt_parts.append("1. Implementation: Your solution implementation")
        prompt_parts.append("2. Explanation: Brief explanation of how your implementation works")
        prompt_parts.append("3. Usage Instructions: How to use or apply your implementation")
        prompt_parts.append("4. Notes: Any important notes, assumptions, or limitations")
        
        if task_type == "code_generation":
            prompt_parts.append("\nFor code, use proper formatting with language-specific syntax highlighting.")
            
        # Combine all parts into the final prompt
        return "\n".join(prompt_parts)
    
    def _process_implementation_result(
        self, 
        result: Dict[str, Any], 
        specifications: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Process the implementation result and extract any artifacts.
        
        Args:
            result: Raw execution result
            specifications: Original specifications
            
        Returns:
            Processed result with extracted artifacts
        """
        output = result.get("output", "")
        task_type = specifications.get("type", "general")
        
        # Initialize processed result
        processed = {
            "implementation": "",
            "explanation": "",
            "usage_instructions": "",
            "notes": "",
            "artifacts": [],
            "original_output": output
        }
        
        # Try to extract sections from the output
        if "Implementation:" in output:
            parts = output.split("Implementation:", 1)
            if len(parts) > 1:
                implementation_text = parts[1].split("\n\n", 1)[0]
                if len(parts[1].split("\n\n")) > 1:
                    remaining = parts[1].split("\n\n", 1)[1]
                else:
                    remaining = ""
                processed["implementation"] = implementation_text.strip()
            else:
                remaining = output
        else:
            # If no explicit Implementation section, use the output until the first section header
            first_section = min(
                [output.find(s) for s in ["Explanation:", "Usage Instructions:", "Notes:"] if s in output] + [len(output)]
            )
            processed["implementation"] = output[:first_section].strip()
            remaining = output[first_section:]
        
        # Extract explanation
        if "Explanation:" in remaining:
            parts = remaining.split("Explanation:", 1)
            if len(parts) > 1:
                explanation_text = parts[1].split("\n\n", 1)[0]
                processed["explanation"] = explanation_text.strip()
                if len(parts[1].split("\n\n")) > 1:
                    remaining = parts[1].split("\n\n", 1)[1]
                else:
                    remaining = ""
        
        # Extract usage instructions
        if "Usage Instructions:" in remaining:
            parts = remaining.split("Usage Instructions:", 1)
            if len(parts) > 1:
                usage_text = parts[1].split("\n\n", 1)[0]
                processed["usage_instructions"] = usage_text.strip()
                if len(parts[1].split("\n\n")) > 1:
                    remaining = parts[1].split("\n\n", 1)[1]
                else:
                    remaining = ""
        
        # Extract notes
        if "Notes:" in remaining:
            parts = remaining.split("Notes:", 1)
            if len(parts) > 1:
                notes_text = parts[1].strip()
                processed["notes"] = notes_text
        
        # Extract code artifacts for code_generation tasks
        if task_type == "code_generation":
            artifacts = self._extract_code_artifacts(output, specifications)
            processed["artifacts"] = artifacts
            
            # Create files for the artifacts
            output_files = []
            for artifact in artifacts:
                file_path = self._save_artifact(artifact)
                if file_path:
                    output_files.append(file_path)
            
            processed["output_files"] = output_files
        
        return processed
    
    def _extract_code_artifacts(self, output: str, specifications: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Extract code artifacts from the output.
        
        Args:
            output: The raw output text
            specifications: The original specifications
            
        Returns:
            List of extracted code artifacts
        """
        artifacts = []
        
        # Look for code blocks in markdown format (```language...```)
        import re
        code_blocks = re.findall(r'```(\w+)?\n(.*?)\n```', output, re.DOTALL)
        
        # Process each code block
        for i, (language, code) in enumerate(code_blocks):
            language = language.strip() if language else "txt"
            
            # Determine filename
            language_to_extension = {
                "python": "py",
                "java": "java",
                "javascript": "js",
                "typescript": "ts",
                "html": "html",
                "css": "css",
                "json": "json",
                "xml": "xml",
                "yaml": "yaml",
                "sql": "sql",
                "bash": "sh",
                "shell": "sh",
                "apex": "cls",
                "visualforce": "page",
                "soql": "soql",
                "aura": "cmp",
                "lwc": "js"
            }
            
            # Get the extension for the language
            extension = language_to_extension.get(language.lower(), "txt")
            
            # Try to determine a meaningful filename
            filename = None
            
            # Look for class/function definitions or comments that might suggest a filename
            if language.lower() == "python":
                class_match = re.search(r'class\s+([A-Za-z0-9_]+)', code)
                if class_match:
                    filename = f"{class_match.group(1).lower()}.{extension}"
                else:
                    def_match = re.search(r'def\s+([A-Za-z0-9_]+)', code)
                    if def_match:
                        filename = f"{def_match.group(1).lower()}.{extension}"
            elif language.lower() in ["java", "apex"]:
                class_match = re.search(r'class\s+([A-Za-z0-9_]+)', code)
                if class_match:
                    filename = f"{class_match.group(1)}.{extension}"
            elif language.lower() in ["javascript", "typescript"]:
                class_match = re.search(r'class\s+([A-Za-z0-9_]+)', code)
                if class_match:
                    filename = f"{class_match.group(1)}.{extension}"
                else:
                    function_match = re.search(r'function\s+([A-Za-z0-9_]+)', code)
                    if function_match:
                        filename = f"{function_match.group(1)}.{extension}"
            
            # Fallback if no specific filename could be determined
            if not filename:
                filename = f"artifact_{i+1}.{extension}"
            
            # Create the artifact entry
            artifact = {
                "type": "code",
                "language": language,
                "content": code,
                "filename": filename
            }
            
            artifacts.append(artifact)
        
        # If no artifacts were found using markdown code blocks, try alternative approaches
        if not artifacts:
            # Try to find code sections based on indentation and context
            lines = output.split("\n")
            in_code_block = False
            current_language = None
            current_code = []
            
            for line in lines:
                # Check for language indicators
                if not in_code_block and ":" in line and any(lang in line.lower() for lang in ["code", "python", "java", "javascript", "html"]):
                    in_code_block = True
                    language_indicator = line.lower()
                    
                    if "python" in language_indicator:
                        current_language = "python"
                    elif "java" in language_indicator and "javascript" not in language_indicator:
                        current_language = "java"
                    elif "javascript" in language_indicator:
                        current_language = "javascript"
                    elif "html" in language_indicator:
                        current_language = "html"
                    elif "apex" in language_indicator:
                        current_language = "apex"
                    else:
                        current_language = "txt"
                    
                    continue
                
                # Check for end of code block
                if in_code_block and (not line.strip() or line.startswith("This code") or line.startswith("The code")):
                    if current_code:
                        extension = language_to_extension.get(current_language.lower(), "txt")
                        filename = f"extracted_code_{len(artifacts)+1}.{extension}"
                        
                        artifact = {
                            "type": "code",
                            "language": current_language,
                            "content": "\n".join(current_code),
                            "filename": filename
                        }
                        
                        artifacts.append(artifact)
                        
                        in_code_block = False
                        current_language = None
                        current_code = []
                    
                    continue
                
                # Add code lines
                if in_code_block:
                    current_code.append(line)
            
            # Add the last code block if there is one
            if in_code_block and current_code:
                extension = language_to_extension.get(current_language.lower(), "txt")
                filename = f"extracted_code_{len(artifacts)+1}.{extension}"
                
                artifact = {
                    "type": "code",
                    "language": current_language,
                    "content": "\n".join(current_code),
                    "filename": filename
                }
                
                artifacts.append(artifact)
        
        return artifacts
    
    def _save_artifact(self, artifact: Dict[str, Any]) -> Optional[str]:
        """
        Save an artifact to a file.
        
        Args:
            artifact: The artifact to save
            
        Returns:
            Path to the saved file or None if save failed
        """
        artifact_type = artifact.get("type")
        
        if artifact_type == "code":
            # Get artifact properties
            filename = artifact.get("filename", "artifact.txt")
            content = artifact.get("content", "")
            
            # Create full path
            file_path = os.path.join(self.output_dir, filename)
            
            try:
                # Create directory if needed
                os.makedirs(os.path.dirname(file_path), exist_ok=True)
                
                # Write content to file
                with open(file_path, "w", encoding="utf-8") as f:
                    f.write(content)
                
                logger.debug(f"Saved artifact to {file_path}")
                return file_path
                
            except Exception as e:
                logger.error(f"Error saving artifact to {file_path}: {str(e)}")
                return None
        
        return None
    
    def _validate_implementation(
        self, 
        processed_result: Dict[str, Any], 
        specifications: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Validate the implementation against specifications.
        
        Args:
            processed_result: The processed implementation result
            specifications: The original specifications
            
        Returns:
            Validation results
        """
        # For now, a simplified validation
        validation = {
            "passed": True,
            "issues": [],
            "suggestions": []
        }
        
        # Check for empty implementation
        if not processed_result.get("implementation"):
            validation["passed"] = False
            validation["issues"].append("Implementation is empty")
        
        # Check for missing artifacts in code_generation task
        if specifications.get("type") == "code_generation" and not processed_result.get("artifacts"):
            validation["passed"] = False
            validation["issues"].append("No code artifacts found in the implementation")
        
        # Check for missing usage instructions
        if not processed_result.get("usage_instructions"):
            validation["suggestions"].append("Usage instructions are missing or incomplete")
        
        # Task-specific validation
        task_type = specifications.get("type", "general")
        
        if task_type == "code_generation":
            # Check code artifacts for basic issues
            for artifact in processed_result.get("artifacts", []):
                code = artifact.get("content", "")
                language = artifact.get("language", "").lower()
                
                # Check for empty code
                if not code.strip():
                    validation["passed"] = False
                    validation["issues"].append(f"Empty code artifact: {artifact.get('filename')}")
                
                # Very basic syntax checks
                if language == "python":
                    if "import" not in code and "def " not in code and "class " not in code:
                        validation["suggestions"].append(f"Python code may be incomplete: {artifact.get('filename')}")
                elif language == "javascript":
                    if "function" not in code and "class" not in code and "const" not in code and "let" not in code:
                        validation["suggestions"].append(f"JavaScript code may be incomplete: {artifact.get('filename')}")
        
        return validation
    
    def generate_code(
        self, 
        code_specs: Dict[str, Any], 
        language: str = "python"
    ) -> Dict[str, Any]:
        """
        Generate code based on specifications.
        
        Args:
            code_specs: Specifications for the code to generate
            language: Programming language to use
            
        Returns:
            Dictionary containing the generated code and metadata
        """
        # Create specialized specifications for code generation
        specifications = {
            "type": "code_generation",
            "description": code_specs.get("description", "Generate code based on specifications"),
            "requirements": code_specs.get("requirements", []),
            "deliverables": code_specs.get("deliverables", []),
            "constraints": code_specs.get("constraints", []),
            "language": language
        }
        
        # Add language-specific context
        language_context = {
            "python": "Use Python 3.8+ features and best practices.",
            "javascript": "Use modern JavaScript (ES6+) features and best practices.",
            "java": "Use Java 11+ features and best practices.",
            "apex": "Follow Salesforce Apex best practices and governor limits."
        }.get(language.lower(), "")
        
        # Add specific language requirements
        if language.lower() == "python":
            specifications["constraints"].append("Follow PEP 8 style guidelines")
            specifications["constraints"].append("Include docstrings for all functions and classes")
        elif language.lower() == "javascript":
            specifications["constraints"].append("Use ES6+ syntax")
            specifications["constraints"].append("Add JSDoc comments for functions")
        elif language.lower() == "apex":
            specifications["constraints"].append("Consider Salesforce governor limits")
            specifications["constraints"].append("Include proper exception handling")
        
        # Execute the implementation with specialized context
        return self.execute_implementation(specifications, language_context)
    
    def configure_system(
        self, 
        config_specs: Dict[str, Any], 
        system_type: str = "general"
    ) -> Dict[str, Any]:
        """
        Generate configuration files or settings.
        
        Args:
            config_specs: Specifications for the configuration
            system_type: Type of system to configure
            
        Returns:
            Dictionary containing the configuration and metadata
        """
        # Create specialized specifications for configuration
        specifications = {
            "type": "configuration",
            "description": config_specs.get("description", "Create configuration based on specifications"),
            "requirements": config_specs.get("requirements", []),
            "deliverables": config_specs.get("deliverables", []),
            "constraints": config_specs.get("constraints", []),
            "system_type": system_type
        }
        
        # Add system-specific context
        system_context = {
            "salesforce": "Configure Salesforce-specific settings and metadata.",
            "web": "Configure web application settings.",
            "database": "Configure database settings and schema.",
            "network": "Configure network-related settings."
        }.get(system_type.lower(), "")
        
        # Execute the implementation with specialized context
        return self.execute_implementation(specifications, system_context)
    
    def create_documentation(
        self, 
        doc_specs: Dict[str, Any], 
        doc_type: str = "user_guide"
    ) -> Dict[str, Any]:
        """
        Create documentation based on specifications.
        
        Args:
            doc_specs: Specifications for the documentation
            doc_type: Type of documentation to create
            
        Returns:
            Dictionary containing the documentation and metadata
        """
        # Create specialized specifications for documentation
        specifications = {
            "type": "documentation",
            "description": doc_specs.get("description", "Create documentation based on specifications"),
            "requirements": doc_specs.get("requirements", []),
            "deliverables": doc_specs.get("deliverables", []),
            "constraints": doc_specs.get("constraints", []),
            "doc_type": doc_type
        }
        
        # Add documentation-specific context
        doc_context = {
            "user_guide": "Create user-facing documentation explaining how to use the system.",
            "api_reference": "Create technical API reference documentation.",
            "technical_spec": "Create a detailed technical specification document.",
            "installation_guide": "Create step-by-step installation instructions."
        }.get(doc_type.lower(), "")
        
        # Execute the implementation with specialized context
        return self.execute_implementation(specifications, doc_context)
    
    def get_role_description(self) -> str:
        """
        Get a description of this agent's role.
        
        Returns:
            Description of the agent's role
        """
        return (
            f"I am a {self.role} agent specializing in implementing solutions and executing tasks. "
            f"I can generate code, create configurations, implement designs, and produce working "
            f"artifacts based on specifications. I focus on turning plans and requirements into "
            f"concrete, functional implementations."
        )
--------------------------------------------------------------------------------
        planner_agent.py

Content of C:/AI PROJECT/My Langchain Crew 1\agents\planner_agent.py:
"""
Planner Agent Module

This module implements the PlannerAgent class, which specializes in strategic 
planning, task decomposition, and creating structured execution plans for the team.
"""

import logging
import json
from typing import Dict, Any, List, Optional, Union

from agents.base_agent import BaseAgent
from core.knowledge_repository import KnowledgeRepository

logger = logging.getLogger(__name__)

class PlannerAgent(BaseAgent):
    """
    Agent specialized in strategic planning and task decomposition.
    
    This agent analyzes complex tasks, breaks them down into manageable subtasks,
    identifies dependencies, and creates structured plans for execution by the team.
    """
    
    def __init__(
        self, 
        agent_executor,
        role: str = "planner",
        config: Dict[str, Any] = None,
        knowledge_repository: Optional[KnowledgeRepository] = None
    ):
        """
        Initialize the planner agent.
        
        Args:
            agent_executor: The LangChain agent executor
            role: The specific role of this planner agent
            config: Configuration dictionary with agent settings
            knowledge_repository: Knowledge repository for accessing shared information
        """
        config = config or {}
        super().__init__(agent_executor, role, config, knowledge_repository)
        
        # Planner-specific configuration
        self.planning_depth = config.get("planning_depth", "medium")
        self.include_contingencies = config.get("include_contingencies", True)
        self.max_subtasks = config.get("max_subtasks", 10)
        
        logger.debug(f"Initialized PlannerAgent with role: {role}, planning depth: {self.planning_depth}")
    
    def get_capabilities(self) -> List[str]:
        """
        Get the list of capabilities this agent has.
        
        Returns:
            List of capability descriptions
        """
        return [
            "Task decomposition and breakdown",
            "Dependency identification between subtasks",
            "Resource allocation planning",
            "Timeline and milestone creation",
            "Risk assessment and contingency planning",
            "Critical path analysis"
        ]
    
    def create_plan(self, task_description: str, team_composition: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        Create a comprehensive execution plan for a given task.
        
        Args:
            task_description: Description of the task to plan
            team_composition: Optional information about the available team members
            
        Returns:
            Dictionary containing the structured plan
        """
        # Construct a detailed planning prompt
        planning_prompt = self._create_planning_prompt(task_description, team_composition)
        
        # Execute the planning task
        result = self.execute_task(planning_prompt)
        
        # Extract and structure the plan
        structured_plan = self._structure_plan(result, task_description)
        
        return structured_plan
    
    def _create_planning_prompt(self, task_description: str, team_composition: Dict[str, Any] = None) -> str:
        """
        Create a detailed planning prompt for the given task.
        
        Args:
            task_description: Description of the task to plan
            team_composition: Optional information about the available team members
            
        Returns:
            Formatted planning prompt
        """
        # Adjust depth instructions based on configuration
        depth_instructions = {
            "light": "Create a high-level plan with major phases and key deliverables.",
            "medium": "Create a balanced plan with main phases broken down into specific tasks, key dependencies, and estimated complexity.",
            "detailed": "Create a comprehensive plan with detailed task breakdowns, specific assignments, clear dependencies, contingencies, and precise complexity estimates."
        }
        
        depth_instruction = depth_instructions.get(self.planning_depth, depth_instructions["medium"])
        
        # Start building the prompt
        prompt_parts = [
            f"Task Description: {task_description}",
            "",
            f"{depth_instruction}",
            "",
            "Please structure your plan as follows:",
            "1. Project Overview: Brief summary of the task and approach",
            "2. Goals & Deliverables: Clear list of what will be produced",
            "3. Task Breakdown: Detailed breakdown of work items"
        ]
        
        # Add team-specific instructions if team composition is provided
        if team_composition:
            prompt_parts.append("4. Team Assignments: Mapping of tasks to team members")
            prompt_parts.append("5. Dependencies: Relationships and dependencies between tasks")
            
            # Add information about available team members
            prompt_parts.append("\nAvailable Team Members:")
            for member_id, member_info in team_composition.items():
                member_role = member_info.get("role", "Unknown role")
                prompt_parts.append(f"- {member_id}: {member_role}")
        else:
            prompt_parts.append("4. Dependencies: Relationships and dependencies between tasks")
        
        # Add timeline and risk assessment
        prompt_parts.append("5. Timeline & Milestones: Key checkpoints and estimated durations")
        
        if self.include_contingencies:
            prompt_parts.append("6. Risk Assessment: Potential issues and contingency plans")
        
        # Add formatting instructions
        prompt_parts.append("\nFor the Task Breakdown section, format each task as a JSON object with:")
        prompt_parts.append("- id: A unique identifier for the task")
        prompt_parts.append("- description: Clear description of what needs to be done")
        prompt_parts.append("- estimated_complexity: Low, Medium, or High")
        prompt_parts.append("- dependencies: List of task IDs that must be completed first")
        
        if team_composition:
            prompt_parts.append("- assigned_to: ID of the team member best suited for this task")
        
        prompt_parts.append("\nReturn the Task Breakdown as a valid JSON array.")
        
        return "\n".join(prompt_parts)
    
    def _structure_plan(self, result: Dict[str, Any], task_description: str) -> Dict[str, Any]:
        """
        Structure the raw planning result into a consistent format.
        
        Args:
            result: Raw execution result
            task_description: Original task description
            
        Returns:
            Structured execution plan
        """
        output = result.get("output", "")
        
        # Initialize the structured plan
        structured_plan = {
            "task_description": task_description,
            "project_overview": "",
            "goals_deliverables": [],
            "tasks": [],
            "dependencies": [],
            "timeline_milestones": [],
            "risk_assessment": []
        }
        
        # Extract project overview
        if "Project Overview:" in output:
            parts = output.split("Project Overview:", 1)
            if len(parts) > 1:
                overview_text = parts[1].split("\n\n", 1)[0].strip()
                structured_plan["project_overview"] = overview_text
        
        # Extract goals and deliverables
        if "Goals & Deliverables:" in output:
            parts = output.split("Goals & Deliverables:", 1)
            if len(parts) > 1:
                deliverables_text = parts[1].split("\n\n", 1)[0].strip()
                # Split by lines and clean up
                deliverables = [d.strip() for d in deliverables_text.split("\n") if d.strip()]
                # Remove bullet points or numbering
                deliverables = [d[2:].strip() if d.startswith('- ') else 
                               d[d.find('.')+1:].strip() if d[0].isdigit() and '.' in d[:3] else 
                               d for d in deliverables]
                structured_plan["goals_deliverables"] = deliverables
        
        # Try to extract JSON task breakdown
        try:
            # Look for JSON array in the text
            import re
            json_match = re.search(r'\[\s*\{.*\}\s*\]', output, re.DOTALL)
            if json_match:
                json_content = json_match.group(0)
                tasks = json.loads(json_content)
                structured_plan["tasks"] = tasks
            else:
                # Fallback: Extract task breakdown manually
                if "Task Breakdown:" in output:
                    parts = output.split("Task Breakdown:", 1)
                    if len(parts) > 1:
                        tasks_text = parts[1].split("\n\n", 1)[0].strip()
                        # Parse tasks manually (simplified)
                        tasks = self._parse_tasks_manually(tasks_text)
                        structured_plan["tasks"] = tasks
        except Exception as e:
            logger.error(f"Error extracting tasks from plan: {str(e)}")
            # Empty list already set as default
        
        # Extract dependencies if not in tasks
        if not structured_plan["tasks"] and "Dependencies:" in output:
            parts = output.split("Dependencies:", 1)
            if len(parts) > 1:
                dependencies_text = parts[1].split("\n\n", 1)[0].strip()
                # Simple parsing of dependencies
                dependencies = [d.strip() for d in dependencies_text.split("\n") if d.strip()]
                structured_plan["dependencies"] = dependencies
        
        # Extract timeline and milestones
        if "Timeline & Milestones:" in output:
            parts = output.split("Timeline & Milestones:", 1)
            if len(parts) > 1:
                timeline_text = parts[1].split("\n\n", 1)[0].strip()
                # Simple parsing of timeline
                timeline = [t.strip() for t in timeline_text.split("\n") if t.strip()]
                structured_plan["timeline_milestones"] = timeline
        
        # Extract risk assessment if included
        if "Risk Assessment:" in output:
            parts = output.split("Risk Assessment:", 1)
            if len(parts) > 1:
                risk_text = parts[1].strip()
                # Simple parsing of risks
                risks = [r.strip() for r in risk_text.split("\n") if r.strip()]
                structured_plan["risk_assessment"] = risks
        
        # Add raw output for reference
        structured_plan["raw_output"] = output
        
        return structured_plan
    
    def _parse_tasks_manually(self, tasks_text: str) -> List[Dict[str, Any]]:
        """
        Manually parse tasks from text when JSON parsing fails.
        
        Args:
            tasks_text: Text containing task descriptions
            
        Returns:
            List of parsed task dictionaries
        """
        tasks = []
        current_task = {}
        task_lines = tasks_text.split('\n')
        
        for line in task_lines:
            line = line.strip()
            if not line:
                continue
                
            # Check if this is a new task (starts with number or has ID:)
            if line[0].isdigit() and '.' in line[:3] or line.lower().startswith('task'):
                # Save previous task if it exists
                if current_task:
                    tasks.append(current_task)
                    current_task = {}
                
                # Extract task name/description
                task_desc = line[line.find('.')+1:].strip() if '.' in line[:3] else line
                current_task = {"description": task_desc, "id": f"task_{len(tasks) + 1}"}
            
            # Extract task properties
            elif ':' in line:
                key, value = line.split(':', 1)
                key = key.strip().lower().replace(' ', '_')
                value = value.strip()
                
                # Handle special cases
                if key == 'dependencies' or key == 'assigned_to':
                    # Convert comma-separated list to array
                    value = [v.strip() for v in value.split(',') if v.strip()]
                
                current_task[key] = value
        
        # Add the last task if it exists
        if current_task:
            tasks.append(current_task)
        
        return tasks
    
    def analyze_dependencies(self, tasks: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Analyze task dependencies to identify critical path and potential bottlenecks.
        
        Args:
            tasks: List of tasks with dependencies
            
        Returns:
            Dictionary with dependency analysis
        """
        # Create dependency graph
        dependency_graph = {}
        for task in tasks:
            task_id = task.get("id", "")
            if not task_id:
                continue
                
            dependencies = task.get("dependencies", [])
            dependency_graph[task_id] = dependencies
        
        # Identify tasks with no dependencies (entry points)
        entry_tasks = [task.get("id") for task in tasks if not task.get("dependencies")]
        
        # Identify tasks that no other tasks depend on (exit points)
        all_dependencies = [dep for deps in dependency_graph.values() for dep in deps]
        exit_tasks = [task_id for task_id in dependency_graph if task_id not in all_dependencies]
        
        # Simple critical path determination (placeholder for actual algorithm)
        # A real implementation would use a proper CPM algorithm
        critical_path = self._simple_critical_path(tasks, dependency_graph)
        
        return {
            "entry_points": entry_tasks,
            "exit_points": exit_tasks,
            "critical_path": critical_path,
            "dependency_graph": dependency_graph
        }
    
    def _simple_critical_path(self, tasks: List[Dict[str, Any]], dependency_graph: Dict[str, List[str]]) -> List[str]:
        """
        Simple approximation of critical path (not a true CPM algorithm).
        
        Args:
            tasks: List of tasks
            dependency_graph: Graph of task dependencies
            
        Returns:
            List of task IDs approximating the critical path
        """
        # This is a simplified placeholder - a real implementation would use proper CPM
        # with forward and backward passes to calculate float and identify critical path
        
        # For this demo, just find a path from an entry to an exit with highest complexities
        task_complexity = {}
        for task in tasks:
            task_id = task.get("id", "")
            complexity = task.get("estimated_complexity", "medium").lower()
            
            # Convert complexity to numeric value
            complexity_value = {"low": 1, "medium": 2, "high": 3}.get(complexity, 2)
            task_complexity[task_id] = complexity_value
        
        # Find entry tasks (tasks with no dependencies)
        entry_tasks = [task.get("id") for task in tasks if not task.get("dependencies")]
        
        # Find exit tasks (tasks that no other tasks depend on)
        all_dependencies = [dep for deps in dependency_graph.values() for dep in deps]
        exit_tasks = [task_id for task_id in dependency_graph if task_id not in all_dependencies]
        
        # Simplified path finding - just a placeholder
        if not entry_tasks or not exit_tasks:
            return []
            
        # Just return a simple chain for demonstration purposes
        current = entry_tasks[0]
        path = [current]
        
        while current not in exit_tasks:
            # Find tasks that depend on current
            next_tasks = []
            for task_id, deps in dependency_graph.items():
                if current in deps:
                    next_tasks.append(task_id)
            
            if not next_tasks:
                break
                
            # Choose the task with highest complexity
            next_task = max(next_tasks, key=lambda t: task_complexity.get(t, 0))
            path.append(next_task)
            current = next_task
        
        return path
    
    def create_gantt_chart(self, tasks: List[Dict[str, Any]]) -> str:
        """
        Create a text-based Gantt chart representation of the plan.
        
        Args:
            tasks: List of tasks with dependencies
            
        Returns:
            Text representation of a Gantt chart
        """
        # Simple text-based Gantt chart
        chart = ["Gantt Chart:\n"]
        
        # Sort tasks based on dependencies (simple topological sort)
        sorted_tasks = self._topological_sort(tasks)
        
        # Create a simple timeline representation
        timeline = {}
        current_time = 0
        
        for task in sorted_tasks:
            task_id = task.get("id", "")
            description = task.get("description", "").split('\n')[0][:30]  # Truncate for display
            dependencies = task.get("dependencies", [])
            
            # Determine start time based on dependencies
            start_time = 0
            for dep in dependencies:
                if dep in timeline and timeline[dep]["end"] > start_time:
                    start_time = timeline[dep]["end"]
            
            # Calculate duration based on complexity
            complexity = task.get("estimated_complexity", "medium").lower()
            duration = {"low": 1, "medium": 2, "high": 3}.get(complexity, 2)
            
            # Record in timeline
            timeline[task_id] = {
                "start": start_time,
                "end": start_time + duration,
                "description": description,
                "duration": duration
            }
        
        # Find the max time
        max_time = max([t["end"] for t in timeline.values()]) if timeline else 0
        
        # Create header
        chart.append("Task" + " " * 26 + "|" + "".join([str(i % 10) for i in range(max_time + 1)]))
        chart.append("-" * 30 + "+" + "-" * (max_time + 1))
        
        # Add tasks to chart
        for task_id, task_info in timeline.items():
            # Create the task line
            task_name = f"{task_id}: {task_info['description']}"
            if len(task_name) > 29:
                task_name = task_name[:26] + "..."
            
            line = task_name + " " * (30 - len(task_name)) + "|"
            
            # Add the timeline
            for i in range(max_time + 1):
                if task_info["start"] <= i < task_info["end"]:
                    line += "#"
                else:
                    line += " "
            
            chart.append(line)
        
        return "\n".join(chart)
    
    def _topological_sort(self, tasks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Sort tasks based on dependencies (topological sort).
        
        Args:
            tasks: List of tasks with dependencies
            
        Returns:
            Sorted list of tasks
        """
        # Create a dictionary of task_id to task
        task_dict = {task.get("id", f"task_{i}"): task for i, task in enumerate(tasks)}
        
        # Create adjacency list
        graph = {}
        for task in tasks:
            task_id = task.get("id", "")
            if not task_id:
                continue
            
            graph[task_id] = task.get("dependencies", [])
        
        # Perform topological sort
        visited = set()
        temp_mark = set()
        result = []
        
        def visit(node):
            if node in temp_mark:
                # Circular dependency, handle gracefully
                return
            if node not in visited:
                temp_mark.add(node)
                for dep in graph.get(node, []):
                    if dep in task_dict:  # Make sure the dependency exists
                        visit(dep)
                temp_mark.remove(node)
                visited.add(node)
                result.append(task_dict[node])
        
        # Visit all nodes
        for node in graph:
            if node not in visited:
                visit(node)
        
        # Reverse to get correct order
        return result[::-1]
    
    def get_role_description(self) -> str:
        """
        Get a description of this agent's role.
        
        Returns:
            Description of the agent's role
        """
        return (
            f"I am a {self.role} agent specializing in strategic planning and task management. "
            f"I can analyze complex tasks, break them down into manageable components, "
            f"identify dependencies, and create structured execution plans. "
            f"I can also perform critical path analysis and help with resource allocation."
        )
--------------------------------------------------------------------------------
        research_agent.py

Content of C:/AI PROJECT/My Langchain Crew 1\agents\research_agent.py:
"""
Research Agent Module

This module implements the ResearchAgent class, which specializes in gathering
and synthesizing information from various sources to support other agents.
"""

import logging
import json
from typing import Dict, Any, List, Optional, Union

from langchain_core.tools import BaseTool

from agents.base_agent import BaseAgent
from core.knowledge_repository import KnowledgeRepository

logger = logging.getLogger(__name__)

class ResearchAgent(BaseAgent):
    """
    Agent specialized in gathering, analyzing, and synthesizing information.
    
    This agent can use web search tools, documentation retrieval, and other
    information-gathering methods to support the team's knowledge needs.
    """
    
    def __init__(
        self, 
        agent_executor,
        role: str = "research",
        config: Dict[str, Any] = None,
        knowledge_repository: Optional[KnowledgeRepository] = None
    ):
        """
        Initialize the research agent.
        
        Args:
            agent_executor: The LangChain agent executor
            role: The specific role of this research agent
            config: Configuration dictionary with agent settings
            knowledge_repository: Knowledge repository for accessing shared information
        """
        config = config or {}
        super().__init__(agent_executor, role, config, knowledge_repository)
        
        # Research-specific configuration
        self.auto_save_results = config.get("auto_save_results", True)
        self.max_search_results = config.get("max_search_results", 5)
        self.include_sources = config.get("include_sources", True)
        
        logger.debug(f"Initialized ResearchAgent with role: {role}")
    
    def get_capabilities(self) -> List[str]:
        """
        Get the list of capabilities this agent has.
        
        Returns:
            List of capability descriptions
        """
        return [
            "Web search to find relevant information",
            "Information synthesis and summarization",
            "Extraction of key facts and insights",
            "Organization of research findings",
            "Citation and source tracking",
            "Identification of knowledge gaps"
        ]
    
    def research_topic(self, topic: str, depth: str = "medium") -> Dict[str, Any]:
        """
        Conduct comprehensive research on a specific topic.
        
        Args:
            topic: The research topic or question
            depth: Depth of research ("brief", "medium", "comprehensive")
            
        Returns:
            Dictionary with research results
        """
        # Create structured research request
        research_prompt = self._create_research_prompt(topic, depth)
        
        # Execute the research task
        result = self.execute_task(research_prompt)
        
        # Extract and structure the research findings
        structured_results = self._structure_research_results(result, topic)
        
        # Store in knowledge repository if configured
        if self.auto_save_results and self.knowledge_repository:
            self._store_research_results(structured_results, topic)
        
        return structured_results
    
    def _create_research_prompt(self, topic: str, depth: str) -> str:
        """
        Create a detailed research prompt for the given topic.
        
        Args:
            topic: Research topic or question
            depth: Depth of research
            
        Returns:
            Formatted research prompt
        """
        depth_instructions = {
            "brief": "Provide a concise overview with key facts and insights. Keep your research focused on the most important aspects.",
            "medium": "Provide a balanced research report covering main aspects of the topic. Include key facts, some context, and notable insights.",
            "comprehensive": "Conduct thorough research on all aspects of this topic. Include detailed information, historical context, different perspectives, and in-depth analysis."
        }
        
        depth_instruction = depth_instructions.get(depth.lower(), depth_instructions["medium"])
        
        prompt = f"""
        Research Request: {topic}
        
        {depth_instruction}
        
        Please structure your research as follows:
        1. Summary: A concise overview of your findings
        2. Key Facts: The most important facts and data points
        3. Detailed Analysis: In-depth exploration of the topic
        4. Insights & Implications: What these findings mean or suggest
        5. Sources: References to where this information was found (if available)
        
        Use the available search tools to gather accurate and relevant information.
        If certain information isn't available, acknowledge these limitations.
        """
        
        return prompt
    
    def _structure_research_results(self, result: Dict[str, Any], topic: str) -> Dict[str, Any]:
        """
        Structure the raw research results into a consistent format.
        
        Args:
            result: Raw execution result
            topic: Original research topic
            
        Returns:
            Structured research results
        """
        output = result.get("output", "")
        
        # Attempt to parse structured sections from the output
        sections = {
            "summary": "",
            "key_facts": [],
            "detailed_analysis": "",
            "insights": "",
            "sources": []
        }
        
        # Extract sections using simple heuristics
        if "Summary:" in output or "SUMMARY:" in output:
            parts = output.split("Summary:", 1) if "Summary:" in output else output.split("SUMMARY:", 1)
            if len(parts) > 1:
                summary_text = parts[1].split("\n\n", 1)[0].strip()
                sections["summary"] = summary_text
        
        if "Key Facts:" in output or "KEY FACTS:" in output:
            parts = output.split("Key Facts:", 1) if "Key Facts:" in output else output.split("KEY FACTS:", 1)
            if len(parts) > 1:
                facts_text = parts[1].split("\n\n", 1)[0].strip()
                # Split into bullet points or numbered items
                facts = [f.strip() for f in facts_text.split("\n") if f.strip()]
                sections["key_facts"] = facts
        
        if "Detailed Analysis:" in output or "DETAILED ANALYSIS:" in output:
            parts = output.split("Detailed Analysis:", 1) if "Detailed Analysis:" in output else output.split("DETAILED ANALYSIS:", 1)
            if len(parts) > 1:
                analysis_text = parts[1].split("\n\n", 1)[0].strip()
                sections["detailed_analysis"] = analysis_text
        
        if "Insights" in output or "INSIGHTS" in output:
            parts = output.split("Insights", 1) if "Insights" in output else output.split("INSIGHTS", 1)
            if len(parts) > 1:
                insights_text = parts[1].split("\n\n", 1)[0].strip()
                sections["insights"] = insights_text
        
        if "Sources:" in output or "SOURCES:" in output:
            parts = output.split("Sources:", 1) if "Sources:" in output else output.split("SOURCES:", 1)
            if len(parts) > 1:
                sources_text = parts[1].strip()
                # Split into bullet points or numbered items
                sources = [s.strip() for s in sources_text.split("\n") if s.strip()]
                sections["sources"] = sources
        
        # If we couldn't parse structured sections, use the entire output as summary
        if not sections["summary"] and not sections["detailed_analysis"]:
            sections["summary"] = output
        
        # Create the final structured result
        structured_result = {
            "topic": topic,
            "research_data": sections,
            "raw_output": output
        }
        
        return structured_result
    
    def _store_research_results(self, research_results: Dict[str, Any], topic: str):
        """
        Store research results in the knowledge repository.
        
        Args:
            research_results: Structured research results
            topic: Research topic
        """
        if not self.knowledge_repository:
            return
        
        try:
            # Format the content for storage
            content = f"Research on: {topic}\n\n"
            
            # Add summary
            summary = research_results.get("research_data", {}).get("summary", "")
            if summary:
                content += f"Summary:\n{summary}\n\n"
            
            # Add key facts
            key_facts = research_results.get("research_data", {}).get("key_facts", [])
            if key_facts:
                content += "Key Facts:\n"
                for i, fact in enumerate(key_facts, 1):
                    content += f"{i}. {fact}\n"
                content += "\n"
            
            # Add detailed analysis
            analysis = research_results.get("research_data", {}).get("detailed_analysis", "")
            if analysis:
                content += f"Detailed Analysis:\n{analysis}\n\n"
            
            # Add insights
            insights = research_results.get("research_data", {}).get("insights", "")
            if insights:
                content += f"Insights & Implications:\n{insights}\n\n"
            
            # Add sources
            sources = research_results.get("research_data", {}).get("sources", [])
            if sources and self.include_sources:
                content += "Sources:\n"
                for i, source in enumerate(sources, 1):
                    content += f"{i}. {source}\n"
            
            # Store in knowledge repository
            self.knowledge_repository.store_external_knowledge(
                source=f"Research on {topic}",
                content=content,
                metadata={
                    "type": "research",
                    "topic": topic,
                    "agent_role": self.role
                }
            )
            
            logger.info(f"Stored research results for topic: {topic}")
            
        except Exception as e:
            logger.error(f"Error storing research results: {str(e)}")
    
    def find_information(self, query: str, max_results: int = None) -> Dict[str, Any]:
        """
        Find specific information based on a query.
        
        Args:
            query: Information query
            max_results: Maximum number of results to return
            
        Returns:
            Dictionary with search results
        """
        # Use default if not specified
        max_results = max_results or self.max_search_results
        
        # Create search prompt
        search_prompt = f"""
        Information Request: {query}
        
        Please search for this specific information and provide a clear, concise answer.
        If multiple relevant pieces of information are found, include up to {max_results} results.
        
        Include the source of the information when available.
        If the information cannot be found, explain what was searched for and why it might not be available.
        """
        
        # Execute search task
        result = self.execute_task(search_prompt)
        
        # Process and return results
        return {
            "query": query,
            "results": result.get("output", "No results found"),
            "metadata": result.get("metadata", {})
        }
    
    def combine_information(self, sources: List[Dict[str, Any]], query: str = None) -> Dict[str, Any]:
        """
        Combine and synthesize information from multiple sources.
        
        Args:
            sources: List of information sources
            query: Optional context for the synthesis
            
        Returns:
            Dictionary with synthesized information
        """
        # Format sources for the prompt
        formatted_sources = []
        for i, source in enumerate(sources, 1):
            content = source.get("content", "")
            metadata = source.get("metadata", {})
            source_desc = metadata.get("source", f"Source {i}")
            
            formatted_sources.append(f"--- From {source_desc} ---")
            formatted_sources.append(content)
        
        # Create synthesis prompt
        synthesis_prompt = "Synthesize the following information into a coherent, comprehensive response:\n\n"
        synthesis_prompt += "\n\n".join(formatted_sources)
        
        if query:
            synthesis_prompt += f"\n\nThis synthesis should address the following question or topic: {query}"
        
        # Execute synthesis task
        result = self.execute_task(synthesis_prompt)
        
        # Return synthesized information
        return {
            "synthesis": result.get("output", ""),
            "source_count": len(sources),
            "query": query
        }
    
    def _process_result(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """
        Process the execution result with research-specific enhancements.
        
        Args:
            result: The raw execution result
            
        Returns:
            Processed result
        """
        # Call the base implementation first
        processed = super()._process_result(result)
        
        # Extract any URLs or sources if present in the output
        output = processed.get("output", "")
        sources = []
        
        # Simple extraction of URLs (could be enhanced with regex)
        for line in output.split("\n"):
            if "http://" in line or "https://" in line:
                sources.append(line.strip())
            elif "Source:" in line:
                sources.append(line.strip())
        
        # Add extracted sources to metadata
        if sources and "metadata" in processed:
            processed["metadata"]["extracted_sources"] = sources
        
        return processed
    
    def get_role_description(self) -> str:
        """
        Get a description of this agent's role.
        
        Returns:
            Description of the agent's role
        """
        return (
            f"I am a {self.role} agent specializing in gathering, analyzing, and "
            f"synthesizing information from various sources. I can conduct research "
            f"on topics, find specific information, and combine knowledge from "
            f"multiple sources into coherent insights."
        )
--------------------------------------------------------------------------------
        reviewer_agent.py

Content of C:/AI PROJECT/My Langchain Crew 1\agents\reviewer_agent.py:
"""
Reviewer Agent Module

This module implements the ReviewerAgent class, which specializes in evaluating and
reviewing the work of other agents, providing feedback, suggestions for improvement,
and quality assurance.
"""

import logging
from typing import Dict, Any, List, Optional, Union

from agents.base_agent import BaseAgent
from core.knowledge_repository import KnowledgeRepository

logger = logging.getLogger(__name__)

class ReviewerAgent(BaseAgent):
    """
    Agent specialized in reviewing and evaluating the work of other agents.
    
    This agent examines solutions, implementations, and other outputs to assess
    quality, identify issues, and suggest improvements, serving as a quality
    assurance mechanism for the team.
    """
    
    def __init__(
        self, 
        agent_executor,
        role: str = "reviewer",
        config: Dict[str, Any] = None,
        knowledge_repository: Optional[KnowledgeRepository] = None
    ):
        """
        Initialize the reviewer agent.
        
        Args:
            agent_executor: The LangChain agent executor
            role: The specific role of this reviewer agent
            config: Configuration dictionary with agent settings
            knowledge_repository: Knowledge repository for accessing shared information
        """
        config = config or {}
        super().__init__(agent_executor, role, config, knowledge_repository)
        
        # Reviewer-specific configuration
        self.review_criteria = config.get("review_criteria", [
            "correctness",
            "completeness",
            "efficiency",
            "maintainability"
        ])
        
        logger.debug(f"Initialized ReviewerAgent with role: {role}")
    
    def get_capabilities(self) -> List[str]:
        """
        Get the list of capabilities this agent has.
        
        Returns:
            List of capability descriptions
        """
        return [
            "Quality assessment of solutions and implementations",
            "Identification of errors, bugs, and issues",
            "Evaluation against requirements and specifications",
            "Suggestions for improvements and optimizations",
            "Code review and analysis",
            "Documentation review",
            "Compliance checking against standards and best practices"
        ]
    
    def review_solution(
        self, 
        solution: Dict[str, Any], 
        requirements: Dict[str, Any], 
        review_type: str = "general"
    ) -> Dict[str, Any]:
        """
        Review a solution against requirements.
        
        Args:
            solution: The solution to review
            requirements: The requirements to evaluate against
            review_type: Type of review to perform
            
        Returns:
            Dictionary containing the review results
        """
        # Create the review prompt
        review_prompt = self._create_review_prompt(solution, requirements, review_type)
        
        # Execute the review
        result = self.execute_task(review_prompt)
        
        # Process and structure the review results
        structured_review = self._structure_review_results(result, review_type)
        
        # Add metadata
        structured_review["review_type"] = review_type
        structured_review["solution_type"] = solution.get("type", "unknown")
        
        return structured_review
    
    def _create_review_prompt(
        self, 
        solution: Dict[str, Any], 
        requirements: Dict[str, Any], 
        review_type: str
    ) -> str:
        """
        Create a review prompt for the given solution and requirements.
        
        Args:
            solution: The solution to review
            requirements: The requirements to evaluate against
            review_type: Type of review to perform
            
        Returns:
            Formatted review prompt
        """
        # Extract key information
        solution_type = solution.get("type", "general")
        solution_content = solution.get("content", "")
        solution_description = solution.get("description", "")
        
        # If content is a dictionary, format it as a string
        if isinstance(solution_content, dict):
            solution_content = json.dumps(solution_content, indent=2)
        elif isinstance(solution_content, list):
            solution_content = "\n".join([str(item) for item in solution_content])
        
        # Extract requirements
        req_description = requirements.get("description", "")
        req_criteria = requirements.get("criteria", [])
        req_constraints = requirements.get("constraints", [])
        
        # Build the prompt
        prompt_parts = [
            f"Review Type: {review_type}",
            "",
            "Solution Description:",
            solution_description,
            "",
            "Solution to Review:",
            solution_content,
            "",
            "Requirements and Criteria:",
            req_description
        ]
        
        # Add specific requirements criteria
        if req_criteria:
            prompt_parts.append("\nRequirements Criteria:")
            for i, criterion in enumerate(req_criteria, 1):
                prompt_parts.append(f"{i}. {criterion}")
        
        # Add constraints
        if req_constraints:
            prompt_parts.append("\nConstraints:")
            for i, constraint in enumerate(req_constraints, 1):
                prompt_parts.append(f"{i}. {constraint}")
        
        # Add review-type specific instructions
        if review_type == "code_review":
            prompt_parts.append("\nCode Review Instructions:")
            prompt_parts.append(
                "Please perform a thorough code review focusing on correctness, "
                "efficiency, security, maintainability, and adherence to best practices. "
                "Identify any bugs, vulnerabilities, or potential issues."
            )
        elif review_type == "design_review":
            prompt_parts.append("\nDesign Review Instructions:")
            prompt_parts.append(
                "Please evaluate the design for completeness, coherence, scalability, "
                "and alignment with requirements. Consider architectural soundness, "
                "component relationships, and overall effectiveness."
            )
        elif review_type == "documentation_review":
            prompt_parts.append("\nDocumentation Review Instructions:")
            prompt_parts.append(
                "Please review the documentation for clarity, completeness, accuracy, "
                "organization, and usefulness. Ensure it effectively communicates the "
                "necessary information to its intended audience."
            )
        else:
            prompt_parts.append("\nReview Instructions:")
            prompt_parts.append(
                "Please conduct a comprehensive review evaluating how well the solution "
                "meets the requirements and criteria. Identify strengths, weaknesses, "
                "and areas for improvement."
            )
        
        # Add review structure guidelines
        prompt_parts.append("\nPlease structure your review as follows:")
        prompt_parts.append("1. Overall Assessment: A brief summary of your evaluation")
        prompt_parts.append("2. Strengths: What aspects of the solution are well done")
        prompt_parts.append("3. Issues: Problems, bugs, or concerns that need to be addressed")
        prompt_parts.append("4. Improvement Suggestions: Specific recommendations for enhancement")
        prompt_parts.append("5. Compliance: How well the solution meets the requirements")
        
        if review_type == "code_review":
            prompt_parts.append("6. Code Quality: Assessment of the code's quality and maintainability")
            prompt_parts.append("7. Security Analysis: Identification of any security concerns")
        
        prompt_parts.append("\nPlease be specific, constructive, and actionable in your feedback.")
        
        return "\n".join(prompt_parts)
    
    def _structure_review_results(self, result: Dict[str, Any], review_type: str) -> Dict[str, Any]:
        """
        Structure the raw review results into a consistent format.
        
        Args:
            result: Raw execution result
            review_type: Type of review performed
            
        Returns:
            Structured review results
        """
        output = result.get("output", "")
        
        # Initialize structured review
        structured_review = {
            "overall_assessment": "",
            "strengths": [],
            "issues": [],
            "improvement_suggestions": [],
            "compliance": "",
            "rating": None,
            "raw_review": output
        }
        
        # Add code-specific fields for code reviews
        if review_type == "code_review":
            structured_review["code_quality"] = ""
            structured_review["security_analysis"] = ""
        
        # Extract overall assessment
        if "Overall Assessment:" in output:
            parts = output.split("Overall Assessment:", 1)
            if len(parts) > 1:
                assessment_text = parts[1].split("\n\n", 1)[0]
                structured_review["overall_assessment"] = assessment_text.strip()
        
        # Extract strengths
        if "Strengths:" in output:
            parts = output.split("Strengths:", 1)
            if len(parts) > 1:
                strengths_text = parts[1].split("\n\n", 1)[0]
                strengths = [s.strip() for s in strengths_text.split("\n") if s.strip()]
                # Clean up bullet points
                strengths = [s[2:].strip() if s.startswith('- ') else 
                            s[s.find('.')+1:].strip() if s[0].isdigit() and '.' in s[:3] else 
                            s for s in strengths]
                structured_review["strengths"] = strengths
        
        # Extract issues
        if "Issues:" in output:
            parts = output.split("Issues:", 1)
            if len(parts) > 1:
                issues_text = parts[1].split("\n\n", 1)[0]
                issues = [i.strip() for i in issues_text.split("\n") if i.strip()]
                # Clean up bullet points
                issues = [i[2:].strip() if i.startswith('- ') else 
                         i[i.find('.')+1:].strip() if i[0].isdigit() and '.' in i[:3] else 
                         i for i in issues]
                structured_review["issues"] = issues
        
        # Extract improvement suggestions
        if "Improvement Suggestions:" in output:
            parts = output.split("Improvement Suggestions:", 1)
            if len(parts) > 1:
                suggestions_text = parts[1].split("\n\n", 1)[0]
                suggestions = [s.strip() for s in suggestions_text.split("\n") if s.strip()]
                # Clean up bullet points
                suggestions = [s[2:].strip() if s.startswith('- ') else 
                              s[s.find('.')+1:].strip() if s[0].isdigit() and '.' in s[:3] else 
                              s for s in suggestions]
                structured_review["improvement_suggestions"] = suggestions
        
        # Extract compliance
        if "Compliance:" in output:
            parts = output.split("Compliance:", 1)
            if len(parts) > 1:
                compliance_text = parts[1].split("\n\n", 1)[0]
                structured_review["compliance"] = compliance_text.strip()
        
        # Extract code quality for code reviews
        if review_type == "code_review" and "Code Quality:" in output:
            parts = output.split("Code Quality:", 1)
            if len(parts) > 1:
                quality_text = parts[1].split("\n\n", 1)[0]
                structured_review["code_quality"] = quality_text.strip()
        
        # Extract security analysis for code reviews
        if review_type == "code_review" and "Security Analysis:" in output:
            parts = output.split("Security Analysis:", 1)
            if len(parts) > 1:
                security_text = parts[1].split("\n\n", 1)[0]
                structured_review["security_analysis"] = security_text.strip()
        
        # Determine a numeric rating based on the review
        structured_review["rating"] = self._calculate_rating(structured_review)
        
        return structured_review
    
    def _calculate_rating(self, structured_review: Dict[str, Any]) -> float:
        """
        Calculate a numeric rating based on the structured review.
        
        Args:
            structured_review: The structured review data
            
        Returns:
            Numeric rating between 0 and 10
        """
        # This is a simplified rating algorithm
        # A real implementation would be more sophisticated
        
        # Start with a neutral score
        rating = 5.0
        
        # Analyze overall assessment tone
        assessment = structured_review.get("overall_assessment", "").lower()
        if any(word in assessment for word in ["excellent", "outstanding", "exceptional"]):
            rating += 2.0
        elif any(word in assessment for word in ["good", "solid", "strong"]):
            rating += 1.0
        elif any(word in assessment for word in ["poor", "inadequate", "fails"]):
            rating -= 2.0
        elif any(word in assessment for word in ["issue", "concern", "problem"]):
            rating -= 1.0
        
        # Adjust based on strengths and issues
        strengths_count = len(structured_review.get("strengths", []))
        issues_count = len(structured_review.get("issues", []))
        
        # More strengths than issues is good
        if strengths_count > issues_count:
            rating += min(2.0, (strengths_count - issues_count) * 0.5)
        # More issues than strengths is bad
        elif issues_count > strengths_count:
            rating -= min(2.0, (issues_count - strengths_count) * 0.5)
        
        # Check for critical issues
        critical_issues = 0
        for issue in structured_review.get("issues", []):
            if any(word in issue.lower() for word in ["critical", "severe", "major", "serious"]):
                critical_issues += 1
        
        # Deduct for critical issues
        rating -= min(3.0, critical_issues * 1.0)
        
        # Analyze compliance
        compliance = structured_review.get("compliance", "").lower()
        if "fully" in compliance and "meet" in compliance:
            rating += 1.0
        elif "partially" in compliance:
            rating -= 0.5
        elif "not" in compliance and "meet" in compliance:
            rating -= 1.0
        
        # Ensure rating is within bounds
        rating = max(0.0, min(10.0, rating))
        
        return round(rating, 1)
    
    def synthesize_reviews(self, reviews: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Synthesize multiple reviews into a consolidated review.
        
        Args:
            reviews: List of individual reviews
            
        Returns:
            Consolidated review
        """
        if not reviews:
            return {
                "overall_assessment": "No reviews provided",
                "strengths": [],
                "issues": [],
                "improvement_suggestions": [],
                "compliance": "N/A",
                "rating": None
            }
        
        # Create a prompt to synthesize the reviews
        synthesis_prompt = self._create_synthesis_prompt(reviews)
        
        # Execute the synthesis
        result = self.execute_task(synthesis_prompt)
        
        # Process and structure the synthesis results
        structured_synthesis = self._structure_review_results(result, "synthesis")
        
        # Calculate an average rating
        ratings = [review.get("rating", 0) for review in reviews if review.get("rating") is not None]
        avg_rating = sum(ratings) / len(ratings) if ratings else None
        structured_synthesis["rating"] = avg_rating
        
        # Add metadata
        structured_synthesis["review_count"] = len(reviews)
        structured_synthesis["review_types"] = list(set(review.get("review_type", "unknown") for review in reviews))
        
        return structured_synthesis
    
    def _create_synthesis_prompt(self, reviews: List[Dict[str, Any]]) -> str:
        """
        Create a prompt to synthesize multiple reviews.
        
        Args:
            reviews: List of reviews to synthesize
            
        Returns:
            Synthesis prompt
        """
        prompt_parts = [
            "Task: Synthesize the following reviews into a consolidated review.",
            "",
            f"Number of reviews to synthesize: {len(reviews)}",
            "",
            "Reviews:"
        ]
        
        # Add each review
        for i, review in enumerate(reviews, 1):
            prompt_parts.append(f"\nReview {i} ({review.get('review_type', 'unknown')}):")
            prompt_parts.append(f"Overall Assessment: {review.get('overall_assessment', 'N/A')}")
            
            # Add strengths
            prompt_parts.append("Strengths:")
            for strength in review.get("strengths", []):
                prompt_parts.append(f"- {strength}")
            
            # Add issues
            prompt_parts.append("Issues:")
            for issue in review.get("issues", []):
                prompt_parts.append(f"- {issue}")
            
            # Add improvement suggestions
            prompt_parts.append("Improvement Suggestions:")
            for suggestion in review.get("improvement_suggestions", []):
                prompt_parts.append(f"- {suggestion}")
            
            prompt_parts.append(f"Compliance: {review.get('compliance', 'N/A')}")
            prompt_parts.append(f"Rating: {review.get('rating', 'N/A')}")
        
        # Add synthesis instructions
        prompt_parts.append("\nPlease synthesize these reviews into a consolidated review that:")
        prompt_parts.append("1. Provides a balanced overall assessment")
        prompt_parts.append("2. Identifies common strengths across reviews")
        prompt_parts.append("3. Highlights important issues that need addressing")
        prompt_parts.append("4. Consolidates improvement suggestions")
        prompt_parts.append("5. Provides an overall compliance assessment")
        
        prompt_parts.append("\nStructure your synthesis as follows:")
        prompt_parts.append("1. Overall Assessment: A comprehensive summary")
        prompt_parts.append("2. Strengths: Common and significant strengths")
        prompt_parts.append("3. Issues: Important problems that need addressing")
        prompt_parts.append("4. Improvement Suggestions: Consolidated recommendations")
        prompt_parts.append("5. Compliance: Overall assessment of requirement compliance")
        
        return "\n".join(prompt_parts)
    
    def review_code(self, code: str, language: str, requirements: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        Perform a specialized code review.
        
        Args:
            code: The code to review
            language: The programming language of the code
            requirements: Optional requirements to evaluate against
            
        Returns:
            Code review results
        """
        # Create a solution object
        solution = {
            "type": "code",
            "content": code,
            "description": f"{language} code review"
        }
        
        # Default requirements if none provided
        if not requirements:
            requirements = {
                "description": f"Review {language} code for quality, correctness, and best practices",
                "criteria": [
                    "Correctness: The code should function as intended",
                    "Readability: The code should be easy to read and understand",
                    "Maintainability: The code should be easy to maintain and extend",
                    "Efficiency: The code should be efficient and performant",
                    "Security: The code should be secure and free of vulnerabilities"
                ],
                "constraints": []
            }
            
            # Add language-specific criteria
            if language.lower() == "python":
                requirements["criteria"].append("Follows PEP 8 style guidelines")
                requirements["criteria"].append("Uses Python idioms and best practices")
            elif language.lower() == "javascript":
                requirements["criteria"].append("Follows modern JavaScript conventions")
                requirements["criteria"].append("Properly handles asynchronous operations")
            elif language.lower() == "java":
                requirements["criteria"].append("Follows Java coding conventions")
                requirements["criteria"].append("Uses appropriate OOP principles")
            elif language.lower() == "apex":
                requirements["criteria"].append("Considers Salesforce governor limits")
                requirements["criteria"].append("Follows Salesforce security best practices")
        
        # Perform the review
        return self.review_solution(solution, requirements, "code_review")
    
    def review_documentation(self, documentation: str, doc_type: str, requirements: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        Review documentation for quality and completeness.
        
        Args:
            documentation: The documentation to review
            doc_type: Type of documentation (user_guide, api_reference, etc.)
            requirements: Optional requirements to evaluate against
            
        Returns:
            Documentation review results
        """
        # Create a solution object
        solution = {
            "type": "documentation",
            "content": documentation,
            "description": f"{doc_type} documentation review"
        }
        
        # Default requirements if none provided
        if not requirements:
            requirements = {
                "description": f"Review {doc_type} documentation for quality, clarity, and completeness",
                "criteria": [
                    "Clarity: The documentation should be clear and easy to understand",
                    "Completeness: The documentation should cover all relevant aspects",
                    "Accuracy: The documentation should be accurate and up-to-date",
                    "Organization: The documentation should be well-structured and organized",
                    "Usefulness: The documentation should be helpful to its intended audience"
                ],
                "constraints": []
            }
            
            # Add doc-type specific criteria
            if doc_type.lower() == "user_guide":
                requirements["criteria"].append("Includes clear instructions for common tasks")
                requirements["criteria"].append("Provides helpful examples")
            elif doc_type.lower() == "api_reference":
                requirements["criteria"].append("Documents all public APIs")
                requirements["criteria"].append("Includes parameter and return value descriptions")
            elif doc_type.lower() == "technical_spec":
                requirements["criteria"].append("Provides detailed technical information")
                requirements["criteria"].append("Explains design decisions and trade-offs")
        
        # Perform the review
        return self.review_solution(solution, requirements, "documentation_review")
    
    def get_role_description(self) -> str:
        """
        Get a description of this agent's role.
        
        Returns:
            Description of the agent's role
        """
        return (
            f"I am a {self.role} agent specializing in evaluating and improving the "
            f"quality of work. I can review code, documentation, designs, and other "
            f"deliverables, identifying strengths, issues, and opportunities for "
            f"improvement. My goal is to ensure the highest quality of the team's output."
        )
--------------------------------------------------------------------------------
        specialist_agent.py

Content of C:/AI PROJECT/My Langchain Crew 1\agents\specialist_agent.py:
"""
Specialist Agent Module

This module implements the SpecialistAgent class, which provides domain-specific
expertise in various fields. It can be configured for different specializations
such as development, sales, marketing, etc.
"""

import logging
import json
from typing import Dict, Any, List, Optional, Union

from agents.base_agent import BaseAgent
from core.knowledge_repository import KnowledgeRepository

logger = logging.getLogger(__name__)

class SpecialistAgent(BaseAgent):
    """
    Agent specialized in providing domain-specific expertise.
    
    This agent can be configured for different specializations such as
    software development, data science, marketing, sales, etc.
    """
    
    def __init__(
        self, 
        agent_executor,
        role: str = "specialist",
        config: Dict[str, Any] = None,
        knowledge_repository: Optional[KnowledgeRepository] = None
    ):
        """
        Initialize the specialist agent.
        
        Args:
            agent_executor: The LangChain agent executor
            role: The specific role of this specialist agent
            config: Configuration dictionary with agent settings
            knowledge_repository: Knowledge repository for accessing shared information
        """
        config = config or {}
        super().__init__(agent_executor, role, config, knowledge_repository)
        
        # Extract specialization from role
        self.specialization = self._extract_specialization(role)
        
        # Specialist-specific configuration
        self.domain_knowledge = config.get("domain_knowledge", {})
        self.best_practices = config.get("best_practices", [])
        self.reference_materials = config.get("reference_materials", [])
        
        logger.debug(f"Initialized SpecialistAgent with specialization: {self.specialization}")
    
    def _extract_specialization(self, role: str) -> str:
        """
        Extract specialization from the role string.
        
        Args:
            role: The role string (e.g., "specialist_salesforce_developer")
            
        Returns:
            Extracted specialization
        """
        parts = role.split('_', 1)
        if len(parts) > 1:
            return parts[1]
        return "general"  # Default if no specialization specified
    
    def get_capabilities(self) -> List[str]:
        """
        Get the list of capabilities this agent has.
        
        Returns:
            List of capability descriptions
        """
        # Base capabilities
        capabilities = [
            "Domain-specific expertise and knowledge",
            "Application of best practices in specialty area",
            "Analysis of domain-specific problems",
            "Generation of specialized solutions",
            "Technical implementation in specialty area"
        ]
        
        # Add specialization-specific capabilities
        if self.specialization == "salesforce_developer":
            capabilities.extend([
                "Apex code development and optimization",
                "Lightning component design and implementation",
                "Salesforce integration patterns",
                "SOQL and SOSL query optimization",
                "Salesforce deployment and CI/CD practices"
            ])
        elif self.specialization == "salesforce_admin":
            capabilities.extend([
                "Salesforce configuration and setup",
                "User management and security settings",
                "Workflow and process automation",
                "Report and dashboard creation",
                "Data management and maintenance"
            ])
        elif self.specialization == "web_developer":
            capabilities.extend([
                "Frontend development (HTML, CSS, JavaScript)",
                "Backend system implementation",
                "API design and development",
                "Responsive design implementation",
                "Web performance optimization"
            ])
        elif self.specialization == "data_scientist":
            capabilities.extend([
                "Data analysis and interpretation",
                "Statistical modeling and machine learning",
                "Data visualization and reporting",
                "Predictive analytics",
                "Big data processing techniques"
            ])
        
        return capabilities
    
    def provide_expertise(self, problem_description: str) -> Dict[str, Any]:
        """
        Provide domain-specific expertise on a given problem.
        
        Args:
            problem_description: Description of the problem or question
            
        Returns:
            Dictionary with expert analysis and recommendations
        """
        prompt = self._create_expertise_prompt(problem_description)
        
        # Execute the task
        result = self.execute_task(prompt)
        
        # Process and structure the response
        structured_result = self._structure_expertise_result(result, problem_description)
        
        return structured_result
    
    def _create_expertise_prompt(self, problem_description: str) -> str:
        """
        Create an expertise request prompt.
        
        Args:
            problem_description: Description of the problem
            
        Returns:
            Formatted expertise prompt
        """
        # Add specialization-specific context
        specialization_context = self._get_specialization_context()
        
        # Create the prompt
        prompt = f"""
        As a specialist in {self.specialization}, please provide your expert analysis and recommendations for the following:
        
        Problem/Question: {problem_description}
        
        {specialization_context}
        
        Please structure your response as follows:
        1. Analysis: Your assessment of the problem/question
        2. Key Considerations: Important factors or constraints to consider
        3. Recommendations: Your suggested approach or solution
        4. Best Practices: Relevant best practices to apply
        5. Implementation Notes: Guidance on implementing your recommendations
        
        Be specific, practical, and thorough in your expertise.
        """
        
        return prompt
    
    def _get_specialization_context(self) -> str:
        """
        Get context information specific to this agent's specialization.
        
        Returns:
            Context information as a string
        """
        # Specialization-specific contexts
        contexts = {
            "salesforce_developer": """
            When analyzing, consider:
            - Salesforce governor limits and their impact
            - Security and sharing model implications
            - Maintainability and upgradability of code
            - Integration with existing systems
            - Testing and deployment considerations
            
            Reference latest Salesforce development standards and patterns.
            """,
            
            "salesforce_admin": """
            When analyzing, consider:
            - Declarative vs programmatic solutions
            - Security and permission implications
            - User experience and adoption
            - Maintenance and administration overhead
            - Scalability for future growth
            
            Prioritize declarative solutions where appropriate.
            """,
            
            "web_developer": """
            When analyzing, consider:
            - Browser compatibility requirements
            - Responsive design needs
            - Performance optimization
            - Accessibility requirements
            - Security best practices
            - SEO implications
            
            Balance modern techniques with broad compatibility.
            """,
            
            "data_scientist": """
            When analyzing, consider:
            - Data quality and availability
            - Statistical validity of approaches
            - Computational efficiency
            - Interpretability of models
            - Deployment and operationalization
            - Ethical implications
            
            Focus on practical, implementable solutions with clear value.
            """
        }
        
        # Return the context for this specialization, or a default if not found
        return contexts.get(self.specialization, "Please provide detailed, specialized guidance based on your expertise.")
    
    def _structure_expertise_result(
        self, 
        result: Dict[str, Any], 
        problem_description: str
    ) -> Dict[str, Any]:
        """
        Structure the expertise result into a consistent format.
        
        Args:
            result: Raw execution result
            problem_description: Original problem description
            
        Returns:
            Structured expertise result
        """
        output = result.get("output", "")
        
        # Attempt to parse structured sections from the output
        sections = {
            "analysis": "",
            "key_considerations": [],
            "recommendations": [],
            "best_practices": [],
            "implementation_notes": ""
        }
        
        # Extract sections using simple heuristics
        if "Analysis:" in output or "ANALYSIS:" in output:
            parts = output.split("Analysis:", 1) if "Analysis:" in output else output.split("ANALYSIS:", 1)
            if len(parts) > 1:
                analysis_text = parts[1].split("\n\n", 1)[0].strip()
                sections["analysis"] = analysis_text
        
        if "Key Considerations:" in output or "KEY CONSIDERATIONS:" in output:
            parts = output.split("Key Considerations:", 1) if "Key Considerations:" in output else output.split("KEY CONSIDERATIONS:", 1)
            if len(parts) > 1:
                considerations_text = parts[1].split("\n\n", 1)[0].strip()
                # Split into bullet points or numbered items
                considerations = [c.strip() for c in considerations_text.split("\n") if c.strip()]
                sections["key_considerations"] = considerations
        
        if "Recommendations:" in output or "RECOMMENDATIONS:" in output:
            parts = output.split("Recommendations:", 1) if "Recommendations:" in output else output.split("RECOMMENDATIONS:", 1)
            if len(parts) > 1:
                recommendations_text = parts[1].split("\n\n", 1)[0].strip()
                # Split into bullet points or numbered items
                recommendations = [r.strip() for r in recommendations_text.split("\n") if r.strip()]
                sections["recommendations"] = recommendations
        
        if "Best Practices:" in output or "BEST PRACTICES:" in output:
            parts = output.split("Best Practices:", 1) if "Best Practices:" in output else output.split("BEST PRACTICES:", 1)
            if len(parts) > 1:
                practices_text = parts[1].split("\n\n", 1)[0].strip()
                # Split into bullet points or numbered items
                practices = [p.strip() for p in practices_text.split("\n") if p.strip()]
                sections["best_practices"] = practices
        
        if "Implementation Notes:" in output or "IMPLEMENTATION NOTES:" in output:
            parts = output.split("Implementation Notes:", 1) if "Implementation Notes:" in output else output.split("IMPLEMENTATION NOTES:", 1)
            if len(parts) > 1:
                notes_text = parts[1].strip()
                sections["implementation_notes"] = notes_text
        
        # If we couldn't parse structured sections, use the entire output as analysis
        if not sections["analysis"] and not any(sections.values()):
            sections["analysis"] = output
        
        # Create the final structured result
        structured_result = {
            "problem_description": problem_description,
            "expertise_data": sections,
            "specialization": self.specialization,
            "raw_output": output
        }
        
        return structured_result
    
    def evaluate_solution(self, solution: str, requirements: str = None) -> Dict[str, Any]:
        """
        Evaluate a proposed solution from a domain-specialist perspective.
        
        Args:
            solution: The proposed solution to evaluate
            requirements: Optional requirements to evaluate against
            
        Returns:
            Dictionary with evaluation results
        """
        # Create evaluation prompt
        prompt = f"""
        As a specialist in {self.specialization}, please evaluate the following solution:
        
        Solution to Evaluate:
        {solution}
        """
        
        # Add requirements if provided
        if requirements:
            prompt += f"""
            
            Requirements to evaluate against:
            {requirements}
            """
        
        prompt += """
        
        Please provide your evaluation structured as follows:
        1. Strengths: What aspects of the solution are well-designed or effective
        2. Weaknesses: Where the solution falls short or could be improved
        3. Alignment with Best Practices: How well the solution follows standards in this field
        4. Risks: Potential issues or challenges with this approach
        5. Recommendations: Specific suggestions for improvement
        6. Overall Assessment: Your general evaluation (excellent, good, adequate, problematic)
        
        Be specific and constructive in your feedback.
        """
        
        # Execute the evaluation
        result = self.execute_task(prompt)
        
        # Extract and structure the evaluation
        output = result.get("output", "")
        
        # Simple structure for evaluation response
        evaluation = {
            "strengths": self._extract_section(output, "Strengths:"),
            "weaknesses": self._extract_section(output, "Weaknesses:"),
            "alignment": self._extract_section(output, "Alignment with Best Practices:"),
            "risks": self._extract_section(output, "Risks:"),
            "recommendations": self._extract_section(output, "Recommendations:"),
            "overall_assessment": self._extract_section(output, "Overall Assessment:"),
            "raw_evaluation": output
        }
        
        return {
            "solution_evaluated": solution[:200] + "..." if len(solution) > 200 else solution,
            "evaluation": evaluation,
            "specialization": self.specialization
        }
    
    def _extract_section(self, text: str, section_header: str) -> str:
        """
        Extract a section from text based on a header.
        
        Args:
            text: The text to extract from
            section_header: The section header to look for
            
        Returns:
            The extracted section text or empty string if not found
        """
        if section_header in text:
            parts = text.split(section_header, 1)
            if len(parts) > 1:
                section_text = parts[1].split("\n\n", 1)[0].strip()
                return section_text
        return ""
    
    def implement_solution(self, task_description: str, specifications: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        Implement a solution based on task description and specifications.
        
        Args:
            task_description: Description of the task to implement
            specifications: Optional specifications to follow
            
        Returns:
            Dictionary with implementation results
        """
        # Create implementation prompt
        prompt = f"""
        As a specialist in {self.specialization}, please implement a solution for the following task:
        
        Task: {task_description}
        """
        
        # Add specifications if provided
        if specifications:
            prompt += "\n\nSpecifications:\n"
            for key, value in specifications.items():
                prompt += f"- {key}: {value}\n"
        
        prompt += """
        
        Please provide your implementation with:
        1. A clear description of your approach
        2. The actual implementation (code, configuration, etc.)
        3. Instructions for deployment or use
        4. Any assumptions or limitations
        
        Make your solution as complete and ready-to-use as possible.
        """
        
        # Execute the implementation task
        result = self.execute_task(prompt)
        
        # Structure the result
        return {
            "task": task_description,
            "implementation": result.get("output", ""),
            "specialization": self.specialization,
            "metadata": result.get("metadata", {})
        }
    
    def get_role_description(self) -> str:
        """
        Get a description of this agent's role.
        
        Returns:
            Description of the agent's role
        """
        return (
            f"I am a specialist in {self.specialization} with deep domain expertise. "
            f"I can provide expert analysis, evaluate solutions from my domain perspective, "
            f"and implement specialized solutions following best practices in my field."
        )
--------------------------------------------------------------------------------
        __init__.py

Content of C:/AI PROJECT/My Langchain Crew 1\agents\__init__.py:
"""
Agents package.
"""
--------------------------------------------------------------------------------
    core/
        agent_coordinator.py

Content of C:/AI PROJECT/My Langchain Crew 1\core\agent_coordinator.py:
"""
Agent Coordinator Module

This module is responsible for coordinating the workflow between multiple agents,
managing the execution of tasks, and facilitating communication between team members.
"""

import logging
import time
from typing import Dict, Any, List, Optional, Tuple

from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage

from agents.base_agent import BaseAgent
from core.knowledge_repository import KnowledgeRepository
from core.task_scheduler import TaskScheduler
from utils.prompt_templates import COORDINATION_PROMPT, TASK_BREAKDOWN_PROMPT, RESULT_SYNTHESIS_PROMPT

logger = logging.getLogger(__name__)

class AgentCoordinator:
    """
    Coordinates the execution of tasks across a team of agents, managing
    the workflow and facilitating communication between agents.
    """
    
    def __init__(self, config: Dict[str, Any], knowledge_repository: Optional[KnowledgeRepository] = None):
        """
        Initialize the agent coordinator.
        
        Args:
            config: Configuration dictionary with coordinator settings
            knowledge_repository: Knowledge repository for accessing shared information
        """
        self.config = config
        self.knowledge_repository = knowledge_repository
        self.coordination_model = config.get("coordination_model", "gpt-4o")
        self.max_coordination_retries = config.get("max_coordination_retries", 3)
        self.task_scheduler = TaskScheduler(config.get("task_scheduler", {}))
        
        # Initialize the coordination LLM
        self.coordination_llm = ChatOpenAI(
            model=self.coordination_model,
            temperature=0.2
        )
        
        logger.debug(f"Initialized AgentCoordinator with model: {self.coordination_model}")
    
    def execute_task(self, task_description: str, agent_team: Dict[str, BaseAgent]) -> Dict[str, Any]:
        """
        Execute a task with a team of agents.
        
        Args:
            task_description: Description of the task to execute
            agent_team: Dictionary mapping agent IDs to agent instances
            
        Returns:
            Dictionary containing the results and metadata
        """
        logger.info(f"Executing task: {task_description}")
        logger.info(f"Team composition: {', '.join(agent_team.keys())}")
        
        # Step 1: Break down the task into subtasks
        subtasks = self._break_down_task(task_description, agent_team)
        logger.info(f"Task broken down into {len(subtasks)} subtasks")
        
        # Step 2: Schedule the subtasks
        task_schedule = self.task_scheduler.create_schedule(subtasks, list(agent_team.keys()))
        logger.info(f"Created task schedule with {len(task_schedule)} steps")
        
        # Step 3: Execute the scheduled tasks
        execution_results = self._execute_scheduled_tasks(task_schedule, agent_team, task_description)
        logger.info("Task execution completed")
        
        # Step 4: Synthesize the results
        final_results = self._synthesize_results(task_description, execution_results, agent_team)
        logger.info("Results synthesized")
        
        return final_results
    
    def _break_down_task(
        self, 
        task_description: str, 
        agent_team: Dict[str, BaseAgent]
    ) -> List[Dict[str, Any]]:
        """
        Break down a task into subtasks that can be assigned to agents.
        
        Args:
            task_description: The main task description
            agent_team: Dictionary of available agents
            
        Returns:
            List of subtask specifications
        """
        # Check if we have a planner agent in the team
        planner_agent = None
        for agent_id, agent in agent_team.items():
            if agent.role.startswith("planner"):
                planner_agent = agent
                break
        
        subtasks = []
        
        # If we have a planner, use it to break down the task
        if planner_agent:
            logger.debug("Using planner agent to break down task")
            
            # Create a prompt for the planner
            prompt = f"""
            Task Description: {task_description}
            
            As the planning agent, break down this task into subtasks that can be assigned to team members.
            For each subtask, specify:
            1. A clear description
            2. The required skills or role to complete it
            3. Estimated complexity (low, medium, high)
            4. Any dependencies on other subtasks
            
            Available team members and their roles:
            {', '.join([f"{agent_id} ({agent.role})" for agent_id, agent in agent_team.items()])}
            
            Format your response as a list of JSON objects, one per subtask.
            """
            
            # Ask the planner to break down the task
            planner_response = planner_agent.execute_task(prompt)
            
            try:
                # Try to parse the planner's response as a list of subtasks
                import json
                parsed_response = planner_response.get("output", "")
                
                # Find JSON content in the response
                import re
                json_match = re.search(r'\[[\s\S]*\]', parsed_response)
                if json_match:
                    json_content = json_match.group(0)
                    subtasks = json.loads(json_content)
                    logger.debug(f"Successfully parsed {len(subtasks)} subtasks from planner")
                else:
                    raise ValueError("No JSON list found in planner response")
                
            except Exception as e:
                logger.error(f"Error parsing planner response: {str(e)}")
                logger.debug(f"Planner response: {planner_response}")
                # Fall back to LLM-based task breakdown
                subtasks = self._llm_task_breakdown(task_description, agent_team)
        else:
            # No planner, use LLM to break down the task
            logger.debug("No planner agent available, using LLM for task breakdown")
            subtasks = self._llm_task_breakdown(task_description, agent_team)
        
        return subtasks
    
    def _llm_task_breakdown(
        self, 
        task_description: str, 
        agent_team: Dict[str, BaseAgent]
    ) -> List[Dict[str, Any]]:
        """
        Use an LLM to break down a task into subtasks.
        
        Args:
            task_description: The main task description
            agent_team: Dictionary of available agents
            
        Returns:
            List of subtask specifications
        """
        # Create the prompt for task breakdown
        prompt = ChatPromptTemplate.from_template(TASK_BREAKDOWN_PROMPT)
        
        # Format the prompt with task description and team info
        formatted_prompt = prompt.format(
            task_description=task_description,
            available_agents=", ".join([f"{agent_id} ({agent.role})" for agent_id, agent in agent_team.items()])
        )
        
        # Get response from the LLM
        response = self.coordination_llm.invoke(formatted_prompt)
        
        try:
            # Try to parse the response as a list of subtasks
            import json
            import re
            
            # Find JSON content in the response
            json_match = re.search(r'\[[\s\S]*\]', response.content)
            if json_match:
                json_content = json_match.group(0)
                subtasks = json.loads(json_content)
                logger.debug(f"Successfully parsed {len(subtasks)} subtasks from LLM")
                return subtasks
            else:
                raise ValueError("No JSON list found in LLM response")
            
        except Exception as e:
            logger.error(f"Error parsing LLM task breakdown: {str(e)}")
            logger.debug(f"LLM response: {response.content}")
            
            # Return a simplified default task breakdown
            return self._create_default_subtasks(task_description, agent_team)
    
    def _create_default_subtasks(
        self, 
        task_description: str, 
        agent_team: Dict[str, BaseAgent]
    ) -> List[Dict[str, Any]]:
        """
        Create a default set of subtasks when breakdown fails.
        
        Args:
            task_description: The main task description
            agent_team: Dictionary of available agents
            
        Returns:
            List of default subtask specifications
        """
        logger.info("Creating default subtasks")
        
        # Map of roles to default subtasks
        role_subtasks = {
            "research": {
                "description": "Research and gather information related to the task",
                "assigned_agent": "",
                "complexity": "medium",
                "dependencies": []
            },
            "planner": {
                "description": "Create a detailed plan for completing the task",
                "assigned_agent": "",
                "complexity": "medium",
                "dependencies": ["research"]
            },
            "specialist": {
                "description": "Apply domain expertise to solve core problems",
                "assigned_agent": "",
                "complexity": "high",
                "dependencies": ["planner"]
            },
            "executor": {
                "description": "Implement the solution based on the plan",
                "assigned_agent": "",
                "complexity": "high",
                "dependencies": ["specialist"]
            },
            "reviewer": {
                "description": "Review and validate the implemented solution",
                "assigned_agent": "",
                "complexity": "medium",
                "dependencies": ["executor"]
            }
        }
        
        # Create subtasks based on available agent roles
        subtasks = []
        for agent_id, agent in agent_team.items():
            # Get the base role (before any specialization)
            base_role = agent.role.split("_")[0] if "_" in agent.role else agent.role
            
            if base_role in role_subtasks:
                subtask = role_subtasks[base_role].copy()
                subtask["assigned_agent"] = agent_id
                subtasks.append(subtask)
        
        # Sort subtasks based on dependencies
        return subtasks
    
    def _execute_scheduled_tasks(
        self, 
        task_schedule: List[Dict[str, Any]], 
        agent_team: Dict[str, BaseAgent],
        task_description: str
    ) -> Dict[str, Any]:
        """
        Execute the scheduled tasks with the agent team.
        
        Args:
            task_schedule: List of scheduled tasks to execute
            agent_team: Dictionary of available agents
            task_description: Original task description
            
        Returns:
            Dictionary mapping subtask IDs to execution results
        """
        execution_results = {}
        conversation_history = []
        
        # Add the initial task description to the conversation history
        conversation_history.append(
            HumanMessage(content=f"Main task: {task_description}")
        )
        
        # Execute each task in the schedule
        for task_step in task_schedule:
            step_id = task_step.get("step_id", "unknown")
            subtasks = task_step.get("subtasks", [])
            
            logger.info(f"Executing step {step_id} with {len(subtasks)} subtasks")
            
            # Process each subtask in this step (these can be executed in parallel)
            for subtask in subtasks:
                subtask_id = subtask.get("id", "unknown")
                
                # MODIFICATION: Vérifier plusieurs champs pour trouver l'agent assigné
                agent_id = None
                
                # Champs possibles pour l'assignation d'agent
                possible_fields = ["assigned_agent", "required_role", "required_skills_or_role"]
                
                # Vérifier chaque champ possible
                for field in possible_fields:
                    if field in subtask and subtask[field]:
                        potential_id = subtask[field]
                        
                        # Vérifier si c'est directement un ID d'agent
                        if potential_id in agent_team:
                            agent_id = potential_id
                            break
                        
                        # Sinon, chercher un agent par son rôle
                        for ag_id, agent in agent_team.items():
                            if agent.role == potential_id:
                                agent_id = ag_id
                                break
                        
                        # Si on a trouvé un agent, sortir de la boucle
                        if agent_id:
                            break
                
                description = subtask.get("description", "No description provided")
                
                # Skip if no agent is assigned
                if not agent_id or agent_id not in agent_team:
                    logger.warning(f"No valid agent assigned for subtask {subtask_id}, skipping")
                    continue
                
                # Get the assigned agent
                agent = agent_team[agent_id]
                
                # Prepare the context for this subtask
                context = self._prepare_subtask_context(
                    subtask, 
                    execution_results, 
                    conversation_history,
                    task_description
                )
                
                logger.info(f"Executing subtask {subtask_id} with agent {agent_id}")
                
                # Execute the subtask with the agent
                try:
                    result = agent.execute_task(context)
                    
                    # Store the result
                    execution_results[subtask_id] = {
                        "subtask": subtask,
                        "agent_id": agent_id,
                        "output": result.get("output", ""),
                        "status": "completed",
                        "metadata": result.get("metadata", {})
                    }
                    
                    # Add to conversation history
                    conversation_history.append(
                        SystemMessage(content=f"Agent {agent_id} completed subtask: {description}")
                    )
                    conversation_history.append(
                        AIMessage(content=result.get("output", ""))
                    )
                    
                    logger.debug(f"Subtask {subtask_id} completed successfully")
                    
                except Exception as e:
                    logger.error(f"Error executing subtask {subtask_id}: {str(e)}")
                    
                    # Store the error result
                    execution_results[subtask_id] = {
                        "subtask": subtask,
                        "agent_id": agent_id,
                        "output": f"Error: {str(e)}",
                        "status": "failed",
                        "metadata": {"error": str(e)}
                    }
                    
                    # Add to conversation history
                    conversation_history.append(
                        SystemMessage(content=f"Agent {agent_id} failed subtask: {description}")
                    )
                    conversation_history.append(
                        AIMessage(content=f"Error: {str(e)}")
                    )
            
            # Brief pause between steps to avoid rate limiting
            time.sleep(0.5)
        
        # Store the execution results in the knowledge repository if available
        if self.knowledge_repository:
            self.knowledge_repository.store_execution_results(
                task_description, 
                execution_results,
                conversation_history
            )
        
        return {
            "execution_results": execution_results,
            "conversation_history": conversation_history
        }
    
    def _prepare_subtask_context(
        self, 
        subtask: Dict[str, Any], 
        results_so_far: Dict[str, Any],
        conversation_history: List[Any],
        task_description: str
    ) -> str:
        """
        Prepare the context for a subtask execution.
        
        Args:
            subtask: The subtask specification
            results_so_far: Results from previously executed subtasks
            conversation_history: History of the conversation so far
            task_description: Original task description
            
        Returns:
            Context string for the agent
        """
        # Start with the subtask description
        context_parts = [
            f"Main task: {task_description}",
            f"Your subtask: {subtask.get('description', 'No description provided')}"
        ]
        
        # Add dependency results if any
        dependencies = subtask.get("dependencies", [])
        if dependencies:
            context_parts.append("\nRelevant information from dependent tasks:")
            
            for dep_id in dependencies:
                if dep_id in results_so_far:
                    dep_result = results_so_far[dep_id]
                    agent_id = dep_result.get("agent_id", "unknown")
                    output = dep_result.get("output", "No output")
                    
                    context_parts.append(f"\nFrom {agent_id}:")
                    context_parts.append(output)
        
        # Add a request for specific output
        context_parts.append("\nPlease complete this subtask and provide your results.")
        
        return "\n\n".join(context_parts)
    
    def _synthesize_results(
        self, 
        task_description: str, 
        execution_data: Dict[str, Any], 
        agent_team: Dict[str, BaseAgent]
    ) -> Dict[str, Any]:
        """
        Synthesize the execution results into a coherent final result.
        
        Args:
            task_description: Original task description
            execution_data: Data from the task execution
            agent_team: Dictionary of available agents
            
        Returns:
            Synthesized results
        """
        # Extract execution results and conversation history
        execution_results = execution_data.get("execution_results", {})
        conversation_history = execution_data.get("conversation_history", [])
        
        # Check if we have a reviewer agent in the team
        reviewer_agent = None
        for agent_id, agent in agent_team.items():
            if agent.role.startswith("reviewer"):
                reviewer_agent = agent
                break
        
        # If we have a reviewer, use it to synthesize results
        if reviewer_agent:
            logger.debug("Using reviewer agent to synthesize results")
            
            # Create a summary of all results
            results_summary = []
            for subtask_id, result in execution_results.items():
                agent_id = result.get("agent_id", "unknown")
                subtask_desc = result.get("subtask", {}).get("description", "Unknown subtask")
                status = result.get("status", "unknown")
                output = result.get("output", "No output")
                
                results_summary.append(f"Subtask: {subtask_desc}")
                results_summary.append(f"Executed by: {agent_id}")
                results_summary.append(f"Status: {status}")
                results_summary.append(f"Output: {output}\n")
            
            # Create a prompt for the reviewer
            review_prompt = f"""
            Task Description: {task_description}
            
            Below are the results from all team members who worked on this task.
            Please review these results and create:
            1. A comprehensive summary of the work done
            2. An assessment of the quality and completeness
            3. A final deliverable that combines the best parts of everyone's work
            
            Results:
            {''.join(results_summary)}
            
            Your synthesis should be well-structured and ready for delivery to the user.
            """
            
            # Ask the reviewer to synthesize the results
            review_result = reviewer_agent.execute_task(review_prompt)
            synthesis = review_result.get("output", "")
            
        else:
            # No reviewer, use LLM to synthesize results
            logger.debug("No reviewer agent available, using LLM for synthesis")
            
            # Create the prompt for result synthesis
            prompt = ChatPromptTemplate.from_template(RESULT_SYNTHESIS_PROMPT)
            
            # Format the prompt with task description and results
            results_text = ""
            for subtask_id, result in execution_results.items():
                agent_id = result.get("agent_id", "unknown")
                subtask_desc = result.get("subtask", {}).get("description", "Unknown subtask")
                status = result.get("status", "unknown")
                output = result.get("output", "No output")
                
                results_text += f"Subtask: {subtask_desc}\n"
                results_text += f"Executed by: {agent_id}\n"
                results_text += f"Status: {status}\n"
                results_text += f"Output: {output}\n\n"
            
            formatted_prompt = prompt.format(
                task_description=task_description,
                execution_results=results_text
            )
            
            # Get response from the LLM
            response = self.coordination_llm.invoke(formatted_prompt)
            synthesis = response.content
        
        # Extract individual agent contributions
        agent_contributions = {}
        for subtask_id, result in execution_results.items():
            agent_id = result.get("agent_id", "unknown")
            if agent_id not in agent_contributions:
                agent_contributions[agent_id] = []
            
            subtask_desc = result.get("subtask", {}).get("description", "Unknown subtask")
            output = result.get("output", "No output")
            
            agent_contributions[agent_id].append(f"Subtask: {subtask_desc}\nOutput: {output}")
        
        # Combine contributions for each agent
        for agent_id, contributions in agent_contributions.items():
            agent_contributions[agent_id] = "\n\n".join(contributions)
        
        # Check for any output files
        output_files = []
        for result in execution_results.values():
            metadata = result.get("metadata", {})
            if "output_files" in metadata and metadata["output_files"]:
                output_files.extend(metadata["output_files"])
        
        # Create the final result structure
        final_results = {
            "summary": synthesis,
            "agent_contributions": agent_contributions,
            "execution_results": execution_results,
            "output_files": output_files
        }
        
        return final_results
    
    def get_agent_contributions(self, execution_results: Dict[str, Any]) -> Dict[str, str]:
        """
        Extract contributions from each agent from the execution results.
        
        Args:
            execution_results: Results from task execution
            
        Returns:
            Dictionary mapping agent IDs to their contributions
        """
        agent_contributions = {}
        
        for subtask_id, result in execution_results.items():
            agent_id = result.get("agent_id", "unknown")
            if agent_id not in agent_contributions:
                agent_contributions[agent_id] = []
            
            subtask_desc = result.get("subtask", {}).get("description", "Unknown subtask")
            output = result.get("output", "No output")
            
            agent_contributions[agent_id].append(f"Subtask: {subtask_desc}\nOutput: {output}")
        
        # Combine contributions for each agent
        for agent_id, contributions in agent_contributions.items():
            agent_contributions[agent_id] = "\n\n".join(contributions)
        
        return agent_contributions
--------------------------------------------------------------------------------
        agent_factory.py

Content of C:/AI PROJECT/My Langchain Crew 1\core\agent_factory.py:
"""
Agent Factory Module

This module is responsible for creating specialized AI agents with different capabilities
based on the required roles and expertise. It serves as a factory that can instantiate
various types of agents with appropriate configurations.
"""

import logging
from typing import Dict, Any, List, Optional, Type

from langchain.agents import AgentExecutor, create_react_agent, create_tool_calling_agent
from langchain.agents.format_scratchpad import format_to_openai_functions
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.tools import BaseTool
from langchain_openai import ChatOpenAI

from agents.base_agent import BaseAgent
from agents.research_agent import ResearchAgent
from agents.specialist_agent import SpecialistAgent
from agents.planner_agent import PlannerAgent
from agents.executor_agent import ExecutorAgent
from agents.reviewer_agent import ReviewerAgent
from utils.prompt_templates import get_prompt_template_for_role
from core.knowledge_repository import KnowledgeRepository

logger = logging.getLogger(__name__)

class AgentFactory:
    """
    Factory class for creating different types of AI agents.
    """
    
    def __init__(self, config: Dict[str, Any], knowledge_repository: Optional[KnowledgeRepository] = None):
        """
        Initialize the agent factory.
        
        Args:
            config: Configuration dictionary with agent settings
            knowledge_repository: Knowledge repository for agents to access shared information
        """
        self.config = config
        self.knowledge_repository = knowledge_repository
        self.default_model = config.get("default_model", "gpt-4o")
        self.research_model = config.get("research_model", "gpt-4o")
        self.specialist_model = config.get("specialist_model", "gpt-4o")
        self.planner_model = config.get("planner_model", "gpt-4o")
        self.executor_model = config.get("executor_model", "gpt-4o")
        self.reviewer_model = config.get("reviewer_model", "gpt-4o")
        
        logger.debug(f"Initialized AgentFactory with models: default={self.default_model}")
    
    def _get_agent_class(self, role: str) -> Type[BaseAgent]:
        """
        Map role to agent class.
        
        Args:
            role: The role name for the agent
            
        Returns:
            The appropriate agent class
        """
        role_to_class = {
            "research": ResearchAgent,
            "specialist": SpecialistAgent,
            "planner": PlannerAgent,
            "executor": ExecutorAgent,
            "reviewer": ReviewerAgent,
        }
        
        # Get the base role (before any specialization)
        base_role = role.split("_")[0] if "_" in role else role
        
        return role_to_class.get(base_role.lower(), SpecialistAgent)
    
    def _get_model_for_role(self, role: str) -> str:
        """
        Get the appropriate model for a given role.
        
        Args:
            role: The role name for the agent
            
        Returns:
            Model name to use for this agent
        """
        role_to_model = {
            "research": self.research_model,
            "specialist": self.specialist_model,
            "planner": self.planner_model,
            "executor": self.executor_model,
            "reviewer": self.reviewer_model,
        }
        
        # Get the base role (before any specialization)
        base_role = role.split("_")[0] if "_" in role else role
        
        return role_to_model.get(base_role.lower(), self.default_model)
    
    def _create_llm(self, model_name: str, temperature: float = 0.1) -> ChatOpenAI:
        """
        Create a language model instance.
        
        Args:
            model_name: Name of the model to use
            temperature: Temperature setting for generation (0.0 to 1.0)
            
        Returns:
            Initialized language model
        """
        return ChatOpenAI(
            model=model_name,
            temperature=temperature
        )
    
    def _create_agent_executor(
        self, 
        role: str, 
        tools: List[BaseTool], 
        system_prompt: str,
        model_name: Optional[str] = None,
        memory: Optional[Any] = None
    ) -> AgentExecutor:
        """
        Create an agent executor with the appropriate configuration.
        
        Args:
            role: The role of the agent
            tools: List of tools available to the agent
            system_prompt: System prompt for the agent
            model_name: Optional model name override
            memory: Optional memory for the agent
            
        Returns:
            Configured AgentExecutor
        """
        # Determine which model to use
        model_name = model_name or self._get_model_for_role(role)
        
        # Create the language model
        llm = self._create_llm(model_name)
        
        # Create the prompt template
        prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            ("human", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ])
        
        # Create agent based on the tools provided
        if tools:
            agent = create_tool_calling_agent(llm, tools, prompt)
        else:
            # Create a basic agent without tools if none provided
            agent = create_react_agent(llm, [], prompt)
        
        # Create and return the agent executor
        return AgentExecutor.from_agent_and_tools(
            agent=agent,
            tools=tools,
            memory=memory,
            verbose=self.config.get("verbose", True),
            handle_parsing_errors=True,
            max_iterations=self.config.get("max_iterations", 15),
        )
    
    def create_agent(
        self, 
        role: str, 
        specialization: Optional[str] = None,
        tools: Optional[List[BaseTool]] = None,
        background_info: Optional[str] = None,
        memory: Optional[Any] = None
    ) -> BaseAgent:
        """
        Create an agent with the specified role and specialization.
        
        Args:
            role: The basic role of the agent (research, specialist, planner, etc.)
            specialization: Optional specialization within the role (e.g., "salesforce_developer")
            tools: Optional list of tools for the agent to use
            background_info: Optional background information to include in the agent's context
            memory: Optional memory component
            
        Returns:
            An initialized agent instance
        """
        # Ensure tools are always provided
        if tools is None or len(tools) == 0:
            # Create a default tool if none provided
            from langchain.tools.base import Tool
            tools = [
                Tool(
                    name="empty_tool",
                    description="A placeholder tool that does nothing",
                    func=lambda x: "This tool does nothing"
                )
            ]
        
        # Combine role and specialization if provided
        full_role = f"{role}_{specialization}" if specialization else role
        
        # Get appropriate agent class
        agent_class = self._get_agent_class(role)
        
        # Get appropriate model name
        model_name = self._get_model_for_role(role)
        
        # Get role-specific prompt template
        system_prompt = get_prompt_template_for_role(full_role)
        
        # Inject background information if provided
        if background_info:
            system_prompt = f"{system_prompt}\n\nBackground Information:\n{background_info}"
        
        # Create tools list if not provided
        tools = tools or []
        
        # Create the agent executor
        agent_executor = self._create_agent_executor(
            role=full_role,
            tools=tools,
            system_prompt=system_prompt,
            model_name=model_name,
            memory=memory
        )
        
        # Initialize and return the agent
        agent = agent_class(
            agent_executor=agent_executor,
            role=full_role,
            config=self.config,
            knowledge_repository=self.knowledge_repository
        )
        
        logger.info(f"Created agent with role: {full_role}")
        return agent

    def create_specialized_agent(
        self,
        agent_spec: Dict[str, Any],
        tools: Optional[List[BaseTool]] = None,
        memory: Optional[Any] = None
    ) -> BaseAgent:
        """
        Create an agent based on a specification dictionary.
        
        Args:
            agent_spec: Dictionary with agent specifications including role, specialization, etc.
            tools: Optional tools for the agent
            memory: Optional memory for the agent
            
        Returns:
            An initialized agent instance
        """
        role = agent_spec.get("role", "specialist")
        specialization = agent_spec.get("specialization")
        background_info = agent_spec.get("background_info")
        
        # Merge any tools provided in the spec with those passed to the method
        agent_tools = agent_spec.get("tools", [])
        if tools:
            agent_tools.extend(tools)
        
        return self.create_agent(
            role=role,
            specialization=specialization,
            tools=agent_tools,
            background_info=background_info,
            memory=memory
        )
--------------------------------------------------------------------------------
        knowledge_repository.py

Content of C:/AI PROJECT/My Langchain Crew 1\core\knowledge_repository.py:
"""
Knowledge Repository Module

This module is responsible for storing, retrieving, and managing shared knowledge
across agents. It provides a centralized repository for information that can be
accessed and updated by all agents in the team.
"""

import logging
import os
import json
import time
from typing import Dict, Any, List, Optional, Union
from datetime import datetime

from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_core.documents import Document

logger = logging.getLogger(__name__)

class KnowledgeRepository:
    """
    Repository for storing and retrieving knowledge shared across agents.
    Provides vector store capabilities for semantic search and structured
    storage for team compositions, execution results, and other data.
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        Initialize the knowledge repository.
        
        Args:
            config: Configuration dictionary with repository settings
        """
        self.config = config
        self.data_dir = config.get("data_dir", "data")
        self.embedding_model = config.get("embedding_model", "text-embedding-3-small")
        self.chunk_size = config.get("chunk_size", 1000)
        self.chunk_overlap = config.get("chunk_overlap", 100)
        
        # Initialize structured storage
        self._structured_data = {
            "team_compositions": {},
            "execution_results": {},
            "agent_contributions": {},
            "task_schedules": {},
            "external_knowledge": {},
        }
        
        # Create data directory if it doesn't exist
        os.makedirs(self.data_dir, exist_ok=True)
        
        # Load any existing data
        self._load_structured_data()
        
        # Initialize vector store for semantic search
        self._init_vector_store()
        
        logger.debug(f"Initialized KnowledgeRepository with embedding model: {self.embedding_model}")
    
    def _init_vector_store(self):
        """Initialize the vector store for semantic search."""
        vector_store_dir = os.path.join(self.data_dir, "vector_store")
        os.makedirs(vector_store_dir, exist_ok=True)
        
        # Initialize embedding model
        try:
            self.embeddings = OpenAIEmbeddings(model=self.embedding_model)
            
            # Check if vector store exists
            if os.path.exists(os.path.join(vector_store_dir, "chroma.sqlite3")):
                logger.debug("Loading existing vector store")
                self.vector_store = Chroma(
                    persist_directory=vector_store_dir,
                    embedding_function=self.embeddings
                )
            else:
                logger.debug("Creating new vector store")
                self.vector_store = Chroma(
                    persist_directory=vector_store_dir,
                    embedding_function=self.embeddings
                )
                
            # Create text splitter
            self.text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=self.chunk_size,
                chunk_overlap=self.chunk_overlap
            )
            
            self.vector_store_initialized = True
            logger.info("Vector store initialized successfully")
            
        except Exception as e:
            logger.error(f"Error initializing vector store: {str(e)}")
            self.vector_store_initialized = False
    
    def _load_structured_data(self):
        """Load structured data from disk if available."""
        structured_data_path = os.path.join(self.data_dir, "structured_data.json")
        
        if os.path.exists(structured_data_path):
            try:
                with open(structured_data_path, 'r') as f:
                    loaded_data = json.load(f)
                    
                    # Update storage with loaded data
                    for key, value in loaded_data.items():
                        if key in self._structured_data:
                            self._structured_data[key] = value
                
                logger.info("Loaded structured data from disk")
            except Exception as e:
                logger.error(f"Error loading structured data: {str(e)}")
    
    def _save_structured_data(self):
        """Save structured data to disk."""
        structured_data_path = os.path.join(self.data_dir, "structured_data.json")
        
        try:
            with open(structured_data_path, 'w') as f:
                json.dump(self._structured_data, f, indent=2)
                
            logger.debug("Saved structured data to disk")
        except Exception as e:
            logger.error(f"Error saving structured data: {str(e)}")
    
    def store_team_composition(self, task_description: str, team_composition: Dict[str, Any]):
        """
        Store team composition information in both structured_data and teams.json
        """
        # Generate a task ID based on timestamp and task description
        task_id = f"team_{int(time.time())}_{hash(task_description) % 10000}"
        
        # Add timestamp
        team_composition["timestamp"] = datetime.now().isoformat()
        team_composition["task_description"] = task_description
        
        # Store in structured data (existing functionality)
        self._structured_data["team_compositions"][task_id] = team_composition
        
        # Also store in teams.json
        self._save_team_to_teams_file(task_id, team_composition)
        
        # Save to disk
        self._save_structured_data()
        
        logger.info(f"Stored team composition for team ID: {task_id}")
        
        # Return the team ID for reference
        return task_id

    def _save_team_to_teams_file(self, team_id: str, team_composition: Dict[str, Any]):
        """
        Save a team composition to the dedicated teams.json file
        """
        teams_file = os.path.join(self.data_dir, "teams.json")
        
        # Load existing teams
        teams = {}
        if os.path.exists(teams_file):
            try:
                with open(teams_file, 'r') as f:
                    teams = json.load(f)
            except json.JSONDecodeError:
                # If file exists but is invalid, start with empty dict
                teams = {}
        
        # Add the new team
        teams[team_id] = {
            "id": team_id,
            "name": team_composition.get("team_name", "Unnamed Team"),
            "description": team_composition.get("team_goal", "No description"),
            "created_at": team_composition.get("timestamp", datetime.now().isoformat()),
            "task_description": team_composition.get("task_description", ""),
            "agent_specs": team_composition.get("agent_specs", []),
            "additional_context": team_composition.get("additional_context", "")
        }
        
        # Save to file
        with open(teams_file, 'w') as f:
            json.dump(teams, f, indent=2)

    def get_all_teams(self) -> Dict[str, Any]:
        """
        Get all teams from the teams.json file
        """
        teams_file = os.path.join(self.data_dir, "teams.json")
        
        if not os.path.exists(teams_file):
            return {}
        
        try:
            with open(teams_file, 'r') as f:
                return json.load(f)
        except json.JSONDecodeError:
            logger.error(f"Error reading teams file: {teams_file}")
            return {}

    def get_team(self, team_id: str) -> Optional[Dict[str, Any]]:
        """
        Get a team by ID from the teams.json file
        """
        teams = self.get_all_teams()
        return teams.get(team_id)

    def store_execution_results(
        self, 
        task_description: str, 
        execution_results: Dict[str, Any],
        conversation_history: Optional[List[Any]] = None
    ):
        """
        Store execution results from a task.
        
        Args:
            task_description: The task description
            execution_results: The execution results data
            conversation_history: Optional conversation history
        """
        # Generate a task ID based on timestamp and task description
        task_id = f"execution_{int(time.time())}_{hash(task_description) % 10000}"
        
        # Create storage object
        storage_obj = {
            "timestamp": datetime.now().isoformat(),
            "task_description": task_description,
            "execution_results": execution_results
        }
        
        # Add conversation history if provided
        if conversation_history:
            # Convert conversation history to serializable format
            serializable_history = []
            for message in conversation_history:
                if hasattr(message, "to_dict"):
                    serializable_history.append(message.to_dict())
                else:
                    serializable_history.append({
                        "type": type(message).__name__,
                        "content": str(message)
                    })
            
            storage_obj["conversation_history"] = serializable_history
        
        # Store in structured data
        self._structured_data["execution_results"][task_id] = storage_obj
        
        # Save to disk
        self._save_structured_data()
        
        logger.info(f"Stored execution results for task ID: {task_id}")
        
        # Also add to vector store for semantic search
        if self.vector_store_initialized:
            # Extract text content from execution results
            content_parts = [f"Execution Results for: {task_description}"]
            
            # Add each result output
            for subtask_id, result in execution_results.items():
                subtask_desc = result.get("subtask", {}).get("description", "Unknown subtask")
                agent_id = result.get("agent_id", "unknown")
                output = result.get("output", "No output")
                
                content_parts.append(f"Subtask: {subtask_desc}")
                content_parts.append(f"Agent: {agent_id}")
                content_parts.append(f"Output: {output}")
            
            self._add_to_vector_store(
                text="\n\n".join(content_parts),
                metadata={
                    "type": "execution_results",
                    "task_id": task_id,
                    "timestamp": storage_obj["timestamp"]
                }
            )
    
    def store_external_knowledge(
        self, 
        source: str, 
        content: str, 
        metadata: Optional[Dict[str, Any]] = None
    ):
        """
        Store external knowledge such as web search results or documentation.
        
        Args:
            source: Source of the knowledge (e.g., URL, document name)
            content: The content to store
            metadata: Additional metadata about the content
        """
        # Generate an ID for this knowledge
        knowledge_id = f"knowledge_{int(time.time())}_{hash(source) % 10000}"
        
        # Create storage object
        metadata = metadata or {}
        storage_obj = {
            "timestamp": datetime.now().isoformat(),
            "source": source,
            "content": content,
            "metadata": metadata
        }
        
        # Store in structured data
        self._structured_data["external_knowledge"][knowledge_id] = storage_obj
        
        # Save to disk
        self._save_structured_data()
        
        logger.info(f"Stored external knowledge with ID: {knowledge_id}")
        
        # Also add to vector store for semantic search
        if self.vector_store_initialized:
            self._add_to_vector_store(
                text=f"Knowledge from {source}:\n{content}",
                metadata={
                    "type": "external_knowledge",
                    "knowledge_id": knowledge_id,
                    "source": source,
                    "timestamp": storage_obj["timestamp"],
                    **metadata
                }
            )
    
    def _add_to_vector_store(self, text: str, metadata: Dict[str, Any]):
        """
        Add text to the vector store with metadata.
        
        Args:
            text: The text content to add
            metadata: Metadata about the content
        """
        if not self.vector_store_initialized:
            logger.warning("Vector store not initialized, skipping addition")
            return
        
        try:
            # Split text into chunks
            docs = self.text_splitter.create_documents([text], [metadata])
            
            # Add to vector store
            self.vector_store.add_documents(docs)
            
            # Persist the vector store
            if hasattr(self.vector_store, "persist"):
                self.vector_store.persist()
                
            logger.debug(f"Added content to vector store with metadata: {metadata.get('type')}")
            
        except Exception as e:
            logger.error(f"Error adding to vector store: {str(e)}")
    
    def search_knowledge(
        self, 
        query: str, 
        k: int = 5, 
        filter_metadata: Optional[Dict[str, Any]] = None
    ) -> List[Dict[str, Any]]:
        """
        Search the knowledge repository for relevant information.
        
        Args:
            query: The search query
            k: Number of results to return
            filter_metadata: Optional metadata filters
            
        Returns:
            List of search results with content and metadata
        """
        if not self.vector_store_initialized:
            logger.warning("Vector store not initialized, returning empty results")
            return []
        
        try:
            # Search the vector store
            results = self.vector_store.similarity_search(
                query=query,
                k=k,
                filter=filter_metadata
            )
            
            # Format results
            formatted_results = []
            for doc in results:
                formatted_results.append({
                    "content": doc.page_content,
                    "metadata": doc.metadata
                })
                
            logger.debug(f"Search for '{query}' returned {len(formatted_results)} results")
            return formatted_results
            
        except Exception as e:
            logger.error(f"Error searching vector store: {str(e)}")
            return []
    
    def get_relevant_knowledge(
        self, 
        task_description: str, 
        k: int = 5
    ) -> List[Dict[str, Any]]:
        """
        Get knowledge relevant to a specific task.
        
        Args:
            task_description: Description of the task
            k: Number of results to return
            
        Returns:
            List of relevant knowledge items
        """
        return self.search_knowledge(query=task_description, k=k)
    
    def get_agent_knowledge(
        self, 
        agent_role: str, 
        specialization: Optional[str] = None, 
        k: int = 5
    ) -> List[Dict[str, Any]]:
        """
        Get knowledge relevant to a specific agent role and specialization.
        
        Args:
            agent_role: The agent's role
            specialization: Optional specialization
            k: Number of results to return
            
        Returns:
            List of relevant knowledge items
        """
        query = f"Knowledge for {agent_role}"
        if specialization:
            query += f" specialized in {specialization}"
            
        return self.search_knowledge(query=query, k=k)
    
    def get_team_composition(self, task_id: str) -> Optional[Dict[str, Any]]:
        """
        Get a specific team composition by task ID.
        
        Args:
            task_id: The task ID
            
        Returns:
            Team composition dictionary or None if not found
        """
        return self._structured_data["team_compositions"].get(task_id)
    
    def get_execution_results(self, task_id: str) -> Optional[Dict[str, Any]]:
        """
        Get execution results for a specific task.
        
        Args:
            task_id: The task ID
            
        Returns:
            Execution results dictionary or None if not found
        """
        return self._structured_data["execution_results"].get(task_id)
    
    def get_external_knowledge(self, knowledge_id: str) -> Optional[Dict[str, Any]]:
        """
        Get specific external knowledge by ID.
        
        Args:
            knowledge_id: The knowledge ID
            
        Returns:
            Knowledge dictionary or None if not found
        """
        return self._structured_data["external_knowledge"].get(knowledge_id)
    
    def list_recent_tasks(self, limit: int = 10) -> List[Dict[str, Any]]:
        """
        List recent tasks with their descriptions and IDs.
        
        Args:
            limit: Maximum number of tasks to return
            
        Returns:
            List of recent tasks with descriptions and IDs
        """
        # Collect tasks from team compositions and execution results
        tasks = []
        
        # Add tasks from team compositions
        for task_id, composition in self._structured_data["team_compositions"].items():
            tasks.append({
                "task_id": task_id,
                "description": composition.get("task_description", "Unknown"),
                "timestamp": composition.get("timestamp", ""),
                "type": "team_composition"
            })
        
        # Add tasks from execution results
        for task_id, results in self._structured_data["execution_results"].items():
            tasks.append({
                "task_id": task_id,
                "description": results.get("task_description", "Unknown"),
                "timestamp": results.get("timestamp", ""),
                "type": "execution_results"
            })
        
        # Sort by timestamp (recent first) and limit
        tasks.sort(key=lambda x: x["timestamp"], reverse=True)
        return tasks[:limit]
    
    def clear(self):
        """Clear all data in the repository."""
        # Clear structured data
        self._structured_data = {
            "team_compositions": {},
            "execution_results": {},
            "agent_contributions": {},
            "task_schedules": {},
            "external_knowledge": {},
        }
        
        # Save empty data to disk
        self._save_structured_data()
        
        # Clear vector store if initialized
        if self.vector_store_initialized:
            try:
                self.vector_store = Chroma(
                    persist_directory=os.path.join(self.data_dir, "vector_store"),
                    embedding_function=self.embeddings
                )
                self.vector_store.delete_collection()
                self.vector_store = Chroma(
                    persist_directory=os.path.join(self.data_dir, "vector_store"),
                    embedding_function=self.embeddings
                )
                logger.info("Vector store cleared")
            except Exception as e:
                logger.error(f"Error clearing vector store: {str(e)}")
        
        logger.info("Knowledge repository cleared")
--------------------------------------------------------------------------------
        task_scheduler.py

Content of C:/AI PROJECT/My Langchain Crew 1\core\task_scheduler.py:
"""
Task Scheduler Module

This module is responsible for scheduling and organizing tasks for execution by the agent team.
It handles dependency resolution, parallelization opportunities, and creates an optimal
execution plan for completing tasks efficiently.
"""

import logging
import uuid
from typing import Dict, Any, List, Optional, Set, Tuple
from collections import defaultdict, deque

logger = logging.getLogger(__name__)

class TaskScheduler:
    """
    Scheduler for optimizing task execution across a team of agents.
    Handles dependencies between tasks and identifies parallelization opportunities.
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        Initialize the task scheduler.
        
        Args:
            config: Configuration dictionary with scheduler settings
        """
        self.config = config
        self.max_parallel_tasks = config.get("max_parallel_tasks", 3)
        self.prioritize_by_complexity = config.get("prioritize_by_complexity", True)
        
        logger.debug(f"Initialized TaskScheduler with max_parallel_tasks: {self.max_parallel_tasks}")
    
    def create_schedule(
        self, 
        subtasks: List[Dict[str, Any]], 
        available_agents: List[str]
    ) -> List[Dict[str, Any]]:
        """
        Create an execution schedule based on subtasks and available agents.
        
        Args:
            subtasks: List of subtask specifications with dependencies
            available_agents: List of available agent IDs
            
        Returns:
            Scheduled execution plan as a list of steps
        """
        logger.info(f"Creating schedule for {len(subtasks)} subtasks with {len(available_agents)} agents")
        
        # Step 1: Validate and normalize subtasks
        normalized_subtasks = self._normalize_subtasks(subtasks)
        
        # Step 2: Build dependency graph
        dependency_graph, reverse_dependency_graph = self._build_dependency_graphs(normalized_subtasks)
        
        # Step 3: Validate for circular dependencies
        if self._has_circular_dependencies(dependency_graph):
            logger.warning("Circular dependencies detected in subtasks, resolving dependencies")
            dependency_graph, reverse_dependency_graph = self._resolve_circular_dependencies(
                dependency_graph, reverse_dependency_graph
            )
        
        # Step 4: Create execution schedule
        schedule = self._create_execution_plan(
            normalized_subtasks, 
            dependency_graph, 
            reverse_dependency_graph,
            available_agents
        )
        
        logger.info(f"Created execution schedule with {len(schedule)} steps")
        return schedule
    
    def _normalize_subtasks(self, subtasks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Validate and normalize subtask specifications.
        
        Args:
            subtasks: List of subtask specifications
            
        Returns:
            Normalized subtask specifications
        """
        normalized = []
        
        # Keep track of existing IDs to avoid duplicates
        existing_ids = set()
        
        for i, subtask in enumerate(subtasks):
            # Create a new subtask dictionary with normalized fields
            normalized_subtask = {}
            
            # Ensure each subtask has an ID
            if "id" not in subtask or not subtask["id"]:
                subtask_id = f"subtask_{i}_{str(uuid.uuid4())[:8]}"
            else:
                subtask_id = subtask["id"]
                
            # Ensure ID is unique
            if subtask_id in existing_ids:
                subtask_id = f"{subtask_id}_{str(uuid.uuid4())[:8]}"
            
            existing_ids.add(subtask_id)
            normalized_subtask["id"] = subtask_id
            
            # Copy description
            normalized_subtask["description"] = subtask.get("description", f"Subtask {i}")
            
            # Normalize assigned agent
            normalized_subtask["assigned_agent"] = subtask.get("assigned_agent", "")
            
            # Normalize dependencies
            dependencies = subtask.get("dependencies", [])
            if isinstance(dependencies, str):
                dependencies = [dependencies]
            normalized_subtask["dependencies"] = dependencies
            
            # Normalize complexity
            complexity_map = {"low": 1, "medium": 2, "high": 3}
            if isinstance(subtask.get("complexity"), str):
                normalized_subtask["complexity"] = complexity_map.get(
                    subtask.get("complexity", "medium").lower(), 2
                )
            else:
                normalized_subtask["complexity"] = subtask.get("complexity", 2)
            
            # Copy any additional fields
            for key, value in subtask.items():
                if key not in normalized_subtask:
                    normalized_subtask[key] = value
            
            normalized.append(normalized_subtask)
        
        return normalized
    
    def _build_dependency_graphs(
        self, 
        subtasks: List[Dict[str, Any]]
    ) -> Tuple[Dict[str, List[str]], Dict[str, List[str]]]:
        """
        Build dependency and reverse dependency graphs.
        
        Args:
            subtasks: List of normalized subtask specifications
            
        Returns:
            Tuple of (dependency_graph, reverse_dependency_graph)
        """
        # Map of subtask IDs
        id_to_subtask = {subtask["id"]: subtask for subtask in subtasks}
        
        # Initialize graphs
        dependency_graph = defaultdict(list)
        reverse_dependency_graph = defaultdict(list)
        
        # Build graphs
        for subtask in subtasks:
            subtask_id = subtask["id"]
            
            # Process dependencies
            for dep_id in subtask.get("dependencies", []):
                # Skip if dependency doesn't exist
                if dep_id not in id_to_subtask:
                    logger.warning(f"Dependency {dep_id} for subtask {subtask_id} not found, skipping")
                    continue
                
                # Add to dependency graph
                dependency_graph[subtask_id].append(dep_id)
                
                # Add to reverse dependency graph
                reverse_dependency_graph[dep_id].append(subtask_id)
        
        return dict(dependency_graph), dict(reverse_dependency_graph)
    
    def _has_circular_dependencies(self, dependency_graph: Dict[str, List[str]]) -> bool:
        """
        Check if the dependency graph has circular dependencies.
        
        Args:
            dependency_graph: Dependency graph
            
        Returns:
            True if circular dependencies exist, False otherwise
        """
        # Keep track of visited and recursion stack
        visited = set()
        rec_stack = set()
        
        def is_cyclic(node):
            visited.add(node)
            rec_stack.add(node)
            
            # Visit all neighbors
            for neighbor in dependency_graph.get(node, []):
                if neighbor not in visited:
                    if is_cyclic(neighbor):
                        return True
                elif neighbor in rec_stack:
                    return True
            
            rec_stack.remove(node)
            return False
        
        # Check all nodes
        for node in dependency_graph:
            if node not in visited:
                if is_cyclic(node):
                    return True
        
        return False
    
    def _resolve_circular_dependencies(
        self, 
        dependency_graph: Dict[str, List[str]], 
        reverse_dependency_graph: Dict[str, List[str]]
    ) -> Tuple[Dict[str, List[str]], Dict[str, List[str]]]:
        """
        Resolve circular dependencies by removing the least important dependencies.
        
        Args:
            dependency_graph: Dependency graph
            reverse_dependency_graph: Reverse dependency graph
            
        Returns:
            Tuple of (updated_dependency_graph, updated_reverse_dependency_graph)
        """
        # Copy graphs
        dep_graph = {k: v.copy() for k, v in dependency_graph.items()}
        rev_dep_graph = {k: v.copy() for k, v in reverse_dependency_graph.items()}
        
        # Find and break cycles
        visited = set()
        rec_stack = set()
        cycle_edges = []
        
        def find_cycle(node, path):
            visited.add(node)
            rec_stack.add(node)
            path.append(node)
            
            # Visit all neighbors
            for neighbor in dep_graph.get(node, []):
                if neighbor not in visited:
                    if find_cycle(neighbor, path):
                        return True
                elif neighbor in rec_stack:
                    # Found a cycle, record the edge
                    cycle_idx = path.index(neighbor)
                    cycle = path[cycle_idx:]
                    for i in range(len(cycle) - 1):
                        cycle_edges.append((cycle[i], cycle[i + 1]))
                    cycle_edges.append((cycle[-1], cycle[0]))
                    return True
            
            rec_stack.remove(node)
            path.pop()
            return False
        
        # Find all cycles
        for node in dep_graph:
            if node not in visited:
                find_cycle(node, [])
        
        # Remove edges to break cycles
        for src, dest in cycle_edges:
            if src in dep_graph and dest in dep_graph[src]:
                dep_graph[src].remove(dest)
                logger.debug(f"Removed dependency edge: {src} -> {dest} to break circular dependency")
            
            if dest in rev_dep_graph and src in rev_dep_graph[dest]:
                rev_dep_graph[dest].remove(src)
        
        return dep_graph, rev_dep_graph
    
    def _create_execution_plan(
        self, 
        subtasks: List[Dict[str, Any]], 
        dependency_graph: Dict[str, List[str]], 
        reverse_dependency_graph: Dict[str, List[str]],
        available_agents: List[str]
    ) -> List[Dict[str, Any]]:
        """
        Create an execution plan based on dependencies and available agents.
        
        Args:
            subtasks: List of normalized subtask specifications
            dependency_graph: Dependency graph
            reverse_dependency_graph: Reverse dependency graph
            available_agents: List of available agent IDs
            
        Returns:
            Execution plan as a list of steps
        """
        # Map of subtask IDs to subtasks
        id_to_subtask = {subtask["id"]: subtask for subtask in subtasks}
        
        # Calculate in-degree (number of dependencies) for each subtask
        in_degree = {subtask["id"]: len(dependency_graph.get(subtask["id"], [])) for subtask in subtasks}
        
        # Queue of ready tasks (no dependencies)
        ready_tasks = deque([subtask["id"] for subtask in subtasks if in_degree[subtask["id"]] == 0])
        
        # Create execution plan
        execution_plan = []
        completed_tasks = set()
        step_counter = 0
        
        while ready_tasks:
            # Create a new step
            step_counter += 1
            step = {
                "step_id": f"step_{step_counter}",
                "subtasks": []
            }
            
            # Select tasks for this step (up to max_parallel_tasks)
            selected_tasks = []
            selected_agents = set()
            
            # Sort ready tasks by complexity if configured
            ready_task_list = list(ready_tasks)
            if self.prioritize_by_complexity:
                ready_task_list.sort(
                    key=lambda task_id: id_to_subtask[task_id].get("complexity", 2),
                    reverse=True
                )
            
            # Select tasks for this step
            for _ in range(min(len(ready_task_list), self.max_parallel_tasks)):
                # Find a task that can be assigned
                best_task_idx = None
                best_task_score = -1
                
                for i, task_id in enumerate(ready_task_list):
                    if task_id in selected_tasks:
                        continue
                    
                    subtask = id_to_subtask[task_id]
                    agent_id = subtask.get("assigned_agent", "")
                    
                    # If no agent is assigned or assigned agent is already busy, skip
                    if agent_id and agent_id in selected_agents:
                        continue
                    
                    # Calculate a score for this task based on complexity and dependencies
                    complexity = subtask.get("complexity", 2)
                    dependent_count = len(reverse_dependency_graph.get(task_id, []))
                    
                    # Score favors high complexity and many dependents
                    score = (complexity * 10) + dependent_count
                    
                    if score > best_task_score:
                        best_task_score = score
                        best_task_idx = i
                
                # If no suitable task found, break
                if best_task_idx is None:
                    break
                
                # Add the best task to selected tasks
                task_id = ready_task_list[best_task_idx]
                subtask = id_to_subtask[task_id]
                agent_id = subtask.get("assigned_agent", "")
                
                selected_tasks.append(task_id)
                if agent_id:
                    selected_agents.add(agent_id)
                
                # Remove from ready tasks
                ready_tasks.remove(task_id)
            
            # Add selected tasks to the step
            for task_id in selected_tasks:
                subtask = id_to_subtask[task_id]
                step["subtasks"].append(subtask)
                
                # Mark as completed
                completed_tasks.add(task_id)
                
                # Update dependencies
                for dependent in reverse_dependency_graph.get(task_id, []):
                    in_degree[dependent] -= 1
                    
                    # If all dependencies are satisfied, add to ready tasks
                    if in_degree[dependent] == 0:
                        ready_tasks.append(dependent)
            
            # Add step to execution plan
            execution_plan.append(step)
        
        # Check if all tasks are scheduled
        if len(completed_tasks) < len(subtasks):
            unscheduled = [subtask["id"] for subtask in subtasks if subtask["id"] not in completed_tasks]
            logger.warning(f"Not all tasks were scheduled! Unscheduled tasks: {unscheduled}")
        
        return execution_plan
    
    def optimize_agent_assignments(
        self, 
        subtasks: List[Dict[str, Any]], 
        available_agents: List[str]
    ) -> List[Dict[str, Any]]:
        """
        Optimize agent assignments based on expertise and workload balance.
        
        Args:
            subtasks: List of subtask specifications
            available_agents: List of available agent IDs
            
        Returns:
            Updated subtask specifications with optimized agent assignments
        """
        # This is a placeholder for a more sophisticated assignment algorithm
        # In a real implementation, this would consider agent specialization,
        # workload balance, etc.
        
        # Currently just ensures each subtask has an assigned agent
        agent_workload = {agent: 0 for agent in available_agents}
        
        for subtask in subtasks:
            # Skip if already assigned
            if subtask.get("assigned_agent") in available_agents:
                agent_workload[subtask["assigned_agent"]] += 1
                continue
            
            # Find the agent with the least workload
            best_agent = min(agent_workload, key=agent_workload.get)
            
            # Assign agent
            subtask["assigned_agent"] = best_agent
            
            # Update workload
            agent_workload[best_agent] += 1
        
        return subtasks
    
    def visualize_schedule(self, schedule: List[Dict[str, Any]]) -> str:
        """
        Create a text visualization of the execution schedule.
        
        Args:
            schedule: Execution schedule
            
        Returns:
            Text visualization of the schedule
        """
        visualization = ["Schedule Visualization:"]
        
        for step in schedule:
            step_id = step["step_id"]
            subtasks = step["subtasks"]
            
            visualization.append(f"\n[{step_id}]")
            
            for subtask in subtasks:
                subtask_id = subtask["id"]
                description = subtask.get("description", "No description")
                agent = subtask.get("assigned_agent", "Unassigned")
                
                visualization.append(f"  - {subtask_id}: {description} (Agent: {agent})")
        
        return "\n".join(visualization)
--------------------------------------------------------------------------------
        team_manager.py

Content of C:/AI PROJECT/My Langchain Crew 1\core\team_manager.py:
"""
Team Manager Module

This module is responsible for analyzing tasks, determining the required team composition,
and creating teams of specialized agents to accomplish the given tasks.
"""

import logging
from typing import Dict, Any, List, Optional

from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import PydanticOutputParser
from pydantic import BaseModel, Field

from core.agent_factory import AgentFactory
from core.knowledge_repository import KnowledgeRepository
from agents.base_agent import BaseAgent
from utils.prompt_templates import TEAM_COMPOSITION_PROMPT

logger = logging.getLogger(__name__)

class AgentSpec(BaseModel):
    """Specification for an agent to be created."""
    role: str = Field(description="The primary role of the agent (research, specialist, planner, executor, reviewer)")
    specialization: str = Field(description="The specific domain expertise of the agent")
    importance: int = Field(description="Importance level from 1-10, with 10 being most essential", default=5)
    description: str = Field(description="Brief description of the agent's responsibilities")
    required_skills: List[str] = Field(description="List of specific skills this agent needs to have")
    background_info: Optional[str] = Field(description="Additional context for this agent's initialization", default=None)

class TeamComposition(BaseModel):
    """The composition of an agent team for a specific task."""
    team_name: str = Field(description="A descriptive name for the team")
    team_goal: str = Field(description="The primary goal of this team")
    required_agents: List[AgentSpec] = Field(description="List of agent specifications")
    additional_context: Optional[str] = Field(description="Additional context for the entire team", default=None)

class TeamManager:
    """
    Manager class for analyzing tasks and creating appropriate teams of agents.
    """
    
    def __init__(self, config: Dict[str, Any], knowledge_repository: Optional[KnowledgeRepository] = None):
        """
        Initialize the team manager.
        
        Args:
            config: Configuration dictionary with team manager settings
            knowledge_repository: Knowledge repository for accessing shared information
        """
        self.config = config
        self.knowledge_repository = knowledge_repository
        self.agent_factory = AgentFactory(config.get("agent_factory", {}), knowledge_repository)
        self.analysis_model = config.get("analysis_model", "gpt-4o")
        
        logger.debug(f"Initialized TeamManager with analysis model: {self.analysis_model}")
    
    def analyze_task(self, task_description: str) -> List[Dict[str, Any]]:
        """
        Analyze a task description and determine the required team composition.
        
        Args:
            task_description: The description of the task to be performed
            
        Returns:
            List of agent specifications for the required team members
        """
        logger.info(f"Analyzing task: {task_description}")
        
        # Create the prompt with the task description
        prompt = ChatPromptTemplate.from_template(TEAM_COMPOSITION_PROMPT)
        
        # Create a parser for the team composition
        parser = PydanticOutputParser(pydantic_object=TeamComposition)
        
        # Create the language model
        llm = ChatOpenAI(model=self.analysis_model, temperature=0.2)
        
        # Format the prompt with the task description and format instructions
        formatted_prompt = prompt.format(
            task_description=task_description,
            format_instructions=parser.get_format_instructions()
        )
        
        # Get the response from the LLM
        response = llm.invoke(formatted_prompt)
        
        try:
            # Parse the response into a TeamComposition object
            team_composition = parser.parse(response.content)
            logger.debug(f"Successfully parsed team composition: {team_composition.team_name}")
            
            # Convert the TeamComposition to a list of agent specifications
            agent_specs = [
                {
                    "role": agent.role,
                    "specialization": agent.specialization,
                    "importance": agent.importance,
                    "description": agent.description,
                    "required_skills": agent.required_skills,
                    "background_info": agent.background_info
                }
                for agent in team_composition.required_agents
            ]
            
            # Store the team composition in the knowledge repository if available
            if self.knowledge_repository:
                self.knowledge_repository.store_team_composition(
                    task_description, 
                    {
                        "team_name": team_composition.team_name,
                        "team_goal": team_composition.team_goal,
                        "additional_context": team_composition.additional_context,
                        "agent_specs": agent_specs
                    }
                )
            
            return agent_specs
            
        except Exception as e:
            logger.error(f"Error parsing team composition: {str(e)}")
            logger.debug(f"Raw LLM response: {response.content}")
            
            # Fallback to a default team composition
            return self._get_default_team_composition(task_description)
    
    def _get_default_team_composition(self, task_description: str) -> List[Dict[str, Any]]:
        """
        Get a default team composition when analysis fails.
        
        Args:
            task_description: Original task description
            
        Returns:
            Default list of agent specifications
        """
        logger.info("Using default team composition")
        
        return [
            {
                "role": "planner",
                "specialization": "project_manager",
                "importance": 10,
                "description": "Coordinates the team and plans the approach",
                "required_skills": ["project management", "task decomposition", "coordination"],
                "background_info": None
            },
            {
                "role": "research",
                "specialization": "information_retrieval",
                "importance": 8,
                "description": "Gathers information related to the task",
                "required_skills": ["web search", "information synthesis", "knowledge retrieval"],
                "background_info": None
            },
            {
                "role": "specialist",
                "specialization": "domain_expert",
                "importance": 9,
                "description": "Provides domain expertise for the task",
                "required_skills": ["domain knowledge", "problem solving", "technical expertise"],
                "background_info": None
            },
            {
                "role": "executor",
                "specialization": "implementation",
                "importance": 7,
                "description": "Implements solutions and executes plans",
                "required_skills": ["coding", "implementation", "technical execution"],
                "background_info": None
            },
            {
                "role": "reviewer",
                "specialization": "quality_assurance",
                "importance": 6,
                "description": "Reviews work and ensures quality",
                "required_skills": ["quality assurance", "testing", "review"],
                "background_info": None
            }
        ]
    
    def create_team(self, agent_specs: List[Dict[str, Any]]) -> Dict[str, BaseAgent]:
        """
        Create a team of agents based on the provided specifications.
        
        Args:
            agent_specs: List of agent specifications
            
        Returns:
            Dictionary mapping agent roles to agent instances
        """
        logger.info(f"Creating team with {len(agent_specs)} agents")
        
        team = {}
        
        # Process agents in order of importance (if specified)
        sorted_specs = sorted(
            agent_specs, 
            key=lambda x: x.get("importance", 5),
            reverse=True
        )
        
        for spec in sorted_specs:
            role = spec.get("role")
            specialization = spec.get("specialization")
            
            # Create a unique identifier for this agent
            agent_id = f"{role}_{specialization}" if specialization else role
            
            # Check if we already have this agent type in the team
            if agent_id in team:
                logger.warning(f"Agent with ID {agent_id} already exists in the team, skipping")
                continue
            
            try:
                # Create the agent using the agent factory
                agent = self.agent_factory.create_specialized_agent(spec)
                
                # Add the agent to the team
                team[agent_id] = agent
                logger.debug(f"Added agent {agent_id} to the team")
                
            except Exception as e:
                logger.error(f"Error creating agent {agent_id}: {str(e)}")
        
        logger.info(f"Team created successfully with {len(team)} agents")
        return team
    
    def get_team_roles(self, team: Dict[str, BaseAgent]) -> List[str]:
        """
        Get the list of roles present in a team.
        
        Args:
            team: Dictionary mapping agent IDs to agent instances
            
        Returns:
            List of roles in the team
        """
        return [agent.role for agent in team.values()]
    
    def update_team(
        self, 
        team: Dict[str, BaseAgent], 
        additional_specs: List[Dict[str, Any]]
    ) -> Dict[str, BaseAgent]:
        """
        Update an existing team with additional agents.
        
        Args:
            team: Existing team of agents
            additional_specs: Specifications for agents to add
            
        Returns:
            Updated team dictionary
        """
        logger.info(f"Updating team with {len(additional_specs)} additional agents")
        
        # Create agents for the additional specifications
        for spec in additional_specs:
            role = spec.get("role")
            specialization = spec.get("specialization")
            
            # Create a unique identifier for this agent
            agent_id = f"{role}_{specialization}" if specialization else role
            
            # Check if we already have this agent type in the team
            if agent_id in team:
                logger.warning(f"Agent with ID {agent_id} already exists in the team, skipping")
                continue
            
            try:
                # Create the agent using the agent factory
                agent = self.agent_factory.create_specialized_agent(spec)
                
                # Add the agent to the team
                team[agent_id] = agent
                logger.debug(f"Added agent {agent_id} to the team")
                
            except Exception as e:
                logger.error(f"Error creating agent {agent_id}: {str(e)}")
        
        return team

    def get_team(self, team_id: str) -> Dict[str, BaseAgent]:
        """
        Get a previously created team by its ID.
        
        Args:
            team_id: ID of the team to retrieve
            
        Returns:
            Dictionary mapping agent IDs to agent instances
        """
        # Récupérer la composition de l'équipe
        team_data = self.knowledge_repository.get_team(team_id)
        
        if not team_data:
            logger.warning(f"Team with ID {team_id} not found")
            return {}
        
        # Créer l'équipe d'agents à partir des spécifications
        agent_specs = team_data.get("agent_specs", [])
        logger.info(f"Recreating team '{team_data.get('name')}' with {len(agent_specs)} agents")
        
        return self.create_team(agent_specs)
--------------------------------------------------------------------------------
        __init__.py

Content of C:/AI PROJECT/My Langchain Crew 1\core\__init__.py:
"""
Core package.
"""
--------------------------------------------------------------------------------
    data/
        README.md

Content of C:/AI PROJECT/My Langchain Crew 1\data\README.md:
# Data Directory

This directory contains persistent data used by the Team Agents system:

- `vector_store/`: Vector embeddings for knowledge retrieval
- `conversation_history/`: History of agent conversations
- Other data generated during runtime

This directory is created and managed by the Team Agents system.
--------------------------------------------------------------------------------
        structured_data.json

Content of C:/AI PROJECT/My Langchain Crew 1\data\structured_data.json:
{
  "team_compositions": {
    "team_1741513386_4482": {
      "team_name": "Langchain Application Finalization Team",
      "team_goal": "To finalize the development and deployment of a Langchain-based application",
      "additional_context": "The team should be familiar with the latest trends in AI and have experience with Langchain to effectively finalize the application.",
      "agent_specs": [
        {
          "role": "research",
          "specialization": "Langchain Framework",
          "importance": 8,
          "description": "Responsible for researching the latest updates and best practices in Langchain to ensure the application is built on a solid foundation.",
          "required_skills": [
            "Langchain knowledge",
            "Research skills",
            "Technical documentation analysis"
          ],
          "background_info": null
        },
        {
          "role": "specialist",
          "specialization": "Natural Language Processing",
          "importance": 9,
          "description": "Focuses on implementing and optimizing NLP components within the Langchain application.",
          "required_skills": [
            "NLP algorithms",
            "Langchain integration",
            "Python programming"
          ],
          "background_info": null
        },
        {
          "role": "planner",
          "specialization": "Project Management",
          "importance": 7,
          "description": "Coordinates the project timeline, resources, and ensures all team members are aligned with the project goals.",
          "required_skills": [
            "Project management",
            "Communication",
            "Time management"
          ],
          "background_info": null
        },
        {
          "role": "executor",
          "specialization": "Software Development",
          "importance": 10,
          "description": "Handles the coding and implementation of the Langchain application, ensuring all components are functional and integrated.",
          "required_skills": [
            "Software development",
            "Langchain implementation",
            "Debugging"
          ],
          "background_info": null
        },
        {
          "role": "reviewer",
          "specialization": "Quality Assurance",
          "importance": 8,
          "description": "Conducts thorough testing and validation of the application to ensure it meets quality standards and functions as expected.",
          "required_skills": [
            "Testing methodologies",
            "Attention to detail",
            "Problem-solving"
          ],
          "background_info": null
        }
      ],
      "timestamp": "2025-03-09T10:43:06.724041",
      "task_description": "Je souhaite cr\u00e9er une \u00e9quipe sp\u00e9cialis\u00e9e dans Langchain pour m'aider \u00e0 finaliser une application"
    }
  },
  "execution_results": {
    "execution_1741513486_4482": {
      "timestamp": "2025-03-09T10:44:46.325774",
      "task_description": "Je souhaite cr\u00e9er une \u00e9quipe sp\u00e9cialis\u00e9e dans Langchain pour m'aider \u00e0 finaliser une application",
      "execution_results": {
        "subtask_0_fb103ffb": {
          "subtask": {
            "id": "subtask_0_fb103ffb",
            "description": "Define the application requirements and specifications.",
            "assigned_agent": "",
            "dependencies": [],
            "complexity": 2,
            "required_skills_or_role": "planner_Project Management",
            "estimated_complexity": "medium"
          },
          "agent_id": "planner_Project Management",
          "output": "To define the application requirements and specifications for creating a specialized team in Langchain to help finalize an application, we need to follow a structured approach. This will ensure that the team is well-equipped to meet the project's needs and that the application is developed efficiently and effectively. Here is a comprehensive plan to guide this process:\n\n### Step 1: Define the Application's Purpose and Goals\n- **Action Items:**\n  - Clearly articulate the primary purpose of the application.\n  - Identify the key goals the application aims to achieve.\n  - Ensure alignment with the overall project objectives and the capabilities of Langchain.\n- **Success Criteria:** A well-documented purpose and goal statement that is agreed upon by all stakeholders.\n\n### Step 2: Identify Key Features and Functionalities\n- **Action Items:**\n  - List the essential features and functionalities required for the application.\n  - Prioritize these features based on their importance and impact on the application's success.\n  - Consider user needs and potential use cases.\n- **Success Criteria:** A prioritized list of features and functionalities with detailed descriptions.\n\n### Step 3: Determine Technical Requirements\n- **Action Items:**\n  - Specify the technical requirements, including hardware, software, and network needs.\n  - Identify any specific technologies or frameworks that must be used, such as Langchain.\n  - Consider scalability, performance, and security requirements.\n- **Success Criteria:** A comprehensive technical requirements document that outlines all necessary specifications.\n\n### Step 4: Define User Experience and Interface Design\n- **Action Items:**\n  - Outline the desired user experience and interface design principles.\n  - Create wireframes or mockups to visualize the application's layout and navigation.\n  - Ensure the design aligns with user expectations and enhances usability.\n- **Success Criteria:** Approved wireframes or mockups that reflect the desired user experience and interface design.\n\n### Step 5: Establish Development and Testing Processes\n- **Action Items:**\n  - Define the development methodology (e.g., Agile, Waterfall) and processes to be followed.\n  - Outline the testing strategy, including types of testing (e.g., unit, integration, user acceptance) and testing tools.\n  - Set clear criteria for testing success and application readiness.\n- **Success Criteria:** A detailed development and testing plan that ensures quality and reliability.\n\n### Step 6: Identify Resource and Timeline Constraints\n- **Action Items:**\n  - Assess the resources required, including team members, tools, and budget.\n  - Establish a realistic timeline for the application's development and deployment.\n  - Identify potential constraints and plan for contingencies.\n- **Success Criteria:** A resource allocation and timeline plan that is feasible and agreed upon by all stakeholders.\n\n### Step 7: Review and Finalize Specifications\n- **Action Items:**\n  - Conduct a review session with all stakeholders to discuss and finalize the application requirements and specifications.\n  - Make necessary adjustments based on feedback and ensure consensus.\n- **Success Criteria:** A finalized application requirements and specifications document that is approved by all stakeholders.\n\nBy following this structured plan, we can ensure that the application requirements and specifications are clearly defined, enabling the Langchain team to effectively contribute to the application's successful completion.",
          "status": "completed",
          "metadata": {
            "agent_role": "planner_Project Management"
          }
        },
        "subtask_1_430e8702": {
          "subtask": {
            "id": "subtask_1_430e8702",
            "description": "Conduct research on the latest Langchain features and best practices.",
            "assigned_agent": "",
            "dependencies": [],
            "complexity": 2,
            "required_skills_or_role": "research_Langchain Framework",
            "estimated_complexity": "medium"
          },
          "agent_id": "research_Langchain Framework",
          "output": "To conduct research on the latest Langchain features and best practices, I will gather and synthesize information from credible sources. This will include recent advancements, best practices, and any relevant updates in the Langchain framework as of October 2023. Here is a structured summary of the findings:\n\n### Key Insights on Langchain Technology\n\n1. **Langchain Framework Overview**:\n   - Langchain is a framework designed for building applications that leverage language models, particularly useful for complex language processing tasks and integrating natural language processing (NLP) capabilities.\n   - It supports modular development, allowing developers to build scalable and efficient language processing systems.\n\n2. **Recent Advancements**:\n   - **Integration with AI and NLP**: Langchain has been increasingly integrated with advanced AI and NLP technologies, enhancing its capabilities in understanding and generating human-like text.\n   - **Scalability Improvements**: Recent updates have focused on improving the scalability of Langchain applications, making it suitable for large-scale deployments.\n   - **Enhanced API Support**: There have been improvements in API integration, allowing for more seamless connectivity with other systems and services.\n\n3. **Best Practices**:\n   - **Modular Development**: Utilize Langchain's modular architecture to build applications that are easy to maintain and scale.\n   - **Continuous Learning**: Stay updated with the latest advancements in AI and NLP to leverage new features and improvements in Langchain.\n   - **Efficient Resource Management**: Optimize resource allocation to ensure efficient and timely project delivery.\n   - **Comprehensive Testing**: Implement thorough testing strategies to ensure high-quality integration and performance of Langchain applications.\n\n4. **Areas for Further Exploration**:\n   - Explore the integration of Langchain with other emerging technologies to enhance its capabilities.\n   - Investigate new use cases and applications of Langchain in different industries.\n\n### Conclusion\nThe Langchain framework continues to evolve with advancements in AI and NLP, offering enhanced capabilities for building sophisticated language processing applications. By following best practices and staying informed about the latest updates, teams can effectively leverage Langchain to develop scalable and efficient applications.\n\n### Additional Research Needed\n- Detailed case studies on successful Langchain implementations.\n- Comparative analysis of Langchain with other language processing frameworks.\n\nThis summary provides a comprehensive overview of the latest features and best practices in Langchain technology, which can guide the formation of a specialized team to finalize your application.",
          "status": "completed",
          "metadata": {
            "agent_role": "research_Langchain Framework"
          }
        },
        "subtask_2_54709179": {
          "subtask": {
            "id": "subtask_2_54709179",
            "description": "Design the application architecture using Langchain.",
            "assigned_agent": "",
            "dependencies": [
              "Define the application requirements and specifications"
            ],
            "complexity": 2,
            "required_skills_or_role": "specialist_Natural Language Processing",
            "estimated_complexity": "high"
          },
          "agent_id": "specialist_Natural Language Processing",
          "output": "To design an application architecture using Langchain, especially for a team specialized in Langchain, we need to consider several key aspects of both the Langchain framework and the specific requirements of the application. Here's a structured approach to designing the application architecture:\n\n### 1. **Understand the Application Requirements**\n   - **Objective**: Clearly define the purpose and functionality of the application.\n   - **User Needs**: Identify the target users and their needs.\n   - **Performance Goals**: Establish performance benchmarks and scalability requirements.\n\n### 2. **Langchain Framework Overview**\n   - **Core Features**: Understand the core features of Langchain that are relevant to the application, such as modularity, integration capabilities, and scalability.\n   - **Compatibility**: Ensure compatibility with existing systems and technologies used by the team.\n\n### 3. **Define the Application Architecture**\n   - **Modular Design**: Utilize Langchain's modular architecture to create reusable components.\n   - **Integration Points**: Identify key integration points with other systems or data sources.\n   - **Data Flow**: Design the data flow within the application, ensuring efficient data processing and storage.\n\n### 4. **Incorporate NLP Capabilities**\n   - **NLP Techniques**: Integrate advanced NLP techniques to enhance language processing tasks.\n   - **Machine Learning Models**: Utilize machine learning models for tasks such as text classification, sentiment analysis, or entity recognition.\n   - **Continuous Learning**: Implement mechanisms for continuous learning and improvement of NLP models.\n\n### 5. **Scalability and Performance Optimization**\n   - **Load Balancing**: Design for load balancing to handle high traffic and ensure reliability.\n   - **Caching Strategies**: Implement caching strategies to improve response times.\n   - **Performance Monitoring**: Set up monitoring tools to track performance and identify bottlenecks.\n\n### 6. **Security and Compliance**\n   - **Data Security**: Ensure data security and privacy, especially if handling sensitive information.\n   - **Compliance**: Adhere to relevant regulations and standards, such as GDPR or HIPAA.\n\n### 7. **Testing and Deployment**\n   - **Testing Framework**: Use a robust testing framework to ensure the application meets all requirements.\n   - **Deployment Strategy**: Plan a deployment strategy that includes staging environments and rollback mechanisms.\n\n### 8. **Documentation and Training**\n   - **Technical Documentation**: Provide comprehensive technical documentation for the architecture and components.\n   - **Training**: Offer training sessions for the team to ensure they are proficient with the Langchain framework and the application architecture.\n\n### Conclusion\nBy following this structured approach, the team can design a robust and scalable application architecture using Langchain. This architecture should leverage the strengths of the Langchain framework while meeting the specific needs of the application and its users. Regular updates and continuous integration of new NLP advancements will ensure the application remains cutting-edge and effective.",
          "status": "completed",
          "metadata": {
            "agent_role": "specialist_Natural Language Processing"
          }
        },
        "subtask_3_35b18691": {
          "subtask": {
            "id": "subtask_3_35b18691",
            "description": "Develop the core functionalities of the application using Langchain.",
            "assigned_agent": "",
            "dependencies": [
              "Design the application architecture using Langchain"
            ],
            "complexity": 2,
            "required_skills_or_role": "executor_Software Development",
            "estimated_complexity": "high"
          },
          "agent_id": "executor_Software Development",
          "output": "To develop the core functionalities of an application using Langchain, we need to follow a structured approach. Here's a step-by-step plan to implement the core functionalities:\n\n### Step 1: Define Core Functionalities\nIdentify the key features and functionalities that the application must have. This involves understanding the application requirements and how Langchain can be leveraged to meet these needs.\n\n### Step 2: Set Up the Development Environment\nEnsure that the development environment is properly set up with all necessary tools and libraries, including Langchain. This includes:\n- Installing Python and necessary packages\n- Setting up a version control system (e.g., Git)\n- Configuring any required databases or external services\n\n### Step 3: Implement Core Features\nDevelop the core features of the application using Langchain. This involves:\n- Writing Python code to implement the desired functionalities\n- Utilizing Langchain's capabilities to enhance the application's performance and scalability\n- Ensuring that the code is modular and maintainable\n\n### Step 4: Integration and Testing\nIntegrate the developed features into the existing system and perform thorough testing to ensure functionality and reliability. This includes:\n- Unit testing individual components\n- Integration testing to ensure seamless operation within the system\n- Performance testing to ensure the application meets performance benchmarks\n\n### Step 5: Documentation\nDocument the code and functionalities clearly to ensure that other team members can understand and maintain the application. This includes:\n- Writing comments and documentation for the code\n- Creating user manuals or guides if necessary\n\n### Step 6: Review and Optimize\nReview the implemented functionalities for any potential improvements or optimizations. This involves:\n- Code review for quality and adherence to best practices\n- Optimizing algorithms and code for better performance\n\n### Step 7: Deployment\nPrepare the application for deployment by ensuring all components are ready and tested. This includes:\n- Setting up deployment scripts or processes\n- Ensuring that the application is secure and scalable\n\nBy following these steps, we can effectively develop the core functionalities of the application using Langchain. If you have specific requirements or features in mind, please provide them so that I can tailor the implementation accordingly.",
          "status": "completed",
          "metadata": {
            "agent_role": "executor_Software Development"
          }
        },
        "subtask_4_249f78f3": {
          "subtask": {
            "id": "subtask_4_249f78f3",
            "description": "Integrate NLP components into the application.",
            "assigned_agent": "",
            "dependencies": [
              "Develop the core functionalities of the application using Langchain"
            ],
            "complexity": 2,
            "required_skills_or_role": "specialist_Natural Language Processing",
            "estimated_complexity": "high"
          },
          "agent_id": "specialist_Natural Language Processing",
          "output": "To integrate NLP components into an application using the Langchain framework, we need to follow a structured approach that leverages advanced Natural Language Processing techniques. Here's a detailed plan to achieve this:\n\n### 1. **Understand the Langchain Framework**\n   - **Objective**: Gain a comprehensive understanding of the Langchain framework, its architecture, and its capabilities.\n   - **Action Items**:\n     - Review the official Langchain documentation and any available tutorials.\n     - Explore community forums and discussions to gather insights and best practices.\n     - Identify the specific modules and components within Langchain that are relevant to NLP tasks.\n\n### 2. **Define NLP Requirements**\n   - **Objective**: Clearly outline the NLP functionalities needed for the application.\n   - **Action Items**:\n     - Conduct a requirements analysis to determine the specific NLP tasks (e.g., text classification, sentiment analysis, entity recognition).\n     - Collaborate with stakeholders to prioritize these tasks based on the application's goals.\n\n### 3. **Select Appropriate NLP Models and Techniques**\n   - **Objective**: Choose the most suitable NLP models and techniques for integration.\n   - **Action Items**:\n     - Evaluate different NLP models (e.g., BERT, GPT, Transformer-based models) for their suitability in the context of Langchain.\n     - Consider factors such as model accuracy, computational efficiency, and scalability.\n     - Stay updated with the latest advancements in NLP to leverage cutting-edge techniques.\n\n### 4. **Integrate NLP Models with Langchain**\n   - **Objective**: Seamlessly integrate the selected NLP models into the Langchain application.\n   - **Action Items**:\n     - Utilize Langchain's modular architecture to incorporate NLP components.\n     - Develop custom modules or adapt existing ones to fit the application's requirements.\n     - Ensure that the integration supports scalability and efficient processing of language tasks.\n\n### 5. **Test and Optimize NLP Components**\n   - **Objective**: Validate the performance and accuracy of the integrated NLP components.\n   - **Action Items**:\n     - Conduct thorough testing using a diverse set of language data to evaluate model performance.\n     - Optimize the models for speed and accuracy, considering trade-offs as necessary.\n     - Implement feedback loops to continuously improve the NLP capabilities based on user interactions and data.\n\n### 6. **Documentation and Knowledge Sharing**\n   - **Objective**: Document the integration process and share knowledge with the team.\n   - **Action Items**:\n     - Create detailed documentation outlining the integration steps, challenges faced, and solutions implemented.\n     - Organize knowledge-sharing sessions to ensure the team is aligned and informed about the NLP components.\n\n### Considerations and Limitations\n- **Scalability**: Ensure that the NLP components can handle large volumes of data efficiently.\n- **Model Updates**: Plan for regular updates to the NLP models to incorporate new advancements and improve performance.\n- **Resource Constraints**: Be mindful of computational resources and optimize accordingly to prevent bottlenecks.\n\nBy following this structured approach, we can effectively integrate NLP components into the Langchain application, enhancing its language processing capabilities and ensuring it meets the desired objectives.",
          "status": "completed",
          "metadata": {
            "agent_role": "specialist_Natural Language Processing"
          }
        },
        "subtask_5_e9224650": {
          "subtask": {
            "id": "subtask_5_e9224650",
            "description": "Conduct quality assurance testing to ensure application stability and performance.",
            "assigned_agent": "",
            "dependencies": [
              "Integrate NLP components into the application"
            ],
            "complexity": 2,
            "required_skills_or_role": "reviewer_Quality Assurance",
            "estimated_complexity": "medium"
          },
          "agent_id": "reviewer_Quality Assurance",
          "output": "To conduct quality assurance testing for the Langchain application and ensure its stability and performance, I will follow a structured approach based on the provided information and best practices in quality assurance. Here is a detailed plan and recommendations:\n\n### Quality Assurance Testing Plan\n\n1. **Establish Quality Standards**\n   - Define clear quality standards and best practices specific to Langchain applications.\n   - Ensure these standards align with industry best practices and the specific needs of Langchain.\n\n2. **Integration Testing**\n   - Execute integration tests to verify the interactions between different modules of the application.\n   - Ensure that all modules work together seamlessly without any integration issues.\n\n3. **System Testing**\n   - Conduct system-level tests to validate the overall functionality of the application.\n   - Ensure that the application meets all specified requirements and functions as expected in a real-world environment.\n\n4. **Performance Optimization**\n   - Analyze the application's performance under various conditions and loads.\n   - Optimize system performance to ensure the application runs efficiently and effectively.\n\n5. **Documentation**\n   - Document the integration and testing process thoroughly.\n   - Ensure that all testing procedures, results, and any issues encountered are well-documented for future reference and continuous improvement.\n\n6. **Feedback and Iteration**\n   - Gather feedback from stakeholders and users to identify any areas for improvement.\n   - Iterate on the application based on feedback and testing results to enhance quality and performance.\n\n### Recommendations\n\n- **Attention to Detail**: Ensure that all aspects of the application are thoroughly tested, including edge cases and potential failure points.\n- **Continuous Improvement**: Regularly update testing procedures and standards to incorporate new insights and advancements in Langchain and related technologies.\n- **Collaboration**: Work closely with the development team to address any issues identified during testing and ensure timely resolution.\n\nBy following this plan, we can ensure that the Langchain application is stable, performs well, and meets the quality standards expected by users and stakeholders. If there are any specific areas you would like me to focus on or any additional requirements, please let me know.",
          "status": "completed",
          "metadata": {
            "agent_role": "reviewer_Quality Assurance"
          }
        },
        "subtask_6_d81d660f": {
          "subtask": {
            "id": "subtask_6_d81d660f",
            "description": "Finalize documentation and user guides for the application.",
            "assigned_agent": "",
            "dependencies": [
              "Conduct quality assurance testing to ensure application stability and performance"
            ],
            "complexity": 2,
            "required_skills_or_role": "planner_Project Management",
            "estimated_complexity": "low"
          },
          "agent_id": "planner_Project Management",
          "output": "To finalize the documentation and user guides for the Langchain-based application, we need to create a structured plan that ensures comprehensive and user-friendly documentation. This plan will guide the documentation process, ensuring that all necessary information is captured and presented clearly. Here is a detailed plan to achieve this subtask:\n\n### Step 1: Analyze Documentation Requirements\n- **Action Items:**\n  - Identify the target audience for the documentation (e.g., developers, end-users, administrators).\n  - Determine the scope of the documentation, including technical details, user guides, and troubleshooting sections.\n  - Gather existing documentation and notes from the development team.\n\n- **Success Criteria:** A clear understanding of the documentation requirements and target audience.\n\n### Step 2: Organize Documentation Structure\n- **Action Items:**\n  - Create an outline for the documentation, including sections such as Introduction, Installation, Configuration, Usage, Troubleshooting, and FAQs.\n  - Define the format and style guidelines for the documentation to ensure consistency.\n\n- **Success Criteria:** A well-organized documentation outline and style guide.\n\n### Step 3: Draft Technical Documentation\n- **Action Items:**\n  - Collaborate with developers to document technical aspects of the application, including architecture, APIs, and integration points.\n  - Ensure that technical documentation is detailed and accurate, with diagrams and code snippets where applicable.\n\n- **Success Criteria:** Comprehensive technical documentation that accurately reflects the application's architecture and functionality.\n\n### Step 4: Develop User Guides\n- **Action Items:**\n  - Write user guides that provide step-by-step instructions for common tasks and features.\n  - Include screenshots, examples, and tips to enhance user understanding and engagement.\n\n- **Success Criteria:** User guides that are clear, concise, and easy to follow for the intended audience.\n\n### Step 5: Review and Revise Documentation\n- **Action Items:**\n  - Conduct a peer review of the documentation to identify areas for improvement.\n  - Revise the documentation based on feedback, ensuring clarity and accuracy.\n\n- **Success Criteria:** Documentation that has been reviewed and refined to meet quality standards.\n\n### Step 6: Finalize and Publish Documentation\n- **Action Items:**\n  - Format the documentation for publication, ensuring it is accessible in various formats (e.g., PDF, HTML).\n  - Publish the documentation on appropriate platforms, such as the company website or a dedicated documentation portal.\n\n- **Success Criteria:** Finalized documentation that is published and accessible to the target audience.\n\n### Step 7: Plan for Ongoing Updates\n- **Action Items:**\n  - Establish a process for updating the documentation as the application evolves.\n  - Schedule regular reviews to ensure the documentation remains current and relevant.\n\n- **Success Criteria:** A documented process for maintaining and updating the documentation over time.\n\nBy following this structured plan, we can ensure that the documentation and user guides for the Langchain-based application are comprehensive, user-friendly, and effectively support the application's users.",
          "status": "completed",
          "metadata": {
            "agent_role": "planner_Project Management"
          }
        }
      },
      "conversation_history": [
        {
          "type": "HumanMessage",
          "content": "content=\"Main task: Je souhaite cr\u00e9er une \u00e9quipe sp\u00e9cialis\u00e9e dans Langchain pour m'aider \u00e0 finaliser une application\" additional_kwargs={} response_metadata={}"
        },
        {
          "type": "SystemMessage",
          "content": "content='Agent planner_Project Management completed subtask: Define the application requirements and specifications.' additional_kwargs={} response_metadata={}"
        },
        {
          "type": "AIMessage",
          "content": "content=\"To define the application requirements and specifications for creating a specialized team in Langchain to help finalize an application, we need to follow a structured approach. This will ensure that the team is well-equipped to meet the project's needs and that the application is developed efficiently and effectively. Here is a comprehensive plan to guide this process:\\n\\n### Step 1: Define the Application's Purpose and Goals\\n- **Action Items:**\\n  - Clearly articulate the primary purpose of the application.\\n  - Identify the key goals the application aims to achieve.\\n  - Ensure alignment with the overall project objectives and the capabilities of Langchain.\\n- **Success Criteria:** A well-documented purpose and goal statement that is agreed upon by all stakeholders.\\n\\n### Step 2: Identify Key Features and Functionalities\\n- **Action Items:**\\n  - List the essential features and functionalities required for the application.\\n  - Prioritize these features based on their importance and impact on the application's success.\\n  - Consider user needs and potential use cases.\\n- **Success Criteria:** A prioritized list of features and functionalities with detailed descriptions.\\n\\n### Step 3: Determine Technical Requirements\\n- **Action Items:**\\n  - Specify the technical requirements, including hardware, software, and network needs.\\n  - Identify any specific technologies or frameworks that must be used, such as Langchain.\\n  - Consider scalability, performance, and security requirements.\\n- **Success Criteria:** A comprehensive technical requirements document that outlines all necessary specifications.\\n\\n### Step 4: Define User Experience and Interface Design\\n- **Action Items:**\\n  - Outline the desired user experience and interface design principles.\\n  - Create wireframes or mockups to visualize the application's layout and navigation.\\n  - Ensure the design aligns with user expectations and enhances usability.\\n- **Success Criteria:** Approved wireframes or mockups that reflect the desired user experience and interface design.\\n\\n### Step 5: Establish Development and Testing Processes\\n- **Action Items:**\\n  - Define the development methodology (e.g., Agile, Waterfall) and processes to be followed.\\n  - Outline the testing strategy, including types of testing (e.g., unit, integration, user acceptance) and testing tools.\\n  - Set clear criteria for testing success and application readiness.\\n- **Success Criteria:** A detailed development and testing plan that ensures quality and reliability.\\n\\n### Step 6: Identify Resource and Timeline Constraints\\n- **Action Items:**\\n  - Assess the resources required, including team members, tools, and budget.\\n  - Establish a realistic timeline for the application's development and deployment.\\n  - Identify potential constraints and plan for contingencies.\\n- **Success Criteria:** A resource allocation and timeline plan that is feasible and agreed upon by all stakeholders.\\n\\n### Step 7: Review and Finalize Specifications\\n- **Action Items:**\\n  - Conduct a review session with all stakeholders to discuss and finalize the application requirements and specifications.\\n  - Make necessary adjustments based on feedback and ensure consensus.\\n- **Success Criteria:** A finalized application requirements and specifications document that is approved by all stakeholders.\\n\\nBy following this structured plan, we can ensure that the application requirements and specifications are clearly defined, enabling the Langchain team to effectively contribute to the application's successful completion.\" additional_kwargs={} response_metadata={}"
        },
        {
          "type": "SystemMessage",
          "content": "content='Agent research_Langchain Framework completed subtask: Conduct research on the latest Langchain features and best practices.' additional_kwargs={} response_metadata={}"
        },
        {
          "type": "AIMessage",
          "content": "content=\"To conduct research on the latest Langchain features and best practices, I will gather and synthesize information from credible sources. This will include recent advancements, best practices, and any relevant updates in the Langchain framework as of October 2023. Here is a structured summary of the findings:\\n\\n### Key Insights on Langchain Technology\\n\\n1. **Langchain Framework Overview**:\\n   - Langchain is a framework designed for building applications that leverage language models, particularly useful for complex language processing tasks and integrating natural language processing (NLP) capabilities.\\n   - It supports modular development, allowing developers to build scalable and efficient language processing systems.\\n\\n2. **Recent Advancements**:\\n   - **Integration with AI and NLP**: Langchain has been increasingly integrated with advanced AI and NLP technologies, enhancing its capabilities in understanding and generating human-like text.\\n   - **Scalability Improvements**: Recent updates have focused on improving the scalability of Langchain applications, making it suitable for large-scale deployments.\\n   - **Enhanced API Support**: There have been improvements in API integration, allowing for more seamless connectivity with other systems and services.\\n\\n3. **Best Practices**:\\n   - **Modular Development**: Utilize Langchain's modular architecture to build applications that are easy to maintain and scale.\\n   - **Continuous Learning**: Stay updated with the latest advancements in AI and NLP to leverage new features and improvements in Langchain.\\n   - **Efficient Resource Management**: Optimize resource allocation to ensure efficient and timely project delivery.\\n   - **Comprehensive Testing**: Implement thorough testing strategies to ensure high-quality integration and performance of Langchain applications.\\n\\n4. **Areas for Further Exploration**:\\n   - Explore the integration of Langchain with other emerging technologies to enhance its capabilities.\\n   - Investigate new use cases and applications of Langchain in different industries.\\n\\n### Conclusion\\nThe Langchain framework continues to evolve with advancements in AI and NLP, offering enhanced capabilities for building sophisticated language processing applications. By following best practices and staying informed about the latest updates, teams can effectively leverage Langchain to develop scalable and efficient applications.\\n\\n### Additional Research Needed\\n- Detailed case studies on successful Langchain implementations.\\n- Comparative analysis of Langchain with other language processing frameworks.\\n\\nThis summary provides a comprehensive overview of the latest features and best practices in Langchain technology, which can guide the formation of a specialized team to finalize your application.\" additional_kwargs={} response_metadata={}"
        },
        {
          "type": "SystemMessage",
          "content": "content='Agent specialist_Natural Language Processing completed subtask: Design the application architecture using Langchain.' additional_kwargs={} response_metadata={}"
        },
        {
          "type": "AIMessage",
          "content": "content=\"To design an application architecture using Langchain, especially for a team specialized in Langchain, we need to consider several key aspects of both the Langchain framework and the specific requirements of the application. Here's a structured approach to designing the application architecture:\\n\\n### 1. **Understand the Application Requirements**\\n   - **Objective**: Clearly define the purpose and functionality of the application.\\n   - **User Needs**: Identify the target users and their needs.\\n   - **Performance Goals**: Establish performance benchmarks and scalability requirements.\\n\\n### 2. **Langchain Framework Overview**\\n   - **Core Features**: Understand the core features of Langchain that are relevant to the application, such as modularity, integration capabilities, and scalability.\\n   - **Compatibility**: Ensure compatibility with existing systems and technologies used by the team.\\n\\n### 3. **Define the Application Architecture**\\n   - **Modular Design**: Utilize Langchain's modular architecture to create reusable components.\\n   - **Integration Points**: Identify key integration points with other systems or data sources.\\n   - **Data Flow**: Design the data flow within the application, ensuring efficient data processing and storage.\\n\\n### 4. **Incorporate NLP Capabilities**\\n   - **NLP Techniques**: Integrate advanced NLP techniques to enhance language processing tasks.\\n   - **Machine Learning Models**: Utilize machine learning models for tasks such as text classification, sentiment analysis, or entity recognition.\\n   - **Continuous Learning**: Implement mechanisms for continuous learning and improvement of NLP models.\\n\\n### 5. **Scalability and Performance Optimization**\\n   - **Load Balancing**: Design for load balancing to handle high traffic and ensure reliability.\\n   - **Caching Strategies**: Implement caching strategies to improve response times.\\n   - **Performance Monitoring**: Set up monitoring tools to track performance and identify bottlenecks.\\n\\n### 6. **Security and Compliance**\\n   - **Data Security**: Ensure data security and privacy, especially if handling sensitive information.\\n   - **Compliance**: Adhere to relevant regulations and standards, such as GDPR or HIPAA.\\n\\n### 7. **Testing and Deployment**\\n   - **Testing Framework**: Use a robust testing framework to ensure the application meets all requirements.\\n   - **Deployment Strategy**: Plan a deployment strategy that includes staging environments and rollback mechanisms.\\n\\n### 8. **Documentation and Training**\\n   - **Technical Documentation**: Provide comprehensive technical documentation for the architecture and components.\\n   - **Training**: Offer training sessions for the team to ensure they are proficient with the Langchain framework and the application architecture.\\n\\n### Conclusion\\nBy following this structured approach, the team can design a robust and scalable application architecture using Langchain. This architecture should leverage the strengths of the Langchain framework while meeting the specific needs of the application and its users. Regular updates and continuous integration of new NLP advancements will ensure the application remains cutting-edge and effective.\" additional_kwargs={} response_metadata={}"
        },
        {
          "type": "SystemMessage",
          "content": "content='Agent executor_Software Development completed subtask: Develop the core functionalities of the application using Langchain.' additional_kwargs={} response_metadata={}"
        },
        {
          "type": "AIMessage",
          "content": "content=\"To develop the core functionalities of an application using Langchain, we need to follow a structured approach. Here's a step-by-step plan to implement the core functionalities:\\n\\n### Step 1: Define Core Functionalities\\nIdentify the key features and functionalities that the application must have. This involves understanding the application requirements and how Langchain can be leveraged to meet these needs.\\n\\n### Step 2: Set Up the Development Environment\\nEnsure that the development environment is properly set up with all necessary tools and libraries, including Langchain. This includes:\\n- Installing Python and necessary packages\\n- Setting up a version control system (e.g., Git)\\n- Configuring any required databases or external services\\n\\n### Step 3: Implement Core Features\\nDevelop the core features of the application using Langchain. This involves:\\n- Writing Python code to implement the desired functionalities\\n- Utilizing Langchain's capabilities to enhance the application's performance and scalability\\n- Ensuring that the code is modular and maintainable\\n\\n### Step 4: Integration and Testing\\nIntegrate the developed features into the existing system and perform thorough testing to ensure functionality and reliability. This includes:\\n- Unit testing individual components\\n- Integration testing to ensure seamless operation within the system\\n- Performance testing to ensure the application meets performance benchmarks\\n\\n### Step 5: Documentation\\nDocument the code and functionalities clearly to ensure that other team members can understand and maintain the application. This includes:\\n- Writing comments and documentation for the code\\n- Creating user manuals or guides if necessary\\n\\n### Step 6: Review and Optimize\\nReview the implemented functionalities for any potential improvements or optimizations. This involves:\\n- Code review for quality and adherence to best practices\\n- Optimizing algorithms and code for better performance\\n\\n### Step 7: Deployment\\nPrepare the application for deployment by ensuring all components are ready and tested. This includes:\\n- Setting up deployment scripts or processes\\n- Ensuring that the application is secure and scalable\\n\\nBy following these steps, we can effectively develop the core functionalities of the application using Langchain. If you have specific requirements or features in mind, please provide them so that I can tailor the implementation accordingly.\" additional_kwargs={} response_metadata={}"
        },
        {
          "type": "SystemMessage",
          "content": "content='Agent specialist_Natural Language Processing completed subtask: Integrate NLP components into the application.' additional_kwargs={} response_metadata={}"
        },
        {
          "type": "AIMessage",
          "content": "content=\"To integrate NLP components into an application using the Langchain framework, we need to follow a structured approach that leverages advanced Natural Language Processing techniques. Here's a detailed plan to achieve this:\\n\\n### 1. **Understand the Langchain Framework**\\n   - **Objective**: Gain a comprehensive understanding of the Langchain framework, its architecture, and its capabilities.\\n   - **Action Items**:\\n     - Review the official Langchain documentation and any available tutorials.\\n     - Explore community forums and discussions to gather insights and best practices.\\n     - Identify the specific modules and components within Langchain that are relevant to NLP tasks.\\n\\n### 2. **Define NLP Requirements**\\n   - **Objective**: Clearly outline the NLP functionalities needed for the application.\\n   - **Action Items**:\\n     - Conduct a requirements analysis to determine the specific NLP tasks (e.g., text classification, sentiment analysis, entity recognition).\\n     - Collaborate with stakeholders to prioritize these tasks based on the application's goals.\\n\\n### 3. **Select Appropriate NLP Models and Techniques**\\n   - **Objective**: Choose the most suitable NLP models and techniques for integration.\\n   - **Action Items**:\\n     - Evaluate different NLP models (e.g., BERT, GPT, Transformer-based models) for their suitability in the context of Langchain.\\n     - Consider factors such as model accuracy, computational efficiency, and scalability.\\n     - Stay updated with the latest advancements in NLP to leverage cutting-edge techniques.\\n\\n### 4. **Integrate NLP Models with Langchain**\\n   - **Objective**: Seamlessly integrate the selected NLP models into the Langchain application.\\n   - **Action Items**:\\n     - Utilize Langchain's modular architecture to incorporate NLP components.\\n     - Develop custom modules or adapt existing ones to fit the application's requirements.\\n     - Ensure that the integration supports scalability and efficient processing of language tasks.\\n\\n### 5. **Test and Optimize NLP Components**\\n   - **Objective**: Validate the performance and accuracy of the integrated NLP components.\\n   - **Action Items**:\\n     - Conduct thorough testing using a diverse set of language data to evaluate model performance.\\n     - Optimize the models for speed and accuracy, considering trade-offs as necessary.\\n     - Implement feedback loops to continuously improve the NLP capabilities based on user interactions and data.\\n\\n### 6. **Documentation and Knowledge Sharing**\\n   - **Objective**: Document the integration process and share knowledge with the team.\\n   - **Action Items**:\\n     - Create detailed documentation outlining the integration steps, challenges faced, and solutions implemented.\\n     - Organize knowledge-sharing sessions to ensure the team is aligned and informed about the NLP components.\\n\\n### Considerations and Limitations\\n- **Scalability**: Ensure that the NLP components can handle large volumes of data efficiently.\\n- **Model Updates**: Plan for regular updates to the NLP models to incorporate new advancements and improve performance.\\n- **Resource Constraints**: Be mindful of computational resources and optimize accordingly to prevent bottlenecks.\\n\\nBy following this structured approach, we can effectively integrate NLP components into the Langchain application, enhancing its language processing capabilities and ensuring it meets the desired objectives.\" additional_kwargs={} response_metadata={}"
        },
        {
          "type": "SystemMessage",
          "content": "content='Agent reviewer_Quality Assurance completed subtask: Conduct quality assurance testing to ensure application stability and performance.' additional_kwargs={} response_metadata={}"
        },
        {
          "type": "AIMessage",
          "content": "content=\"To conduct quality assurance testing for the Langchain application and ensure its stability and performance, I will follow a structured approach based on the provided information and best practices in quality assurance. Here is a detailed plan and recommendations:\\n\\n### Quality Assurance Testing Plan\\n\\n1. **Establish Quality Standards**\\n   - Define clear quality standards and best practices specific to Langchain applications.\\n   - Ensure these standards align with industry best practices and the specific needs of Langchain.\\n\\n2. **Integration Testing**\\n   - Execute integration tests to verify the interactions between different modules of the application.\\n   - Ensure that all modules work together seamlessly without any integration issues.\\n\\n3. **System Testing**\\n   - Conduct system-level tests to validate the overall functionality of the application.\\n   - Ensure that the application meets all specified requirements and functions as expected in a real-world environment.\\n\\n4. **Performance Optimization**\\n   - Analyze the application's performance under various conditions and loads.\\n   - Optimize system performance to ensure the application runs efficiently and effectively.\\n\\n5. **Documentation**\\n   - Document the integration and testing process thoroughly.\\n   - Ensure that all testing procedures, results, and any issues encountered are well-documented for future reference and continuous improvement.\\n\\n6. **Feedback and Iteration**\\n   - Gather feedback from stakeholders and users to identify any areas for improvement.\\n   - Iterate on the application based on feedback and testing results to enhance quality and performance.\\n\\n### Recommendations\\n\\n- **Attention to Detail**: Ensure that all aspects of the application are thoroughly tested, including edge cases and potential failure points.\\n- **Continuous Improvement**: Regularly update testing procedures and standards to incorporate new insights and advancements in Langchain and related technologies.\\n- **Collaboration**: Work closely with the development team to address any issues identified during testing and ensure timely resolution.\\n\\nBy following this plan, we can ensure that the Langchain application is stable, performs well, and meets the quality standards expected by users and stakeholders. If there are any specific areas you would like me to focus on or any additional requirements, please let me know.\" additional_kwargs={} response_metadata={}"
        },
        {
          "type": "SystemMessage",
          "content": "content='Agent planner_Project Management completed subtask: Finalize documentation and user guides for the application.' additional_kwargs={} response_metadata={}"
        },
        {
          "type": "AIMessage",
          "content": "content=\"To finalize the documentation and user guides for the Langchain-based application, we need to create a structured plan that ensures comprehensive and user-friendly documentation. This plan will guide the documentation process, ensuring that all necessary information is captured and presented clearly. Here is a detailed plan to achieve this subtask:\\n\\n### Step 1: Analyze Documentation Requirements\\n- **Action Items:**\\n  - Identify the target audience for the documentation (e.g., developers, end-users, administrators).\\n  - Determine the scope of the documentation, including technical details, user guides, and troubleshooting sections.\\n  - Gather existing documentation and notes from the development team.\\n\\n- **Success Criteria:** A clear understanding of the documentation requirements and target audience.\\n\\n### Step 2: Organize Documentation Structure\\n- **Action Items:**\\n  - Create an outline for the documentation, including sections such as Introduction, Installation, Configuration, Usage, Troubleshooting, and FAQs.\\n  - Define the format and style guidelines for the documentation to ensure consistency.\\n\\n- **Success Criteria:** A well-organized documentation outline and style guide.\\n\\n### Step 3: Draft Technical Documentation\\n- **Action Items:**\\n  - Collaborate with developers to document technical aspects of the application, including architecture, APIs, and integration points.\\n  - Ensure that technical documentation is detailed and accurate, with diagrams and code snippets where applicable.\\n\\n- **Success Criteria:** Comprehensive technical documentation that accurately reflects the application's architecture and functionality.\\n\\n### Step 4: Develop User Guides\\n- **Action Items:**\\n  - Write user guides that provide step-by-step instructions for common tasks and features.\\n  - Include screenshots, examples, and tips to enhance user understanding and engagement.\\n\\n- **Success Criteria:** User guides that are clear, concise, and easy to follow for the intended audience.\\n\\n### Step 5: Review and Revise Documentation\\n- **Action Items:**\\n  - Conduct a peer review of the documentation to identify areas for improvement.\\n  - Revise the documentation based on feedback, ensuring clarity and accuracy.\\n\\n- **Success Criteria:** Documentation that has been reviewed and refined to meet quality standards.\\n\\n### Step 6: Finalize and Publish Documentation\\n- **Action Items:**\\n  - Format the documentation for publication, ensuring it is accessible in various formats (e.g., PDF, HTML).\\n  - Publish the documentation on appropriate platforms, such as the company website or a dedicated documentation portal.\\n\\n- **Success Criteria:** Finalized documentation that is published and accessible to the target audience.\\n\\n### Step 7: Plan for Ongoing Updates\\n- **Action Items:**\\n  - Establish a process for updating the documentation as the application evolves.\\n  - Schedule regular reviews to ensure the documentation remains current and relevant.\\n\\n- **Success Criteria:** A documented process for maintaining and updating the documentation over time.\\n\\nBy following this structured plan, we can ensure that the documentation and user guides for the Langchain-based application are comprehensive, user-friendly, and effectively support the application's users.\" additional_kwargs={} response_metadata={}"
        }
      ]
    }
  },
  "agent_contributions": {},
  "task_schedules": {},
  "external_knowledge": {}
}
--------------------------------------------------------------------------------
        teams.json

Content of C:/AI PROJECT/My Langchain Crew 1\data\teams.json:
{
  "team_1741513386_4482": {
    "id": "team_1741513386_4482",
    "name": "Langchain Application Finalization Team",
    "description": "To finalize the development and deployment of a Langchain-based application",
    "created_at": "2025-03-09T10:43:06.724041",
    "task_description": "Je souhaite cr\u00e9er une \u00e9quipe sp\u00e9cialis\u00e9e dans Langchain pour m'aider \u00e0 finaliser une application",
    "agent_specs": [
      {
        "role": "research",
        "specialization": "Langchain Framework",
        "importance": 8,
        "description": "Responsible for researching the latest updates and best practices in Langchain to ensure the application is built on a solid foundation.",
        "required_skills": [
          "Langchain knowledge",
          "Research skills",
          "Technical documentation analysis"
        ],
        "background_info": null
      },
      {
        "role": "specialist",
        "specialization": "Natural Language Processing",
        "importance": 9,
        "description": "Focuses on implementing and optimizing NLP components within the Langchain application.",
        "required_skills": [
          "NLP algorithms",
          "Langchain integration",
          "Python programming"
        ],
        "background_info": null
      },
      {
        "role": "planner",
        "specialization": "Project Management",
        "importance": 7,
        "description": "Coordinates the project timeline, resources, and ensures all team members are aligned with the project goals.",
        "required_skills": [
          "Project management",
          "Communication",
          "Time management"
        ],
        "background_info": null
      },
      {
        "role": "executor",
        "specialization": "Software Development",
        "importance": 10,
        "description": "Handles the coding and implementation of the Langchain application, ensuring all components are functional and integrated.",
        "required_skills": [
          "Software development",
          "Langchain implementation",
          "Debugging"
        ],
        "background_info": null
      },
      {
        "role": "reviewer",
        "specialization": "Quality Assurance",
        "importance": 8,
        "description": "Conducts thorough testing and validation of the application to ensure it meets quality standards and functions as expected.",
        "required_skills": [
          "Testing methodologies",
          "Attention to detail",
          "Problem-solving"
        ],
        "background_info": null
      }
    ],
    "additional_context": "The team should be familiar with the latest trends in AI and have experience with Langchain to effectively finalize the application."
  }
}
--------------------------------------------------------------------------------
        conversation_history/
    memory/
        conversation_history.py

Content of C:/AI PROJECT/My Langchain Crew 1\memory\conversation_history.py:
"""
Conversation History Module

This module provides functionality for storing, retrieving, and managing conversation
history between agents and users. It maintains context across interactions and
supports persistent storage of conversation data.
"""

import logging
import os
import json
import time
from typing import Dict, Any, List, Optional, Union, Tuple
from datetime import datetime
import uuid

# Try importing LangChain message types
try:
    from langchain_core.messages import (
        AIMessage,
        HumanMessage,
        SystemMessage,
        FunctionMessage,
        ToolMessage,
        BaseMessage
    )
    LANGCHAIN_MESSAGES_AVAILABLE = True
except ImportError:
    LANGCHAIN_MESSAGES_AVAILABLE = False

logger = logging.getLogger(__name__)

class ConversationHistory:
    """
    Manages conversation history between agents and users.
    
    This class stores and retrieves conversation messages, maintains context
    across interactions, and supports persistence to disk for long-running
    conversations.
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        Initialize the conversation history manager.
        
        Args:
            config: Configuration dictionary with history settings
        """
        self.config = config
        self.data_dir = config.get("data_dir", "data")
        self.history_dir = config.get("history_dir", "conversation_history")
        self.max_history_length = config.get("max_history_length", 100)
        self.enable_persistence = config.get("enable_persistence", True)
        self.auto_save = config.get("auto_save", True)
        
        # Create history storage
        self.conversations = {}  # Map of conversation_id to list of messages
        self.metadata = {}  # Map of conversation_id to metadata
        
        # Create data directory if it doesn't exist
        self.history_path = os.path.join(self.data_dir, self.history_dir)
        os.makedirs(self.history_path, exist_ok=True)
        
        # Load existing conversations if persistence is enabled
        if self.enable_persistence:
            self._load_conversations()
        
        logger.debug(f"Initialized ConversationHistory with max_length: {self.max_history_length}")
    
    def add_message(
        self, 
        message: Union[Dict, Any], 
        conversation_id: Optional[str] = None,
        role: Optional[str] = None,
        content: Optional[str] = None
    ) -> str:
        """
        Add a message to the conversation history.
        
        Args:
            message: Message to add (either a dict, BaseMessage object, or will be created from role/content)
            conversation_id: ID of the conversation to add to (created if None)
            role: Role of the message sender (used if message is not a dict or BaseMessage)
            content: Content of the message (used if message is not a dict or BaseMessage)
            
        Returns:
            The conversation ID
        """
        # Generate conversation ID if not provided
        if conversation_id is None:
            conversation_id = str(uuid.uuid4())
        
        # Initialize conversation if it doesn't exist
        if conversation_id not in self.conversations:
            self.conversations[conversation_id] = []
            self.metadata[conversation_id] = {
                "created_at": datetime.now().isoformat(),
                "updated_at": datetime.now().isoformat(),
                "message_count": 0
            }
        
        # Process the message
        processed_message = self._process_message(message, role, content)
        
        # Add message to conversation
        self.conversations[conversation_id].append(processed_message)
        
        # Update metadata
        self.metadata[conversation_id]["updated_at"] = datetime.now().isoformat()
        self.metadata[conversation_id]["message_count"] += 1
        
        # Enforce maximum length
        if len(self.conversations[conversation_id]) > self.max_history_length:
            # Remove oldest messages, keeping the most recent ones
            self.conversations[conversation_id] = self.conversations[conversation_id][-self.max_history_length:]
        
        # Auto-save if enabled
        if self.enable_persistence and self.auto_save:
            self._save_conversation(conversation_id)
        
        return conversation_id
    
    def _process_message(
        self,
        message: Union[Dict, Any],
        role: Optional[str] = None,
        content: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Process a message to ensure it's in a standard format.
        
        Args:
            message: Message to process
            role: Role of the message sender
            content: Content of the message
            
        Returns:
            Processed message dictionary
        """
        # Check message type
        if LANGCHAIN_MESSAGES_AVAILABLE and isinstance(message, BaseMessage):
            # Handle LangChain message types
            processed = {
                "role": self._get_role_from_langchain_message(message),
                "content": message.content,
                "type": message.type,
                "timestamp": datetime.now().isoformat()
            }
            
            # Add additional fields
            if hasattr(message, "additional_kwargs") and message.additional_kwargs:
                processed["additional_kwargs"] = message.additional_kwargs
                
            if hasattr(message, "id") and message.id:
                processed["message_id"] = message.id
                
        elif isinstance(message, dict):
            # Handle dictionary message
            processed = message.copy()
            
            # Ensure required fields
            if "role" not in processed:
                processed["role"] = role or "unknown"
            if "content" not in processed:
                processed["content"] = content or ""
            if "timestamp" not in processed:
                processed["timestamp"] = datetime.now().isoformat()
                
        else:
            # Create new message from role and content
            processed = {
                "role": role or "unknown",
                "content": content or str(message),
                "timestamp": datetime.now().isoformat()
            }
        
        # Add message ID if not present
        if "message_id" not in processed:
            processed["message_id"] = str(uuid.uuid4())
            
        return processed
    
    def _get_role_from_langchain_message(self, message: Any) -> str:
        """
        Get the role from a LangChain message.
        
        Args:
            message: LangChain message
            
        Returns:
            Role string
        """
        if isinstance(message, AIMessage):
            return "assistant"
        elif isinstance(message, HumanMessage):
            return "user"
        elif isinstance(message, SystemMessage):
            return "system"
        elif isinstance(message, FunctionMessage):
            return "function"
        elif isinstance(message, ToolMessage):
            return "tool"
        else:
            return "unknown"
    
    def get_history(
        self, 
        conversation_id: str, 
        limit: Optional[int] = None, 
        as_langchain_messages: bool = False
    ) -> List[Any]:
        """
        Get the conversation history.
        
        Args:
            conversation_id: ID of the conversation
            limit: Maximum number of messages to return (default: all)
            as_langchain_messages: Whether to return LangChain message objects
            
        Returns:
            List of messages
        """
        # Check if conversation exists
        if conversation_id not in self.conversations:
            logger.warning(f"Conversation {conversation_id} not found")
            return []
        
        # Get messages
        messages = self.conversations[conversation_id]
        
        # Apply limit if specified
        if limit is not None:
            messages = messages[-limit:]
        
        # Convert to LangChain messages if requested
        if as_langchain_messages and LANGCHAIN_MESSAGES_AVAILABLE:
            return self._convert_to_langchain_messages(messages)
        
        return messages
    
    def _convert_to_langchain_messages(self, messages: List[Dict[str, Any]]) -> List[Any]:
        """
        Convert message dictionaries to LangChain message objects.
        
        Args:
            messages: List of message dictionaries
            
        Returns:
            List of LangChain message objects
        """
        langchain_messages = []
        
        for message in messages:
            role = message.get("role", "unknown")
            content = message.get("content", "")
            additional_kwargs = message.get("additional_kwargs", {})
            
            # Create appropriate message type
            if role == "assistant":
                langchain_messages.append(AIMessage(content=content, additional_kwargs=additional_kwargs))
            elif role == "user":
                langchain_messages.append(HumanMessage(content=content, additional_kwargs=additional_kwargs))
            elif role == "system":
                langchain_messages.append(SystemMessage(content=content, additional_kwargs=additional_kwargs))
            elif role == "function":
                langchain_messages.append(FunctionMessage(
                    content=content,
                    name=additional_kwargs.get("name", "unknown_function"),
                    additional_kwargs=additional_kwargs
                ))
            elif role == "tool":
                langchain_messages.append(ToolMessage(
                    content=content,
                    tool_call_id=additional_kwargs.get("tool_call_id", "unknown_tool"),
                    additional_kwargs=additional_kwargs
                ))
            else:
                # Default to human message for unknown types
                langchain_messages.append(HumanMessage(content=content, additional_kwargs=additional_kwargs))
        
        return langchain_messages
    
    def create_conversation(self, metadata: Optional[Dict[str, Any]] = None) -> str:
        """
        Create a new conversation.
        
        Args:
            metadata: Optional metadata for the conversation
            
        Returns:
            New conversation ID
        """
        conversation_id = str(uuid.uuid4())
        
        # Initialize conversation
        self.conversations[conversation_id] = []
        self.metadata[conversation_id] = {
            "created_at": datetime.now().isoformat(),
            "updated_at": datetime.now().isoformat(),
            "message_count": 0
        }
        
        # Add additional metadata if provided
        if metadata:
            self.metadata[conversation_id].update(metadata)
        
        # Save if persistence is enabled
        if self.enable_persistence and self.auto_save:
            self._save_conversation(conversation_id)
        
        logger.debug(f"Created new conversation with ID: {conversation_id}")
        return conversation_id
    
    def delete_conversation(self, conversation_id: str) -> bool:
        """
        Delete a conversation.
        
        Args:
            conversation_id: ID of the conversation to delete
            
        Returns:
            True if successful, False otherwise
        """
        # Check if conversation exists
        if conversation_id not in self.conversations:
            logger.warning(f"Conversation {conversation_id} not found, cannot delete")
            return False
        
        # Delete from memory
        del self.conversations[conversation_id]
        del self.metadata[conversation_id]
        
        # Delete from disk if persistence is enabled
        if self.enable_persistence:
            conversation_file = os.path.join(self.history_path, f"{conversation_id}.json")
            if os.path.exists(conversation_file):
                try:
                    os.remove(conversation_file)
                except Exception as e:
                    logger.error(f"Error deleting conversation file: {str(e)}")
        
        logger.debug(f"Deleted conversation with ID: {conversation_id}")
        return True
    
    def update_metadata(self, conversation_id: str, metadata: Dict[str, Any]) -> bool:
        """
        Update the metadata for a conversation.
        
        Args:
            conversation_id: ID of the conversation
            metadata: Metadata to update
            
        Returns:
            True if successful, False otherwise
        """
        # Check if conversation exists
        if conversation_id not in self.metadata:
            logger.warning(f"Conversation {conversation_id} not found, cannot update metadata")
            return False
        
        # Update metadata
        self.metadata[conversation_id].update(metadata)
        
        # Save if persistence is enabled
        if self.enable_persistence and self.auto_save:
            self._save_conversation(conversation_id)
        
        logger.debug(f"Updated metadata for conversation: {conversation_id}")
        return True
    
    def get_metadata(self, conversation_id: str) -> Optional[Dict[str, Any]]:
        """
        Get the metadata for a conversation.
        
        Args:
            conversation_id: ID of the conversation
            
        Returns:
            Metadata dictionary or None if not found
        """
        if conversation_id not in self.metadata:
            logger.warning(f"Conversation {conversation_id} not found, cannot get metadata")
            return None
            
        return self.metadata[conversation_id]
    
    def list_conversations(self) -> List[Dict[str, Any]]:
        """
        List all conversations.
        
        Returns:
            List of conversation summaries
        """
        conversations = []
        
        for conversation_id, metadata in self.metadata.items():
            # Create summary
            conversation_summary = {
                "conversation_id": conversation_id,
                "created_at": metadata.get("created_at"),
                "updated_at": metadata.get("updated_at"),
                "message_count": metadata.get("message_count", 0)
            }
            
            # Add custom metadata fields
            for key, value in metadata.items():
                if key not in ["created_at", "updated_at", "message_count"]:
                    conversation_summary[key] = value
            
            conversations.append(conversation_summary)
        
        # Sort by updated_at (newest first)
        conversations.sort(key=lambda x: x.get("updated_at", ""), reverse=True)
        
        return conversations
    
    def clear_history(self, conversation_id: str) -> bool:
        """
        Clear the history for a conversation while keeping the metadata.
        
        Args:
            conversation_id: ID of the conversation to clear
            
        Returns:
            True if successful, False otherwise
        """
        # Check if conversation exists
        if conversation_id not in self.conversations:
            logger.warning(f"Conversation {conversation_id} not found, cannot clear")
            return False
        
        # Clear messages but keep metadata
        self.conversations[conversation_id] = []
        
        # Update metadata
        self.metadata[conversation_id]["updated_at"] = datetime.now().isoformat()
        self.metadata[conversation_id]["message_count"] = 0
        
        # Save if persistence is enabled
        if self.enable_persistence and self.auto_save:
            self._save_conversation(conversation_id)
        
        logger.debug(f"Cleared conversation history for: {conversation_id}")
        return True
    
    def save_all(self) -> bool:
        """
        Save all conversations to disk.
        
        Returns:
            True if successful, False otherwise
        """
        if not self.enable_persistence:
            logger.warning("Persistence is disabled, not saving conversations")
            return False
        
        success = True
        
        for conversation_id in self.conversations:
            if not self._save_conversation(conversation_id):
                success = False
        
        return success
    
    def _save_conversation(self, conversation_id: str) -> bool:
        """
        Save a conversation to disk.
        
        Args:
            conversation_id: ID of the conversation to save
            
        Returns:
            True if successful, False otherwise
        """
        if not self.enable_persistence:
            return False
            
        try:
            # Prepare data for saving
            data = {
                "conversation_id": conversation_id,
                "metadata": self.metadata.get(conversation_id, {}),
                "messages": self.conversations.get(conversation_id, [])
            }
            
            # Save to file
            file_path = os.path.join(self.history_path, f"{conversation_id}.json")
            with open(file_path, 'w') as f:
                json.dump(data, f, indent=2)
                
            logger.debug(f"Saved conversation {conversation_id} to {file_path}")
            return True
            
        except Exception as e:
            logger.error(f"Error saving conversation {conversation_id}: {str(e)}")
            return False
    
    def _load_conversations(self):
        """Load all conversations from disk."""
        try:
            # Get all JSON files in the history directory
            for filename in os.listdir(self.history_path):
                if filename.endswith(".json"):
                    file_path = os.path.join(self.history_path, filename)
                    
                    try:
                        with open(file_path, 'r') as f:
                            data = json.load(f)
                            
                        # Extract data
                        conversation_id = data.get("conversation_id")
                        metadata = data.get("metadata", {})
                        messages = data.get("messages", [])
                        
                        # Store in memory
                        if conversation_id:
                            self.conversations[conversation_id] = messages
                            self.metadata[conversation_id] = metadata
                            
                    except Exception as e:
                        logger.error(f"Error loading conversation from {file_path}: {str(e)}")
            
            logger.info(f"Loaded {len(self.conversations)} conversations from disk")
            
        except Exception as e:
            logger.error(f"Error loading conversations: {str(e)}")
    
    def export_conversation(self, conversation_id: str, format: str = "json") -> Optional[str]:
        """
        Export a conversation to a specific format.
        
        Args:
            conversation_id: ID of the conversation to export
            format: Export format (json, text)
            
        Returns:
            Exported conversation string or None if failed
        """
        # Check if conversation exists
        if conversation_id not in self.conversations:
            logger.warning(f"Conversation {conversation_id} not found, cannot export")
            return None
        
        try:
            messages = self.conversations[conversation_id]
            metadata = self.metadata[conversation_id]
            
            if format.lower() == "json":
                # Export as JSON
                data = {
                    "conversation_id": conversation_id,
                    "metadata": metadata,
                    "messages": messages
                }
                
                return json.dumps(data, indent=2)
                
            elif format.lower() == "text":
                # Export as plain text
                lines = [f"Conversation: {conversation_id}"]
                lines.append("-" * 50)
                
                # Add metadata
                lines.append("Metadata:")
                for key, value in metadata.items():
                    lines.append(f"  {key}: {value}")
                
                lines.append("-" * 50)
                lines.append("Messages:")
                
                # Add messages
                for message in messages:
                    role = message.get("role", "unknown")
                    content = message.get("content", "")
                    timestamp = message.get("timestamp", "")
                    
                    lines.append(f"[{timestamp}] {role.upper()}: {content}")
                
                return "\n".join(lines)
                
            else:
                logger.error(f"Unsupported export format: {format}")
                return None
                
        except Exception as e:
            logger.error(f"Error exporting conversation {conversation_id}: {str(e)}")
            return None
    
    def import_conversation(self, data: str, format: str = "json") -> Optional[str]:
        """
        Import a conversation from a specific format.
        
        Args:
            data: Conversation data to import
            format: Import format (json)
            
        Returns:
            Imported conversation ID or None if failed
        """
        try:
            if format.lower() == "json":
                # Import from JSON
                json_data = json.loads(data)
                
                conversation_id = json_data.get("conversation_id", str(uuid.uuid4()))
                metadata = json_data.get("metadata", {})
                messages = json_data.get("messages", [])
                
                # Store in memory
                self.conversations[conversation_id] = messages
                self.metadata[conversation_id] = metadata
                
                # Save if persistence is enabled
                if self.enable_persistence and self.auto_save:
                    self._save_conversation(conversation_id)
                
                logger.info(f"Imported conversation with ID: {conversation_id}")
                return conversation_id
                
            else:
                logger.error(f"Unsupported import format: {format}")
                return None
                
        except Exception as e:
            logger.error(f"Error importing conversation: {str(e)}")
            return None
    
    def get_last_message(self, conversation_id: str) -> Optional[Dict[str, Any]]:
        """
        Get the last message from a conversation.
        
        Args:
            conversation_id: ID of the conversation
            
        Returns:
            Last message or None if conversation is empty or not found
        """
        # Check if conversation exists
        if conversation_id not in self.conversations:
            logger.warning(f"Conversation {conversation_id} not found")
            return None
            
        # Check if conversation has messages
        messages = self.conversations[conversation_id]
        if not messages:
            logger.warning(f"Conversation {conversation_id} has no messages")
            return None
            
        return messages[-1]
    
    def get_last_n_messages(
        self, 
        conversation_id: str, 
        n: int, 
        as_langchain_messages: bool = False
    ) -> List[Any]:
        """
        Get the last N messages from a conversation.
        
        Args:
            conversation_id: ID of the conversation
            n: Number of messages to get
            as_langchain_messages: Whether to return LangChain message objects
            
        Returns:
            List of messages
        """
        return self.get_history(
            conversation_id=conversation_id,
            limit=n,
            as_langchain_messages=as_langchain_messages
        )
--------------------------------------------------------------------------------
        team_memory.py

Content of C:/AI PROJECT/My Langchain Crew 1\memory\team_memory.py:
"""
Team Memory Module

This module provides a shared memory system for the agent team, allowing agents to
store and retrieve information throughout the execution of tasks. It enables
persistent context and knowledge sharing between different agents.
"""

import logging
import time
import json
import os
from typing import Dict, Any, List, Optional, Union
from datetime import datetime

logger = logging.getLogger(__name__)

class TeamMemory:
    """
    Shared memory system for the agent team.
    
    TeamMemory provides a central repository for shared information,
    allowing agents to store and retrieve data across multiple interactions.
    It supports different memory types, persistence, and efficient retrieval.
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        Initialize the team memory system.
        
        Args:
            config: Configuration dictionary with memory settings
        """
        self.config = config
        self.data_dir = config.get("data_dir", "data")
        self.memory_file = config.get("memory_file", "team_memory.json")
        self.max_entries = config.get("max_entries", 1000)
        self.enable_persistence = config.get("enable_persistence", True)
        
        # Initialize memory storage
        self.working_memory = {}  # Short-term memory for current task
        self.long_term_memory = {}  # Persistent memory across tasks
        self.agent_memories = {}  # Agent-specific memories
        self.task_memories = {}  # Task-specific memories
        
        # Create data directory if it doesn't exist
        if self.enable_persistence:
            os.makedirs(self.data_dir, exist_ok=True)
            self._load_from_disk()
        
        logger.debug("Initialized TeamMemory")
    
    def store(self, key: str, value: Any, memory_type: str = "working", metadata: Optional[Dict[str, Any]] = None) -> bool:
        """
        Store a value in memory.
        
        Args:
            key: Key to store the value under
            value: Value to store
            memory_type: Type of memory ("working", "long_term", "agent", "task")
            metadata: Optional metadata about the value
            
        Returns:
            True if successful, False otherwise
        """
        try:
            # Prepare the memory entry
            entry = {
                "value": value,
                "timestamp": datetime.now().isoformat(),
                "metadata": metadata or {}
            }
            
            # Store in the appropriate memory
            if memory_type == "working":
                self.working_memory[key] = entry
            elif memory_type == "long_term":
                self.long_term_memory[key] = entry
            elif memory_type == "agent":
                agent_id = metadata.get("agent_id")
                if not agent_id:
                    logger.error("Agent ID required for agent memory")
                    return False
                
                if agent_id not in self.agent_memories:
                    self.agent_memories[agent_id] = {}
                
                self.agent_memories[agent_id][key] = entry
            elif memory_type == "task":
                task_id = metadata.get("task_id")
                if not task_id:
                    logger.error("Task ID required for task memory")
                    return False
                
                if task_id not in self.task_memories:
                    self.task_memories[task_id] = {}
                
                self.task_memories[task_id][key] = entry
            else:
                logger.error(f"Unknown memory type: {memory_type}")
                return False
            
            # Enforce maximum entries limit
            self._enforce_limits()
            
            # Persist memory if enabled
            if self.enable_persistence and memory_type != "working":
                self._save_to_disk()
            
            logger.debug(f"Stored value with key '{key}' in {memory_type} memory")
            return True
            
        except Exception as e:
            logger.error(f"Error storing value in memory: {str(e)}")
            return False
    
    def retrieve(self, key: str, memory_type: str = "working", metadata: Optional[Dict[str, Any]] = None) -> Optional[Any]:
        """
        Retrieve a value from memory.
        
        Args:
            key: Key to retrieve
            memory_type: Type of memory to retrieve from
            metadata: Optional metadata for specific memory types
            
        Returns:
            The stored value or None if not found
        """
        try:
            # Retrieve from the appropriate memory
            if memory_type == "working":
                entry = self.working_memory.get(key)
            elif memory_type == "long_term":
                entry = self.long_term_memory.get(key)
            elif memory_type == "agent":
                agent_id = metadata.get("agent_id")
                if not agent_id:
                    logger.error("Agent ID required for agent memory")
                    return None
                
                if agent_id not in self.agent_memories:
                    return None
                
                entry = self.agent_memories[agent_id].get(key)
            elif memory_type == "task":
                task_id = metadata.get("task_id")
                if not task_id:
                    logger.error("Task ID required for task memory")
                    return None
                
                if task_id not in self.task_memories:
                    return None
                
                entry = self.task_memories[task_id].get(key)
            else:
                logger.error(f"Unknown memory type: {memory_type}")
                return None
            
            # Return the value if found
            if entry:
                return entry["value"]
            
            return None
            
        except Exception as e:
            logger.error(f"Error retrieving value from memory: {str(e)}")
            return None
    
    def update(self, key: str, value: Any, memory_type: str = "working", metadata: Optional[Dict[str, Any]] = None) -> bool:
        """
        Update an existing value in memory.
        
        Args:
            key: Key to update
            value: New value
            memory_type: Type of memory to update
            metadata: Optional metadata
            
        Returns:
            True if successful, False otherwise
        """
        # Check if the key exists
        exists = self.retrieve(key, memory_type, metadata) is not None
        
        # If it exists, store the new value
        if exists:
            return self.store(key, value, memory_type, metadata)
        
        logger.warning(f"Key '{key}' not found in {memory_type} memory, cannot update")
        return False
    
    def delete(self, key: str, memory_type: str = "working", metadata: Optional[Dict[str, Any]] = None) -> bool:
        """
        Delete a value from memory.
        
        Args:
            key: Key to delete
            memory_type: Type of memory to delete from
            metadata: Optional metadata for specific memory types
            
        Returns:
            True if successful, False otherwise
        """
        try:
            # Delete from the appropriate memory
            if memory_type == "working":
                if key in self.working_memory:
                    del self.working_memory[key]
                    return True
            elif memory_type == "long_term":
                if key in self.long_term_memory:
                    del self.long_term_memory[key]
                    if self.enable_persistence:
                        self._save_to_disk()
                    return True
            elif memory_type == "agent":
                agent_id = metadata.get("agent_id")
                if not agent_id:
                    logger.error("Agent ID required for agent memory")
                    return False
                
                if agent_id in self.agent_memories and key in self.agent_memories[agent_id]:
                    del self.agent_memories[agent_id][key]
                    if self.enable_persistence:
                        self._save_to_disk()
                    return True
            elif memory_type == "task":
                task_id = metadata.get("task_id")
                if not task_id:
                    logger.error("Task ID required for task memory")
                    return False
                
                if task_id in self.task_memories and key in self.task_memories[task_id]:
                    del self.task_memories[task_id][key]
                    if self.enable_persistence:
                        self._save_to_disk()
                    return True
            else:
                logger.error(f"Unknown memory type: {memory_type}")
                return False
            
            logger.warning(f"Key '{key}' not found in {memory_type} memory, nothing to delete")
            return False
            
        except Exception as e:
            logger.error(f"Error deleting value from memory: {str(e)}")
            return False
    
    def search_memory(self, query: str, memory_types: List[str] = None) -> List[Dict[str, Any]]:
        """
        Search for values in memory that match the query.
        This is a simple string matching search.
        
        Args:
            query: String to search for
            memory_types: List of memory types to search in (default all)
            
        Returns:
            List of matching memory entries
        """
        if memory_types is None:
            memory_types = ["working", "long_term", "agent", "task"]
            
        results = []
        
        # Helper function to search in a memory dictionary
        def search_dict(memory_dict, memory_type, extra_meta=None):
            for key, entry in memory_dict.items():
                value = entry["value"]
                value_str = str(value)
                
                if query.lower() in key.lower() or query.lower() in value_str.lower():
                    result = {
                        "key": key,
                        "value": value,
                        "memory_type": memory_type,
                        "timestamp": entry["timestamp"],
                        "metadata": entry["metadata"].copy()
                    }
                    
                    # Add extra metadata if provided
                    if extra_meta:
                        result["metadata"].update(extra_meta)
                    
                    results.append(result)
        
        # Search in each requested memory type
        if "working" in memory_types:
            search_dict(self.working_memory, "working")
        
        if "long_term" in memory_types:
            search_dict(self.long_term_memory, "long_term")
        
        if "agent" in memory_types:
            for agent_id, agent_memory in self.agent_memories.items():
                search_dict(agent_memory, "agent", {"agent_id": agent_id})
        
        if "task" in memory_types:
            for task_id, task_memory in self.task_memories.items():
                search_dict(task_memory, "task", {"task_id": task_id})
        
        return results
    
    def list_keys(self, memory_type: str = "working", metadata: Optional[Dict[str, Any]] = None) -> List[str]:
        """
        List all keys in a specific memory type.
        
        Args:
            memory_type: Type of memory to list keys from
            metadata: Optional metadata for specific memory types
            
        Returns:
            List of keys
        """
        try:
            # Get keys from the appropriate memory
            if memory_type == "working":
                return list(self.working_memory.keys())
            elif memory_type == "long_term":
                return list(self.long_term_memory.keys())
            elif memory_type == "agent":
                agent_id = metadata.get("agent_id")
                if not agent_id:
                    logger.error("Agent ID required for agent memory")
                    return []
                
                if agent_id not in self.agent_memories:
                    return []
                
                return list(self.agent_memories[agent_id].keys())
            elif memory_type == "task":
                task_id = metadata.get("task_id")
                if not task_id:
                    logger.error("Task ID required for task memory")
                    return []
                
                if task_id not in self.task_memories:
                    return []
                
                return list(self.task_memories[task_id].keys())
            else:
                logger.error(f"Unknown memory type: {memory_type}")
                return []
                
        except Exception as e:
            logger.error(f"Error listing keys: {str(e)}")
            return []
    
    def clear_memory(self, memory_type: str = "working", metadata: Optional[Dict[str, Any]] = None) -> bool:
        """
        Clear all entries from a specific memory type.
        
        Args:
            memory_type: Type of memory to clear
            metadata: Optional metadata for specific memory types
            
        Returns:
            True if successful, False otherwise
        """
        try:
            # Clear the appropriate memory
            if memory_type == "working":
                self.working_memory = {}
                logger.info("Cleared working memory")
                return True
            elif memory_type == "long_term":
                self.long_term_memory = {}
                if self.enable_persistence:
                    self._save_to_disk()
                logger.info("Cleared long-term memory")
                return True
            elif memory_type == "agent":
                agent_id = metadata.get("agent_id")
                if not agent_id:
                    logger.error("Agent ID required for agent memory")
                    return False
                
                if agent_id in self.agent_memories:
                    self.agent_memories[agent_id] = {}
                    if self.enable_persistence:
                        self._save_to_disk()
                    logger.info(f"Cleared memory for agent {agent_id}")
                    return True
                
                logger.warning(f"Agent {agent_id} not found in memory")
                return False
            elif memory_type == "task":
                task_id = metadata.get("task_id")
                if not task_id:
                    logger.error("Task ID required for task memory")
                    return False
                
                if task_id in self.task_memories:
                    self.task_memories[task_id] = {}
                    if self.enable_persistence:
                        self._save_to_disk()
                    logger.info(f"Cleared memory for task {task_id}")
                    return True
                
                logger.warning(f"Task {task_id} not found in memory")
                return False
            elif memory_type == "all":
                self.working_memory = {}
                self.long_term_memory = {}
                self.agent_memories = {}
                self.task_memories = {}
                if self.enable_persistence:
                    self._save_to_disk()
                logger.info("Cleared all memory")
                return True
            else:
                logger.error(f"Unknown memory type: {memory_type}")
                return False
                
        except Exception as e:
            logger.error(f"Error clearing memory: {str(e)}")
            return False
    
    def _enforce_limits(self):
        """Enforce memory size limits by removing oldest entries if needed."""
        # Check working memory
        if len(self.working_memory) > self.max_entries:
            # Sort by timestamp and keep only the most recent entries
            sorted_entries = sorted(
                self.working_memory.items(),
                key=lambda x: x[1]["timestamp"],
                reverse=True
            )
            self.working_memory = dict(sorted_entries[:self.max_entries])
        
        # Check long-term memory
        if len(self.long_term_memory) > self.max_entries:
            sorted_entries = sorted(
                self.long_term_memory.items(),
                key=lambda x: x[1]["timestamp"],
                reverse=True
            )
            self.long_term_memory = dict(sorted_entries[:self.max_entries])
    
    def _save_to_disk(self):
        """Save memory to disk for persistence."""
        if not self.enable_persistence:
            return
            
        try:
            # Create the memory data structure
            memory_data = {
                "long_term_memory": self.long_term_memory,
                "agent_memories": self.agent_memories,
                "task_memories": self.task_memories,
                "last_saved": datetime.now().isoformat()
            }
            
            # Save to file
            file_path = os.path.join(self.data_dir, self.memory_file)
            with open(file_path, 'w') as f:
                json.dump(memory_data, f, indent=2)
                
            logger.debug(f"Saved memory to {file_path}")
            
        except Exception as e:
            logger.error(f"Error saving memory to disk: {str(e)}")
    
    def _load_from_disk(self):
        """Load memory from disk."""
        if not self.enable_persistence:
            return
            
        try:
            file_path = os.path.join(self.data_dir, self.memory_file)
            
            if os.path.exists(file_path):
                with open(file_path, 'r') as f:
                    memory_data = json.load(f)
                    
                self.long_term_memory = memory_data.get("long_term_memory", {})
                self.agent_memories = memory_data.get("agent_memories", {})
                self.task_memories = memory_data.get("task_memories", {})
                
                logger.info(f"Loaded memory from {file_path}")
            else:
                logger.info(f"No memory file found at {file_path}, starting with empty memory")
                
        except Exception as e:
            logger.error(f"Error loading memory from disk: {str(e)}")
    
    def get_memory_stats(self) -> Dict[str, Any]:
        """
        Get statistics about the current memory usage.
        
        Returns:
            Dictionary with memory statistics
        """
        stats = {
            "working_memory_size": len(self.working_memory),
            "long_term_memory_size": len(self.long_term_memory),
            "agent_memories_count": len(self.agent_memories),
            "task_memories_count": len(self.task_memories),
            "total_agent_memory_entries": sum(len(mem) for mem in self.agent_memories.values()),
            "total_task_memory_entries": sum(len(mem) for mem in self.task_memories.values())
        }
        
        return stats
    
    def export_memory(self, memory_type: str = "all") -> Dict[str, Any]:
        """
        Export memory data for the specified memory type.
        
        Args:
            memory_type: Type of memory to export
            
        Returns:
            Dictionary with exported memory data
        """
        export_data = {
            "timestamp": datetime.now().isoformat(),
            "memory_type": memory_type
        }
        
        if memory_type == "working" or memory_type == "all":
            export_data["working_memory"] = self.working_memory
            
        if memory_type == "long_term" or memory_type == "all":
            export_data["long_term_memory"] = self.long_term_memory
            
        if memory_type == "agent" or memory_type == "all":
            export_data["agent_memories"] = self.agent_memories
            
        if memory_type == "task" or memory_type == "all":
            export_data["task_memories"] = self.task_memories
        
        return export_data
    
    def import_memory(self, import_data: Dict[str, Any], overwrite: bool = False) -> bool:
        """
        Import memory data.
        
        Args:
            import_data: Dictionary with memory data to import
            overwrite: Whether to overwrite existing memory
            
        Returns:
            True if successful, False otherwise
        """
        try:
            memory_type = import_data.get("memory_type", "unknown")
            
            if memory_type == "working" or memory_type == "all":
                if overwrite:
                    self.working_memory = import_data.get("working_memory", {})
                else:
                    self.working_memory.update(import_data.get("working_memory", {}))
                    
            if memory_type == "long_term" or memory_type == "all":
                if overwrite:
                    self.long_term_memory = import_data.get("long_term_memory", {})
                else:
                    self.long_term_memory.update(import_data.get("long_term_memory", {}))
                    
            if memory_type == "agent" or memory_type == "all":
                agent_memories = import_data.get("agent_memories", {})
                if overwrite:
                    self.agent_memories = agent_memories
                else:
                    for agent_id, memory in agent_memories.items():
                        if agent_id not in self.agent_memories:
                            self.agent_memories[agent_id] = {}
                        self.agent_memories[agent_id].update(memory)
                    
            if memory_type == "task" or memory_type == "all":
                task_memories = import_data.get("task_memories", {})
                if overwrite:
                    self.task_memories = task_memories
                else:
                    for task_id, memory in task_memories.items():
                        if task_id not in self.task_memories:
                            self.task_memories[task_id] = {}
                        self.task_memories[task_id].update(memory)
            
            # Enforce limits after import
            self._enforce_limits()
            
            # Save to disk if enabled
            if self.enable_persistence:
                self._save_to_disk()
                
            logger.info(f"Successfully imported {memory_type} memory")
            return True
            
        except Exception as e:
            logger.error(f"Error importing memory: {str(e)}")
            return False
--------------------------------------------------------------------------------
        vector_store.py

Content of C:/AI PROJECT/My Langchain Crew 1\memory\vector_store.py:
"""
Vector Store Module

This module provides vector storage capabilities for semantic search and retrieval.
It allows for efficient storage and querying of embeddings derived from text,
supporting similarity-based information retrieval across the agent system.
"""

import logging
import os
import json
import time
from typing import Dict, Any, List, Optional, Union, Tuple
from pathlib import Path
import numpy as np
import shutil

# Try to import different vector database libraries
try:
    from langchain_community.vectorstores import Chroma
    CHROMA_AVAILABLE = True
except ImportError:
    CHROMA_AVAILABLE = False

try:
    from langchain_openai import OpenAIEmbeddings
    OPENAI_EMBEDDINGS_AVAILABLE = True
except ImportError:
    OPENAI_EMBEDDINGS_AVAILABLE = False

try:
    from langchain.embeddings import HuggingFaceEmbeddings
    HUGGINGFACE_EMBEDDINGS_AVAILABLE = True
except ImportError:
    HUGGINGFACE_EMBEDDINGS_AVAILABLE = False

logger = logging.getLogger(__name__)

class VectorStore:
    """
    Vector store for efficient storage and retrieval of embeddings.
    
    This class provides vector storage capabilities for semantic search
    and similarity-based retrieval of information. It supports multiple
    embedding models and vector database backends.
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        Initialize the vector store.
        
        Args:
            config: Configuration dictionary with vector store settings
        """
        self.config = config
        self.data_dir = config.get("data_dir", "data")
        self.vector_dir = config.get("vector_dir", "vector_store")
        self.embedding_model = config.get("embedding_model", "text-embedding-3-small")
        self.embedding_dimension = config.get("embedding_dimension", 1536)  # Default for OpenAI embeddings
        self.similarity_threshold = config.get("similarity_threshold", 0.7)
        self.vector_db_type = config.get("vector_db_type", "chroma")
        
        # Ensure data directory exists
        self.vector_store_path = os.path.join(self.data_dir, self.vector_dir)
        os.makedirs(self.vector_store_path, exist_ok=True)
        
        # Initialize embedding function and vector store
        self.embedding_function = self._initialize_embedding_function()
        self.vector_store = self._initialize_vector_store()
        
        logger.debug(f"Initialized VectorStore with model: {self.embedding_model}")
    
    def _initialize_embedding_function(self):
        """
        Initialize the embedding function based on configuration.
        
        Returns:
            Initialized embedding function
        """
        embedding_function = None
        
        # Try to initialize OpenAI embeddings
        if "openai" in self.embedding_model.lower() and OPENAI_EMBEDDINGS_AVAILABLE:
            try:
                embedding_function = OpenAIEmbeddings(model=self.embedding_model)
                logger.info(f"Initialized OpenAI embeddings: {self.embedding_model}")
            except Exception as e:
                logger.error(f"Error initializing OpenAI embeddings: {str(e)}")
        
        # Try to initialize HuggingFace embeddings if OpenAI embeddings are not available
        elif HUGGINGFACE_EMBEDDINGS_AVAILABLE:
            try:
                # Default to a common model if specific model not specified
                model_name = self.embedding_model
                if "openai" in model_name.lower():
                    model_name = "sentence-transformers/all-mpnet-base-v2"
                
                embedding_function = HuggingFaceEmbeddings(model_name=model_name)
                logger.info(f"Initialized HuggingFace embeddings: {model_name}")
            except Exception as e:
                logger.error(f"Error initializing HuggingFace embeddings: {str(e)}")
        
        # Fallback to a simple embedding function if all else fails
        if embedding_function is None:
            logger.warning("No embedding libraries available, using simple fallback embeddings")
            embedding_function = SimpleFallbackEmbeddings(dim=self.embedding_dimension)
        
        return embedding_function
    
    def _initialize_vector_store(self):
        """
        Initialize the vector store based on configuration.
        
        Returns:
            Initialized vector store
        """
        vector_store = None
        
        # Check if Chroma is available and configured
        if self.vector_db_type.lower() == "chroma" and CHROMA_AVAILABLE:
            try:
                # Check if there's an existing Chroma database
                chroma_dir = os.path.join(self.vector_store_path, "chroma")
                if os.path.exists(chroma_dir) and os.path.isdir(chroma_dir):
                    logger.info(f"Loading existing Chroma vector store from: {chroma_dir}")
                    vector_store = Chroma(
                        persist_directory=chroma_dir,
                        embedding_function=self.embedding_function
                    )
                else:
                    logger.info(f"Creating new Chroma vector store at: {chroma_dir}")
                    vector_store = Chroma(
                        persist_directory=chroma_dir,
                        embedding_function=self.embedding_function
                    )
            except Exception as e:
                logger.error(f"Error initializing Chroma vector store: {str(e)}")
        
        # Fallback to a simple vector store if needed
        if vector_store is None:
            logger.warning("No vector database libraries available, using simple fallback vector store")
            vector_store = SimpleFallbackVectorStore(
                data_dir=self.vector_store_path,
                embedding_function=self.embedding_function,
                similarity_threshold=self.similarity_threshold
            )
        
        return vector_store
    
    def add_texts(
        self, 
        texts: List[str], 
        metadatas: Optional[List[Dict[str, Any]]] = None,
        ids: Optional[List[str]] = None
    ) -> List[str]:
        """
        Add texts to the vector store.
        
        Args:
            texts: List of texts to add
            metadatas: Optional list of metadata dictionaries, one per text
            ids: Optional list of IDs for the texts
            
        Returns:
            List of IDs for the added texts
        """
        try:
            # Ensure metadatas is provided for each text
            if metadatas is None:
                metadatas = [{} for _ in texts]
            
            # Add texts to the vector store
            result_ids = self.vector_store.add_texts(texts=texts, metadatas=metadatas, ids=ids)
            
            # Persist the vector store if it supports it
            if hasattr(self.vector_store, "persist"):
                self.vector_store.persist()
            
            logger.info(f"Added {len(texts)} texts to vector store")
            return result_ids
            
        except Exception as e:
            logger.error(f"Error adding texts to vector store: {str(e)}")
            return []
    
    def similarity_search(
        self, 
        query: str, 
        k: int = 4, 
        filter: Optional[Dict[str, Any]] = None,
        fetch_k: Optional[int] = None
    ) -> List[Dict[str, Any]]:
        """
        Search for documents similar to the query.
        
        Args:
            query: The query text
            k: Number of results to return
            filter: Optional filter criteria
            fetch_k: Optional number of documents to consider before filtering
            
        Returns:
            List of similar documents with content and metadata
        """
        try:
            # Perform similarity search
            if hasattr(self.vector_store, "similarity_search_with_score"):
                docs_and_scores = self.vector_store.similarity_search_with_score(
                    query=query,
                    k=k,
                    filter=filter,
                    fetch_k=fetch_k
                )
                
                # Format results
                results = []
                for doc, score in docs_and_scores:
                    results.append({
                        "content": doc.page_content,
                        "metadata": doc.metadata,
                        "score": score
                    })
                
                return results
            else:
                # Fallback to regular similarity search
                docs = self.vector_store.similarity_search(
                    query=query,
                    k=k,
                    filter=filter,
                    fetch_k=fetch_k
                )
                
                # Format results without scores
                results = []
                for doc in docs:
                    results.append({
                        "content": doc.page_content,
                        "metadata": doc.metadata,
                        "score": None
                    })
                
                return results
                
        except Exception as e:
            logger.error(f"Error performing similarity search: {str(e)}")
            return []
    
    def max_marginal_relevance_search(
        self, 
        query: str, 
        k: int = 4, 
        fetch_k: int = 20,
        lambda_mult: float = 0.5,
        filter: Optional[Dict[str, Any]] = None
    ) -> List[Dict[str, Any]]:
        """
        Search with maximal marginal relevance to balance relevance and diversity.
        
        Args:
            query: The query text
            k: Number of results to return
            fetch_k: Number of documents to consider before filtering for diversity
            lambda_mult: Diversity vs relevance balance factor (0 to 1)
            filter: Optional filter criteria
            
        Returns:
            List of documents balancing relevance and diversity
        """
        try:
            # Check if the vector store supports MMR search
            if hasattr(self.vector_store, "max_marginal_relevance_search"):
                docs = self.vector_store.max_marginal_relevance_search(
                    query=query,
                    k=k,
                    fetch_k=fetch_k,
                    lambda_mult=lambda_mult,
                    filter=filter
                )
                
                # Format results
                results = []
                for doc in docs:
                    results.append({
                        "content": doc.page_content,
                        "metadata": doc.metadata,
                        "score": None
                    })
                
                return results
            else:
                # Fall back to regular similarity search
                logger.warning("Vector store does not support MMR search, falling back to regular search")
                return self.similarity_search(query=query, k=k, filter=filter)
                
        except Exception as e:
            logger.error(f"Error performing MMR search: {str(e)}")
            return []
    
    def delete(self, ids: List[str]) -> bool:
        """
        Delete documents from the vector store by ID.
        
        Args:
            ids: List of document IDs to delete
            
        Returns:
            True if successful, False otherwise
        """
        try:
            # Check if the vector store supports deletion
            if hasattr(self.vector_store, "delete"):
                self.vector_store.delete(ids)
                
                # Persist changes if supported
                if hasattr(self.vector_store, "persist"):
                    self.vector_store.persist()
                
                logger.info(f"Deleted {len(ids)} documents from vector store")
                return True
            else:
                logger.warning("Vector store does not support deletion")
                return False
                
        except Exception as e:
            logger.error(f"Error deleting documents from vector store: {str(e)}")
            return False
    
    def clear(self) -> bool:
        """
        Clear all documents from the vector store.
        
        Returns:
            True if successful, False otherwise
        """
        try:
            # Handle different vector store types
            if self.vector_db_type.lower() == "chroma" and CHROMA_AVAILABLE:
                # For Chroma, we can use the collection's delete method
                if hasattr(self.vector_store, "_collection"):
                    self.vector_store._collection.delete(where={})
                    
                    # Persist changes
                    if hasattr(self.vector_store, "persist"):
                        self.vector_store.persist()
                    
                    logger.info("Cleared all documents from Chroma vector store")
                    return True
                else:
                    # Try to recreate the vector store
                    chroma_dir = os.path.join(self.vector_store_path, "chroma")
                    if os.path.exists(chroma_dir):
                        shutil.rmtree(chroma_dir)
                    
                    self.vector_store = Chroma(
                        persist_directory=chroma_dir,
                        embedding_function=self.embedding_function
                    )
                    
                    logger.info("Recreated Chroma vector store")
                    return True
            
            # For the fallback vector store
            elif isinstance(self.vector_store, SimpleFallbackVectorStore):
                self.vector_store.clear()
                logger.info("Cleared all documents from fallback vector store")
                return True
            
            logger.warning("Vector store clearing not supported for this type")
            return False
            
        except Exception as e:
            logger.error(f"Error clearing vector store: {str(e)}")
            return False
    
    def get_retriever(self, **kwargs):
        """
        Get a retriever interface to the vector store.
        
        Args:
            **kwargs: Additional parameters for the retriever
            
        Returns:
            Retriever object or None if not supported
        """
        try:
            # Check if the vector store supports creating a retriever
            if hasattr(self.vector_store, "as_retriever"):
                return self.vector_store.as_retriever(**kwargs)
            else:
                logger.warning("Vector store does not support retriever interface")
                return None
                
        except Exception as e:
            logger.error(f"Error creating retriever: {str(e)}")
            return None
    
    def count(self) -> int:
        """
        Count the number of documents in the vector store.
        
        Returns:
            Number of documents
        """
        try:
            # Try different methods to get the count
            if hasattr(self.vector_store, "count"):
                return self.vector_store.count()
            elif hasattr(self.vector_store, "_collection") and hasattr(self.vector_store._collection, "count"):
                return self.vector_store._collection.count()
            elif isinstance(self.vector_store, SimpleFallbackVectorStore):
                return self.vector_store.count()
            else:
                logger.warning("Unable to count documents in vector store")
                return -1
                
        except Exception as e:
            logger.error(f"Error counting documents in vector store: {str(e)}")
            return -1


class SimpleFallbackEmbeddings:
    """
    A simple fallback embedding function when no proper embedding libraries are available.
    This is not meant for production use and provides only basic functionality.
    """
    
    def __init__(self, dim: int = 1536):
        """
        Initialize the fallback embeddings.
        
        Args:
            dim: Dimension of the embeddings
        """
        self.dim = dim
        logger.warning(f"Using SimpleFallbackEmbeddings with dimension {dim}")
    
    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """
        Create embeddings for a list of documents.
        
        Args:
            texts: List of texts to embed
            
        Returns:
            List of embeddings as float lists
        """
        embeddings = []
        for text in texts:
            # Create a deterministic but simple embedding based on the text
            # This is NOT a good embedding strategy but works as a fallback
            embedding = self._simple_embedding(text)
            embeddings.append(embedding)
        
        return embeddings
    
    def embed_query(self, text: str) -> List[float]:
        """
        Create an embedding for a query string.
        
        Args:
            text: Query text to embed
            
        Returns:
            Embedding as a list of floats
        """
        return self._simple_embedding(text)
    
    def _simple_embedding(self, text: str) -> List[float]:
        """
        Create a simple deterministic embedding from text.
        
        Args:
            text: Text to embed
            
        Returns:
            Simple embedding vector
        """
        # Use a hash of the text to seed a random number generator
        import hashlib
        import random
        
        # Get deterministic seed from text
        text_hash = hashlib.md5(text.encode()).hexdigest()
        seed = int(text_hash, 16) % (2**32)
        
        # Create a pseudo-random embedding
        random.seed(seed)
        embedding = [random.uniform(-1, 1) for _ in range(self.dim)]
        
        # Normalize the embedding
        norm = sum(x**2 for x in embedding) ** 0.5
        if norm > 0:
            embedding = [x / norm for x in embedding]
        
        return embedding


class SimpleFallbackVectorStore:
    """
    A simple fallback vector store when no proper vector database libraries are available.
    This is not meant for production use and provides only basic functionality.
    """
    
    def __init__(
        self, 
        data_dir: str, 
        embedding_function,
        similarity_threshold: float = 0.7
    ):
        """
        Initialize the fallback vector store.
        
        Args:
            data_dir: Directory to store data
            embedding_function: Function to create embeddings
            similarity_threshold: Threshold for similarity searches
        """
        self.data_dir = data_dir
        self.embedding_function = embedding_function
        self.similarity_threshold = similarity_threshold
        self.vectors = []  # List of (id, embedding, text, metadata) tuples
        self.next_id = 1
        
        # Create data directory
        os.makedirs(data_dir, exist_ok=True)
        
        # Try to load existing data
        self._load()
        
        logger.warning(f"Using SimpleFallbackVectorStore in {data_dir}")
    
    def add_texts(
        self, 
        texts: List[str], 
        metadatas: Optional[List[Dict[str, Any]]] = None,
        ids: Optional[List[str]] = None
    ) -> List[str]:
        """
        Add texts to the vector store.
        
        Args:
            texts: List of texts to add
            metadatas: Optional list of metadata dictionaries
            ids: Optional list of IDs
            
        Returns:
            List of IDs for the added texts
        """
        # Ensure metadatas exists for each text
        if metadatas is None:
            metadatas = [{} for _ in texts]
        
        # Ensure IDs exist for each text
        if ids is None:
            ids = [str(self.next_id + i) for i in range(len(texts))]
            self.next_id += len(texts)
        
        # Get embeddings for texts
        embeddings = self.embedding_function.embed_documents(texts)
        
        # Add to vectors
        for i, (text, embedding, metadata, id) in enumerate(zip(texts, embeddings, metadatas, ids)):
            self.vectors.append((id, embedding, text, metadata))
        
        # Save data
        self._save()
        
        return ids
    
    def similarity_search(
        self, 
        query: str, 
        k: int = 4, 
        filter: Optional[Dict[str, Any]] = None,
        fetch_k: Optional[int] = None
    ) -> List[Dict[str, Any]]:
        """
        Search for documents similar to the query.
        
        Args:
            query: The query text
            k: Number of results to return
            filter: Optional filter criteria
            fetch_k: Ignored in this implementation
            
        Returns:
            List of similar documents
        """
        from langchain_core.documents import Document
        
        # Get query embedding
        query_embedding = self.embedding_function.embed_query(query)
        
        # Calculate similarities
        similarities = []
        for id, embedding, text, metadata in self.vectors:
            # Apply filter if provided
            if filter and not self._matches_filter(metadata, filter):
                continue
                
            # Calculate cosine similarity
            similarity = self._cosine_similarity(query_embedding, embedding)
            similarities.append((id, similarity, text, metadata))
        
        # Sort by similarity (descending)
        similarities.sort(key=lambda x: x[1], reverse=True)
        
        # Get top k results
        top_k = similarities[:k]
        
        # Convert to documents
        documents = []
        for id, similarity, text, metadata in top_k:
            doc = Document(page_content=text, metadata=metadata)
            documents.append(doc)
        
        return documents
    
    def similarity_search_with_score(
        self, 
        query: str, 
        k: int = 4, 
        filter: Optional[Dict[str, Any]] = None,
        fetch_k: Optional[int] = None
    ) -> List[Tuple[Dict[str, Any], float]]:
        """
        Search for documents similar to the query, with similarity scores.
        
        Args:
            query: The query text
            k: Number of results to return
            filter: Optional filter criteria
            fetch_k: Ignored in this implementation
            
        Returns:
            List of (document, score) tuples
        """
        from langchain_core.documents import Document
        
        # Get query embedding
        query_embedding = self.embedding_function.embed_query(query)
        
        # Calculate similarities
        similarities = []
        for id, embedding, text, metadata in self.vectors:
            # Apply filter if provided
            if filter and not self._matches_filter(metadata, filter):
                continue
                
            # Calculate cosine similarity
            similarity = self._cosine_similarity(query_embedding, embedding)
            similarities.append((id, similarity, text, metadata))
        
        # Sort by similarity (descending)
        similarities.sort(key=lambda x: x[1], reverse=True)
        
        # Get top k results
        top_k = similarities[:k]
        
        # Convert to documents with scores
        documents_with_scores = []
        for id, similarity, text, metadata in top_k:
            doc = Document(page_content=text, metadata=metadata)
            documents_with_scores.append((doc, similarity))
        
        return documents_with_scores
    
    def _cosine_similarity(self, a: List[float], b: List[float]) -> float:
        """
        Calculate cosine similarity between two vectors.
        
        Args:
            a: First vector
            b: Second vector
            
        Returns:
            Cosine similarity
        """
        dot_product = sum(x * y for x, y in zip(a, b))
        norm_a = sum(x * x for x in a) ** 0.5
        norm_b = sum(x * x for x in b) ** 0.5
        
        if norm_a == 0 or norm_b == 0:
            return 0
            
        return dot_product / (norm_a * norm_b)
    
    def _matches_filter(self, metadata: Dict[str, Any], filter: Dict[str, Any]) -> bool:
        """
        Check if metadata matches filter criteria.
        
        Args:
            metadata: Metadata to check
            filter: Filter criteria
            
        Returns:
            True if metadata matches filter, False otherwise
        """
        for key, value in filter.items():
            if key not in metadata or metadata[key] != value:
                return False
        return True
    
    def count(self) -> int:
        """
        Count the number of documents in the vector store.
        
        Returns:
            Number of documents
        """
        return len(self.vectors)
    
    def clear(self) -> bool:
        """
        Clear all documents from the vector store.
        
        Returns:
            True if successful
        """
        self.vectors = []
        self._save()
        return True
    
    def _save(self):
        """Save the vector store data to disk."""
        data_path = os.path.join(self.data_dir, "fallback_vectors.json")
        
        # Convert embeddings to lists for JSON serialization
        serializable_vectors = []
        for id, embedding, text, metadata in self.vectors:
            serializable_vectors.append({
                "id": id,
                "embedding": list(embedding),
                "text": text,
                "metadata": metadata
            })
        
        # Save to file
        with open(data_path, 'w') as f:
            json.dump({
                "vectors": serializable_vectors,
                "next_id": self.next_id
            }, f)
    
    def _load(self):
        """Load the vector store data from disk."""
        data_path = os.path.join(self.data_dir, "fallback_vectors.json")
        
        if os.path.exists(data_path):
            try:
                with open(data_path, 'r') as f:
                    data = json.load(f)
                
                # Load vectors
                self.vectors = []
                for item in data.get("vectors", []):
                    self.vectors.append((
                        item["id"],
                        item["embedding"],
                        item["text"],
                        item["metadata"]
                    ))
                
                # Load next ID
                self.next_id = data.get("next_id", 1)
            except Exception as e:
                logger.error(f"Error loading vector store data: {str(e)}")
--------------------------------------------------------------------------------
        __init__.py

Content of C:/AI PROJECT/My Langchain Crew 1\memory\__init__.py:
"""
Memory package.
"""
--------------------------------------------------------------------------------
    output/
        README.md

Content of C:/AI PROJECT/My Langchain Crew 1\output\README.md:
# Output Directory

This directory contains files generated by the Team Agents system:

- Generated code and content from agents
- Artifacts produced during task execution
- Temporary files in the `temp/` subdirectory

Content in this directory is generated during runtime.
--------------------------------------------------------------------------------
        __init__.py

Content of C:/AI PROJECT/My Langchain Crew 1\output\__init__.py:
"""
Output package.
"""
--------------------------------------------------------------------------------
        temp/
    tools/
        code_generation_tool.py

Content of C:/AI PROJECT/My Langchain Crew 1\tools\code_generation_tool.py:
"""
Code Generation Tool Module

This module provides tools for generating code based on specifications or requirements.
It leverages language models to create code in various programming languages and
can handle different types of code generation tasks.
"""

import logging
import os
import json
from typing import Dict, Any, List, Optional, Union
from pathlib import Path

from langchain_openai import ChatOpenAI

logger = logging.getLogger(__name__)

class CodeGenerationTool:
    """
    Tool for generating code based on specifications or requirements.
    
    This tool leverages language models to generate code in various programming
    languages and can handle different types of code generation tasks including
    functions, classes, scripts, or complete applications.
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        Initialize the code generation tool.
        
        Args:
            config: Configuration dictionary with code generation settings
        """
        self.config = config
        self.model_name = config.get("model", "gpt-4o")
        self.temperature = config.get("temperature", 0.1)
        self.output_dir = config.get("output_dir", "output")
        self.language_support = config.get("language_support", [
            "python", "javascript", "java", "csharp", "apex"
        ])
        
        # Initialize language model
        self.llm = ChatOpenAI(
            model=self.model_name,
            temperature=self.temperature
        )
        
        # Create output directory if it doesn't exist
        os.makedirs(self.output_dir, exist_ok=True)
        
        logger.debug(f"Initialized CodeGenerationTool with model: {self.model_name}")
    
    def generate_code(
        self, 
        specification: str, 
        language: str, 
        code_type: str = "function",
        save_to_file: bool = True,
        filename: Optional[str] = None,
        additional_context: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Generate code based on a specification.
        
        Args:
            specification: Description of what the code should do
            language: Programming language to use
            code_type: Type of code to generate (function, class, script, app)
            save_to_file: Whether to save the generated code to a file
            filename: Optional filename to save the code to
            additional_context: Additional context or requirements
            
        Returns:
            Dictionary containing the generated code and metadata
        """
        # Check if the language is supported
        if language.lower() not in [lang.lower() for lang in self.language_support]:
            logger.warning(f"Language {language} not in explicitly supported languages: {self.language_support}")
        
        # Create the prompt for code generation
        prompt = self._create_code_generation_prompt(
            specification, language, code_type, additional_context
        )
        
        # Generate the code
        try:
            logger.debug(f"Generating {code_type} in {language}")
            response = self.llm.invoke(prompt)
            
            # Extract code from the response
            generated_code, code_explanation = self._extract_code_from_response(response.content, language)
            
            # Determine filename if not provided
            file_path = None
            if save_to_file:
                file_path = self._save_code_to_file(generated_code, language, filename)
            
            return {
                "code": generated_code,
                "language": language,
                "explanation": code_explanation,
                "file_path": file_path,
                "success": True
            }
            
        except Exception as e:
            logger.error(f"Error generating code: {str(e)}")
            return {
                "code": f"# Error generating code: {str(e)}",
                "language": language,
                "explanation": f"An error occurred during code generation: {str(e)}",
                "file_path": None,
                "success": False
            }
    
    def _create_code_generation_prompt(
        self,
        specification: str,
        language: str,
        code_type: str,
        additional_context: Optional[str] = None
    ) -> str:
        """
        Create a prompt for code generation.
        
        Args:
            specification: Description of what the code should do
            language: Programming language to use
            code_type: Type of code to generate
            additional_context: Additional context or requirements
            
        Returns:
            Formatted prompt string
        """
        # Base prompt template
        prompt = f"""
        Generate {language} code for the following specification:
        
        SPECIFICATION:
        {specification}
        """
        
        # Add code type specific instructions
        if code_type.lower() == "function":
            prompt += "\nCreate a well-structured function that accomplishes this task."
        elif code_type.lower() == "class":
            prompt += "\nCreate a well-structured class with appropriate methods."
        elif code_type.lower() == "script":
            prompt += "\nCreate a complete script that can be executed."
        elif code_type.lower() == "app":
            prompt += "\nCreate a basic application structure for this requirement."
        
        # Add language-specific best practices
        prompt += f"\n\nFollow these {language} best practices:"
        
        if language.lower() == "python":
            prompt += """
            - Follow PEP 8 style guidelines
            - Include docstrings for functions and classes
            - Use type hints where appropriate
            - Handle errors with try/except blocks
            - Use meaningful variable and function names
            """
        elif language.lower() == "javascript":
            prompt += """
            - Use modern ES6+ syntax
            - Add JSDoc comments for functions
            - Handle errors appropriately
            - Use const and let instead of var
            - Follow standard JavaScript conventions
            """
        elif language.lower() == "java":
            prompt += """
            - Follow Java naming conventions
            - Include JavaDoc comments
            - Handle exceptions appropriately
            - Use proper access modifiers
            - Follow object-oriented principles
            """
        elif language.lower() == "csharp":
            prompt += """
            - Follow C# naming conventions
            - Include XML documentation comments
            - Use proper exception handling
            - Follow C# coding standards
            - Consider SOLID principles
            """
        elif language.lower() == "apex":
            prompt += """
            - Consider Salesforce governor limits
            - Include proper error handling
            - Follow Salesforce security best practices
            - Include test methods
            - Use bulkified patterns
            """
        
        # Add additional context if provided
        if additional_context:
            prompt += f"\n\nADDITIONAL CONTEXT:\n{additional_context}"
        
        # Add formatting instructions
        prompt += """
        
        FORMAT YOUR RESPONSE AS FOLLOWS:
        1. First provide the complete code solution, formatted with proper syntax highlighting
        2. After the code, provide a brief explanation of how it works
        3. Mention any assumptions made
        4. Suggest potential improvements or alternatives
        
        THE CODE MUST BE ENCLOSED IN A CODE BLOCK WITH THE APPROPRIATE LANGUAGE TAG.
        """
        
        return prompt
    
    def _extract_code_from_response(self, response: str, language: str) -> tuple:
        """
        Extract code and explanation from the response.
        
        Args:
            response: The response from the language model
            language: The programming language
            
        Returns:
            Tuple of (code, explanation)
        """
        code = ""
        explanation = ""
        
        # Try to extract code blocks with markdown formatting
        import re
        code_block_pattern = rf"```(?:{language})?\s*(.*?)\s*```"
        code_blocks = re.findall(code_block_pattern, response, re.DOTALL)
        
        if code_blocks:
            # Get the first code block
            code = code_blocks[0].strip()
            
            # Get explanation after the last code block
            last_code_end = response.rfind("```")
            if last_code_end != -1 and last_code_end + 3 < len(response):
                explanation = response[last_code_end + 3:].strip()
        else:
            # If no code blocks found, try to extract based on context
            lines = response.split("\n")
            code_section = False
            code_lines = []
            explanation_lines = []
            
            for line in lines:
                if not code_section and any(indicator in line.lower() for indicator in ["here's the code", "code:", "solution:"]):
                    code_section = True
                    continue
                elif code_section and any(indicator in line.lower() for indicator in ["explanation:", "how it works:", "here's how"]):
                    code_section = False
                    explanation_lines.append(line)
                    continue
                
                if code_section:
                    code_lines.append(line)
                elif not code_section and line.strip():
                    explanation_lines.append(line)
            
            if code_lines:
                code = "\n".join(code_lines).strip()
            if explanation_lines:
                explanation = "\n".join(explanation_lines).strip()
            
            # If still no code found, assume the whole response is code
            if not code:
                code = response.strip()
        
        return code, explanation
    
    def _save_code_to_file(
        self,
        code: str,
        language: str,
        filename: Optional[str] = None
    ) -> str:
        """
        Save generated code to a file.
        
        Args:
            code: The generated code
            language: The programming language
            filename: Optional filename to use
            
        Returns:
            Path to the saved file
        """
        # Map languages to file extensions
        extensions = {
            "python": "py",
            "javascript": "js",
            "java": "java",
            "csharp": "cs",
            "apex": "cls",
            "html": "html",
            "css": "css",
            "sql": "sql"
        }
        
        # Get the file extension for the language
        extension = extensions.get(language.lower(), "txt")
        
        # Generate a filename if not provided
        if not filename:
            # Try to determine a reasonable filename from the code
            if language.lower() == "python":
                # Look for class or function definitions
                import re
                class_match = re.search(r"class\s+([A-Za-z0-9_]+)", code)
                if class_match:
                    filename = f"{class_match.group(1).lower()}.{extension}"
                else:
                    func_match = re.search(r"def\s+([A-Za-z0-9_]+)", code)
                    if func_match:
                        filename = f"{func_match.group(1).lower()}.{extension}"
            elif language.lower() in ["java", "apex", "csharp"]:
                # Look for class definitions
                import re
                class_match = re.search(r"class\s+([A-Za-z0-9_]+)", code)
                if class_match:
                    filename = f"{class_match.group(1)}.{extension}"
            
            # Default filename if we couldn't determine one
            if not filename:
                timestamp = int(os.path.getmtime(os.path.abspath(__file__)))
                filename = f"generated_code_{timestamp}.{extension}"
        
        # Ensure filename has the correct extension
        if not filename.endswith(f".{extension}"):
            filename = f"{filename}.{extension}"
        
        # Create the full file path
        file_path = os.path.join(self.output_dir, filename)
        
        # Make sure the directory exists
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        
        # Save the code to the file
        try:
            with open(file_path, "w", encoding="utf-8") as f:
                f.write(code)
            logger.info(f"Saved generated code to {file_path}")
            return file_path
        except Exception as e:
            logger.error(f"Error saving code to file: {str(e)}")
            return ""
    
    def implement_function(
        self, 
        function_name: str, 
        description: str, 
        language: str, 
        parameters: Optional[List[Dict[str, str]]] = None,
        return_type: Optional[str] = None,
        save_to_file: bool = True
    ) -> Dict[str, Any]:
        """
        Generate a function based on a description.
        
        Args:
            function_name: Name of the function
            description: Description of what the function should do
            language: Programming language to use
            parameters: List of parameter dictionaries with name and type
            return_type: Return type of the function
            save_to_file: Whether to save the generated function to a file
            
        Returns:
            Dictionary containing the generated function and metadata
        """
        # Create parameter string
        params_str = ""
        if parameters:
            params = []
            for param in parameters:
                param_name = param.get("name", "")
                param_type = param.get("type", "")
                
                if language.lower() == "python":
                    if param_type:
                        params.append(f"{param_name}: {param_type}")
                    else:
                        params.append(param_name)
                elif language.lower() in ["java", "csharp", "apex"]:
                    if param_type:
                        params.append(f"{param_type} {param_name}")
                    else:
                        params.append(f"Object {param_name}")
                elif language.lower() == "javascript":
                    params.append(param_name)
                
            params_str = ", ".join(params)
        
        # Create return type string
        return_str = ""
        if return_type:
            if language.lower() == "python":
                return_str = f" -> {return_type}"
            elif language.lower() in ["java", "csharp", "apex"]:
                return_str = f" Returns: {return_type}"
            elif language.lower() == "javascript":
                return_str = f" @returns {{{return_type}}}"
        
        # Create function specification
        specification = f"""
        Function Name: {function_name}
        Description: {description}
        Parameters: {params_str}
        {return_str}
        """
        
        # Generate the function code
        return self.generate_code(
            specification=specification,
            language=language,
            code_type="function",
            save_to_file=save_to_file,
            filename=f"{function_name}.{self._get_extension(language)}"
        )
    
    def implement_class(
        self, 
        class_name: str, 
        description: str, 
        language: str, 
        methods: Optional[List[Dict[str, Any]]] = None,
        properties: Optional[List[Dict[str, Any]]] = None,
        save_to_file: bool = True
    ) -> Dict[str, Any]:
        """
        Generate a class based on a description.
        
        Args:
            class_name: Name of the class
            description: Description of what the class should do
            language: Programming language to use
            methods: List of method specifications
            properties: List of property specifications
            save_to_file: Whether to save the generated class to a file
            
        Returns:
            Dictionary containing the generated class and metadata
        """
        # Create methods string
        methods_str = ""
        if methods:
            methods_str = "Methods:\n"
            for method in methods:
                method_name = method.get("name", "")
                method_desc = method.get("description", "")
                method_params = method.get("parameters", [])
                method_return = method.get("return_type", "")
                
                # Format parameters
                params_list = []
                for param in method_params:
                    param_name = param.get("name", "")
                    param_type = param.get("type", "")
                    if param_type:
                        params_list.append(f"{param_name}: {param_type}")
                    else:
                        params_list.append(param_name)
                
                params_str = ", ".join(params_list)
                
                # Add method to string
                methods_str += f"  - {method_name}({params_str})"
                if method_return:
                    methods_str += f" -> {method_return}"
                methods_str += f": {method_desc}\n"
        
        # Create properties string
        props_str = ""
        if properties:
            props_str = "Properties:\n"
            for prop in properties:
                prop_name = prop.get("name", "")
                prop_type = prop.get("type", "")
                prop_desc = prop.get("description", "")
                
                props_str += f"  - {prop_name}: {prop_type} - {prop_desc}\n"
        
        # Create class specification
        specification = f"""
        Class Name: {class_name}
        Description: {description}
        {props_str}
        {methods_str}
        """
        
        # Generate the class code
        return self.generate_code(
            specification=specification,
            language=language,
            code_type="class",
            save_to_file=save_to_file,
            filename=f"{class_name}.{self._get_extension(language)}"
        )
    
    def _get_extension(self, language: str) -> str:
        """
        Get the file extension for a language.
        
        Args:
            language: The programming language
            
        Returns:
            File extension for the language
        """
        extensions = {
            "python": "py",
            "javascript": "js",
            "java": "java",
            "csharp": "cs",
            "apex": "cls",
            "html": "html",
            "css": "css",
            "sql": "sql"
        }
        
        return extensions.get(language.lower(), "txt")
--------------------------------------------------------------------------------
        communication_tool.py

Content of C:/AI PROJECT/My Langchain Crew 1\tools\communication_tool.py:
"""
Communication Tool Module

This module provides tools for communication between agents, enabling
information sharing, message passing, and collaborative workflows.
It supports structured communication patterns and maintains conversation history.
"""

import logging
import time
import json
from typing import Dict, Any, List, Optional, Union
from datetime import datetime

logger = logging.getLogger(__name__)

class CommunicationTool:
    """
    Tool for facilitating communication between agents.
    
    This tool provides methods for structured communication between agents,
    enabling information sharing, message passing, and collaborative discussions.
    It maintains conversation history and provides mechanisms for context sharing.
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        Initialize the communication tool.
        
        Args:
            config: Configuration dictionary with communication settings
        """
        self.config = config
        self.max_message_history = config.get("max_message_history", 100)
        self.enable_agent_tagging = config.get("enable_agent_tagging", True)
        self.enable_timestamps = config.get("enable_timestamps", True)
        self.structured_messages = config.get("structured_messages", True)
        
        # Initialize conversation history
        self.conversation_history = []
        self.agent_states = {}
        self.shared_context = {}
        
        logger.debug("Initialized CommunicationTool")
    
    def send_message(
        self, 
        sender_id: str, 
        receiver_id: Optional[str], 
        message_content: Union[str, Dict[str, Any]],
        message_type: str = "text"
    ) -> Dict[str, Any]:
        """
        Send a message from one agent to another, or broadcast to all agents.
        
        Args:
            sender_id: ID of the sending agent
            receiver_id: ID of the receiving agent, or None for broadcast
            message_content: The content of the message
            message_type: Type of message (text, data, request, response)
            
        Returns:
            Dictionary with message details and status
        """
        # Create the message structure
        message = {
            "message_id": f"msg_{int(time.time())}_{hash(str(message_content)) % 10000}",
            "sender_id": sender_id,
            "receiver_id": receiver_id if receiver_id else "broadcast",
            "content": message_content,
            "type": message_type,
            "status": "sent"
        }
        
        # Add timestamp if enabled
        if self.enable_timestamps:
            message["timestamp"] = datetime.now().isoformat()
        
        # Add to conversation history
        self.conversation_history.append(message)
        
        # Trim conversation history if it exceeds the maximum
        if len(self.conversation_history) > self.max_message_history:
            self.conversation_history = self.conversation_history[-self.max_message_history:]
        
        logger.debug(f"Message sent from {sender_id} to {receiver_id if receiver_id else 'broadcast'}")
        
        return {
            "message": message,
            "success": True
        }
    
    def receive_messages(
        self, 
        receiver_id: str, 
        sender_id: Optional[str] = None,
        message_type: Optional[str] = None,
        unread_only: bool = False
    ) -> List[Dict[str, Any]]:
        """
        Retrieve messages intended for a specific agent.
        
        Args:
            receiver_id: ID of the receiving agent
            sender_id: Optional filter for messages from a specific sender
            message_type: Optional filter for message type
            unread_only: Whether to return only unread messages
            
        Returns:
            List of messages for the receiving agent
        """
        messages = []
        
        for message in self.conversation_history:
            # Check if the message is intended for this receiver
            is_recipient = (
                message["receiver_id"] == receiver_id or 
                message["receiver_id"] == "broadcast"
            )
            
            # Apply filters
            sender_match = not sender_id or message["sender_id"] == sender_id
            type_match = not message_type or message["type"] == message_type
            status_match = not unread_only or message.get("status") != "read"
            
            if is_recipient and sender_match and type_match and status_match:
                # Create a copy of the message
                msg_copy = message.copy()
                
                # Mark as read if it wasn't before
                if msg_copy.get("status") != "read":
                    # Update the original message status
                    message["status"] = "read"
                    # Update the copy as well
                    msg_copy["status"] = "read"
                
                messages.append(msg_copy)
        
        logger.debug(f"Retrieved {len(messages)} messages for {receiver_id}")
        return messages
    
    def update_agent_state(self, agent_id: str, state_update: Dict[str, Any]) -> Dict[str, Any]:
        """
        Update the shared state of an agent.
        
        Args:
            agent_id: ID of the agent
            state_update: Dictionary with state updates
            
        Returns:
            Dictionary with updated state
        """
        # Initialize agent state if it doesn't exist
        if agent_id not in self.agent_states:
            self.agent_states[agent_id] = {}
        
        # Update the agent state
        self.agent_states[agent_id].update(state_update)
        
        # Add timestamp of last update
        self.agent_states[agent_id]["last_updated"] = datetime.now().isoformat()
        
        logger.debug(f"Updated state for agent {agent_id}")
        
        return {
            "agent_id": agent_id,
            "state": self.agent_states[agent_id],
            "success": True
        }
    
    def get_agent_state(self, agent_id: str) -> Dict[str, Any]:
        """
        Get the current state of an agent.
        
        Args:
            agent_id: ID of the agent
            
        Returns:
            Dictionary with agent state
        """
        # Return empty state if agent doesn't exist
        if agent_id not in self.agent_states:
            return {
                "agent_id": agent_id,
                "state": {},
                "success": False,
                "error": "Agent state not found"
            }
        
        return {
            "agent_id": agent_id,
            "state": self.agent_states[agent_id],
            "success": True
        }
    
    def share_context(
        self, 
        context_id: str, 
        content: Any, 
        access_scope: Union[str, List[str]] = "all"
    ) -> Dict[str, Any]:
        """
        Share context information with other agents.
        
        Args:
            context_id: Identifier for this context
            content: The context content to share
            access_scope: "all" for all agents, or list of specific agent IDs
            
        Returns:
            Dictionary with context details
        """
        # Create the context structure
        context = {
            "context_id": context_id,
            "content": content,
            "access_scope": access_scope,
            "timestamp": datetime.now().isoformat()
        }
        
        # Add to shared context
        self.shared_context[context_id] = context
        
        logger.debug(f"Shared context '{context_id}' with scope {access_scope}")
        
        return {
            "context": context,
            "success": True
        }
    
    def get_context(self, context_id: str, agent_id: str) -> Dict[str, Any]:
        """
        Retrieve shared context by ID if the agent has access.
        
        Args:
            context_id: ID of the context to retrieve
            agent_id: ID of the agent requesting context
            
        Returns:
            Dictionary with context content if available
        """
        # Check if context exists
        if context_id not in self.shared_context:
            return {
                "context_id": context_id,
                "content": None,
                "success": False,
                "error": "Context not found"
            }
        
        context = self.shared_context[context_id]
        access_scope = context["access_scope"]
        
        # Check if agent has access
        has_access = (
            access_scope == "all" or 
            (isinstance(access_scope, list) and agent_id in access_scope)
        )
        
        if not has_access:
            return {
                "context_id": context_id,
                "content": None,
                "success": False,
                "error": "Access denied"
            }
        
        return {
            "context_id": context_id,
            "content": context["content"],
            "timestamp": context["timestamp"],
            "success": True
        }
    
    def get_all_accessible_contexts(self, agent_id: str) -> List[Dict[str, Any]]:
        """
        Get all contexts accessible to a specific agent.
        
        Args:
            agent_id: ID of the agent
            
        Returns:
            List of accessible contexts
        """
        accessible_contexts = []
        
        for context_id, context in self.shared_context.items():
            access_scope = context["access_scope"]
            
            # Check if agent has access
            has_access = (
                access_scope == "all" or 
                (isinstance(access_scope, list) and agent_id in access_scope)
            )
            
            if has_access:
                accessible_contexts.append({
                    "context_id": context_id,
                    "content": context["content"],
                    "timestamp": context["timestamp"],
                    "success": True
                })
        
        return accessible_contexts
    
    def create_structured_message(
        self, 
        sender_id: str, 
        action: str, 
        data: Dict[str, Any],
        metadata: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Create a structured message for standardized agent communication.
        
        Args:
            sender_id: ID of the sending agent
            action: The action or intent of the message
            data: The main payload of the message
            metadata: Optional additional metadata
            
        Returns:
            Structured message dictionary
        """
        if not self.structured_messages:
            logger.warning("Structured messages are disabled in configuration")
        
        # Create structured message
        message = {
            "action": action,
            "data": data,
            "metadata": metadata or {}
        }
        
        # Add sender ID
        if self.enable_agent_tagging:
            message["sender_id"] = sender_id
        
        # Add timestamp
        if self.enable_timestamps:
            message["timestamp"] = datetime.now().isoformat()
        
        return message
    
    def get_conversation_summary(
        self, 
        max_messages: int = 10, 
        participants: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """
        Get a summary of recent conversation history.
        
        Args:
            max_messages: Maximum number of messages to include
            participants: Optional filter for specific participants
            
        Returns:
            Dictionary with conversation summary
        """
        # Filter messages by participants if specified
        filtered_history = self.conversation_history
        if participants:
            filtered_history = [
                msg for msg in self.conversation_history
                if msg["sender_id"] in participants or msg["receiver_id"] in participants
            ]
        
        # Get the most recent messages
        recent_messages = filtered_history[-max_messages:] if filtered_history else []
        
        # Create summary statistics
        message_count = len(self.conversation_history)
        agent_participation = {}
        
        for message in self.conversation_history:
            sender = message["sender_id"]
            if sender not in agent_participation:
                agent_participation[sender] = 0
            agent_participation[sender] += 1
        
        # Sort agents by participation
        sorted_participation = sorted(
            agent_participation.items(),
            key=lambda x: x[1],
            reverse=True
        )
        
        # Format the summary
        summary = {
            "total_messages": message_count,
            "agent_participation": dict(sorted_participation),
            "recent_messages": recent_messages
        }
        
        return summary
    
    def clear_conversation_history(self) -> Dict[str, Any]:
        """
        Clear the conversation history.
        
        Returns:
            Status dictionary
        """
        old_count = len(self.conversation_history)
        self.conversation_history = []
        
        logger.info(f"Cleared conversation history ({old_count} messages)")
        
        return {
            "success": True,
            "cleared_messages": old_count
        }
    
    def export_conversation_history(self, format: str = "json") -> Dict[str, Any]:
        """
        Export the conversation history in various formats.
        
        Args:
            format: Export format (json, text, html)
            
        Returns:
            Dictionary with exported content
        """
        if format.lower() == "json":
            # Export as JSON
            export_data = json.dumps(self.conversation_history, indent=2)
            
        elif format.lower() == "text":
            # Export as plain text
            lines = []
            for msg in self.conversation_history:
                sender = msg["sender_id"]
                receiver = msg["receiver_id"]
                timestamp = msg.get("timestamp", "")
                content = msg["content"]
                
                if isinstance(content, dict):
                    # Format dictionary content
                    content_str = json.dumps(content)
                else:
                    content_str = str(content)
                
                line = f"[{timestamp}] {sender} -> {receiver}: {content_str}"
                lines.append(line)
            
            export_data = "\n".join(lines)
            
        elif format.lower() == "html":
            # Export as HTML
            html_lines = [
                "<!DOCTYPE html>",
                "<html>",
                "<head>",
                "  <title>Conversation History</title>",
                "  <style>",
                "    body { font-family: Arial, sans-serif; margin: 20px; }",
                "    .message { margin-bottom: 10px; padding: 10px; border: 1px solid #ddd; }",
                "    .sender { font-weight: bold; }",
                "    .timestamp { color: #888; font-size: 0.8em; }",
                "    .content { margin-top: 5px; white-space: pre-wrap; }",
                "  </style>",
                "</head>",
                "<body>",
                "  <h1>Conversation History</h1>"
            ]
            
            for msg in self.conversation_history:
                sender = msg["sender_id"]
                receiver = msg["receiver_id"]
                timestamp = msg.get("timestamp", "")
                content = msg["content"]
                
                if isinstance(content, dict):
                    # Format dictionary content
                    content_str = json.dumps(content, indent=2)
                else:
                    content_str = str(content)
                
                html_lines.append("  <div class='message'>")
                html_lines.append(f"    <div class='sender'>{sender} -> {receiver}</div>")
                html_lines.append(f"    <div class='timestamp'>{timestamp}</div>")
                html_lines.append(f"    <div class='content'>{content_str}</div>")
                html_lines.append("  </div>")
            
            html_lines.append("</body>")
            html_lines.append("</html>")
            
            export_data = "\n".join(html_lines)
            
        else:
            return {
                "success": False,
                "error": f"Unsupported format: {format}",
                "supported_formats": ["json", "text", "html"]
            }
        
        return {
            "success": True,
            "format": format,
            "data": export_data,
            "message_count": len(self.conversation_history)
        }
--------------------------------------------------------------------------------
        file_manager_tool.py

Content of C:/AI PROJECT/My Langchain Crew 1\tools\file_manager_tool.py:
"""
File Manager Tool Module

This module provides tools for managing files, including reading, writing, creating,
and organizing files and directories to support the agents' operations.
"""

import os
import logging
import json
import yaml
import csv
import shutil
from typing import Dict, Any, List, Optional, Union, BinaryIO
from pathlib import Path
import datetime

logger = logging.getLogger(__name__)

class FileManagerTool:
    """
    Tool for managing files and directories.
    
    This tool provides methods for reading, writing, creating, and organizing files
    and directories to support the agents' operations and store their outputs.
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        Initialize the file manager tool.
        
        Args:
            config: Configuration dictionary with file manager settings
        """
        self.config = config
        self.base_dir = config.get("base_dir", ".")
        self.output_dir = config.get("output_dir", "output")
        self.allowed_extensions = config.get("allowed_extensions", [
            "txt", "json", "yaml", "yml", "csv", "md", "py", "js", "html", "css", 
            "java", "cs", "cls", "xml", "log", "ini", "conf"
        ])
        self.max_file_size = config.get("max_file_size", 10 * 1024 * 1024)  # 10 MB default
        
        # Create output directory if it doesn't exist
        output_path = Path(self.base_dir) / self.output_dir
        output_path.mkdir(parents=True, exist_ok=True)
        
        logger.debug(f"Initialized FileManagerTool with base_dir: {self.base_dir}, output_dir: {self.output_dir}")
    
    def read_file(self, file_path: str, encoding: str = "utf-8") -> Dict[str, Any]:
        """
        Read a file and return its contents.
        
        Args:
            file_path: Path to the file to read
            encoding: Encoding to use when reading the file
            
        Returns:
            Dictionary with file contents and metadata
        """
        # Normalize path and check if it exists
        full_path = self._get_full_path(file_path)
        
        try:
            # Check if file exists
            if not os.path.exists(full_path):
                return {
                    "success": False,
                    "content": "",
                    "error": f"File not found: {file_path}",
                    "metadata": {}
                }
            
            # Check if path is a directory
            if os.path.isdir(full_path):
                return {
                    "success": False,
                    "content": "",
                    "error": f"Path is a directory, not a file: {file_path}",
                    "metadata": {}
                }
            
            # Check file size
            file_size = os.path.getsize(full_path)
            if file_size > self.max_file_size:
                return {
                    "success": False,
                    "content": "",
                    "error": f"File size ({file_size} bytes) exceeds maximum allowed size ({self.max_file_size} bytes)",
                    "metadata": {"size": file_size}
                }
            
            # Determine file type based on extension
            file_extension = self._get_file_extension(full_path)
            
            # Read file based on its type
            content = ""
            metadata = {
                "path": file_path,
                "size": file_size,
                "extension": file_extension,
                "last_modified": datetime.datetime.fromtimestamp(os.path.getmtime(full_path)).isoformat()
            }
            
            if file_extension == "json":
                with open(full_path, "r", encoding=encoding) as f:
                    content = json.load(f)
                    metadata["content_type"] = "json"
            elif file_extension in ["yaml", "yml"]:
                with open(full_path, "r", encoding=encoding) as f:
                    content = yaml.safe_load(f)
                    metadata["content_type"] = "yaml"
            elif file_extension == "csv":
                with open(full_path, "r", encoding=encoding, newline="") as f:
                    reader = csv.reader(f)
                    content = list(reader)
                    metadata["content_type"] = "csv"
                    metadata["rows"] = len(content)
                    metadata["columns"] = len(content[0]) if content else 0
            else:
                # Default to text
                with open(full_path, "r", encoding=encoding) as f:
                    content = f.read()
                    metadata["content_type"] = "text"
            
            return {
                "success": True,
                "content": content,
                "metadata": metadata
            }
            
        except Exception as e:
            logger.error(f"Error reading file {file_path}: {str(e)}")
            return {
                "success": False,
                "content": "",
                "error": f"Error reading file: {str(e)}",
                "metadata": {}
            }
    
    def write_file(
        self, 
        file_path: str, 
        content: Union[str, Dict, List], 
        mode: str = "w", 
        encoding: str = "utf-8",
        create_dirs: bool = True
    ) -> Dict[str, Any]:
        """
        Write content to a file.
        
        Args:
            file_path: Path to write the file to
            content: Content to write to the file
            mode: File mode ('w' for write, 'a' for append)
            encoding: Encoding to use when writing the file
            create_dirs: Whether to create parent directories if they don't exist
            
        Returns:
            Dictionary with status and metadata
        """
        # Normalize path
        full_path = self._get_full_path(file_path)
        
        try:
            # Ensure the file extension is allowed
            file_extension = self._get_file_extension(full_path)
            if file_extension not in self.allowed_extensions:
                return {
                    "success": False,
                    "error": f"File extension '{file_extension}' not allowed",
                    "metadata": {}
                }
            
            # Create parent directories if needed
            if create_dirs:
                os.makedirs(os.path.dirname(full_path), exist_ok=True)
            
            # Write content based on its type and file extension
            if isinstance(content, (dict, list)) and file_extension == "json":
                with open(full_path, mode, encoding=encoding) as f:
                    json.dump(content, f, indent=2)
            elif isinstance(content, (dict, list)) and file_extension in ["yaml", "yml"]:
                with open(full_path, mode, encoding=encoding) as f:
                    yaml.dump(content, f)
            elif isinstance(content, list) and file_extension == "csv":
                with open(full_path, mode, encoding=encoding, newline="") as f:
                    writer = csv.writer(f)
                    writer.writerows(content)
            else:
                # Default to text
                with open(full_path, mode, encoding=encoding) as f:
                    f.write(str(content))
            
            # Get file metadata
            file_size = os.path.getsize(full_path)
            metadata = {
                "path": file_path,
                "size": file_size,
                "extension": file_extension,
                "last_modified": datetime.datetime.fromtimestamp(os.path.getmtime(full_path)).isoformat()
            }
            
            logger.debug(f"Successfully wrote to file: {file_path}")
            return {
                "success": True,
                "metadata": metadata
            }
            
        except Exception as e:
            logger.error(f"Error writing to file {file_path}: {str(e)}")
            return {
                "success": False,
                "error": f"Error writing to file: {str(e)}",
                "metadata": {}
            }
    
    def create_directory(self, dir_path: str) -> Dict[str, Any]:
        """
        Create a directory.
        
        Args:
            dir_path: Path to the directory to create
            
        Returns:
            Dictionary with status and metadata
        """
        # Normalize path
        full_path = self._get_full_path(dir_path)
        
        try:
            # Create directory and parent directories
            os.makedirs(full_path, exist_ok=True)
            
            metadata = {
                "path": dir_path,
                "created": datetime.datetime.now().isoformat()
            }
            
            logger.debug(f"Successfully created directory: {dir_path}")
            return {
                "success": True,
                "metadata": metadata
            }
            
        except Exception as e:
            logger.error(f"Error creating directory {dir_path}: {str(e)}")
            return {
                "success": False,
                "error": f"Error creating directory: {str(e)}",
                "metadata": {}
            }
    
    def list_directory(
        self, 
        dir_path: str, 
        include_metadata: bool = False,
        recursive: bool = False
    ) -> Dict[str, Any]:
        """
        List contents of a directory.
        
        Args:
            dir_path: Path to the directory to list
            include_metadata: Whether to include metadata for each file
            recursive: Whether to list subdirectories recursively
            
        Returns:
            Dictionary with directory contents and metadata
        """
        # Normalize path
        full_path = self._get_full_path(dir_path)
        
        try:
            # Check if directory exists
            if not os.path.exists(full_path):
                return {
                    "success": False,
                    "contents": [],
                    "error": f"Directory not found: {dir_path}",
                    "metadata": {}
                }
            
            # Check if path is a directory
            if not os.path.isdir(full_path):
                return {
                    "success": False,
                    "contents": [],
                    "error": f"Path is a file, not a directory: {dir_path}",
                    "metadata": {}
                }
            
            # List contents
            contents = []
            
            if recursive:
                # Recursive listing
                for root, dirs, files in os.walk(full_path):
                    rel_path = os.path.relpath(root, full_path)
                    if rel_path == ".":
                        rel_path = ""
                    
                    # Add directories
                    for dir_name in dirs:
                        dir_item = {
                            "name": dir_name,
                            "path": os.path.join(rel_path, dir_name) if rel_path else dir_name,
                            "type": "directory"
                        }
                        
                        if include_metadata:
                            dir_full_path = os.path.join(root, dir_name)
                            dir_item["metadata"] = {
                                "last_modified": datetime.datetime.fromtimestamp(os.path.getmtime(dir_full_path)).isoformat()
                            }
                        
                        contents.append(dir_item)
                    
                    # Add files
                    for file_name in files:
                        file_item = {
                            "name": file_name,
                            "path": os.path.join(rel_path, file_name) if rel_path else file_name,
                            "type": "file",
                            "extension": self._get_file_extension(file_name)
                        }
                        
                        if include_metadata:
                            file_full_path = os.path.join(root, file_name)
                            file_item["metadata"] = {
                                "size": os.path.getsize(file_full_path),
                                "last_modified": datetime.datetime.fromtimestamp(os.path.getmtime(file_full_path)).isoformat()
                            }
                        
                        contents.append(file_item)
            else:
                # Non-recursive listing
                for item_name in os.listdir(full_path):
                    item_path = os.path.join(full_path, item_name)
                    is_dir = os.path.isdir(item_path)
                    
                    item = {
                        "name": item_name,
                        "type": "directory" if is_dir else "file"
                    }
                    
                    if not is_dir:
                        item["extension"] = self._get_file_extension(item_name)
                    
                    if include_metadata:
                        item["metadata"] = {
                            "last_modified": datetime.datetime.fromtimestamp(os.path.getmtime(item_path)).isoformat()
                        }
                        
                        if not is_dir:
                            item["metadata"]["size"] = os.path.getsize(item_path)
                    
                    contents.append(item)
            
            # Sort contents: directories first, then files
            contents.sort(key=lambda x: (0 if x["type"] == "directory" else 1, x["name"]))
            
            dir_metadata = {
                "path": dir_path,
                "item_count": len(contents),
                "directories": sum(1 for item in contents if item["type"] == "directory"),
                "files": sum(1 for item in contents if item["type"] == "file")
            }
            
            return {
                "success": True,
                "contents": contents,
                "metadata": dir_metadata
            }
            
        except Exception as e:
            logger.error(f"Error listing directory {dir_path}: {str(e)}")
            return {
                "success": False,
                "contents": [],
                "error": f"Error listing directory: {str(e)}",
                "metadata": {}
            }
    
    def delete_file(self, file_path: str) -> Dict[str, Any]:
        """
        Delete a file.
        
        Args:
            file_path: Path to the file to delete
            
        Returns:
            Dictionary with status and metadata
        """
        # Normalize path
        full_path = self._get_full_path(file_path)
        
        try:
            # Check if file exists
            if not os.path.exists(full_path):
                return {
                    "success": False,
                    "error": f"File not found: {file_path}",
                    "metadata": {}
                }
            
            # Check if path is a directory
            if os.path.isdir(full_path):
                return {
                    "success": False,
                    "error": f"Path is a directory, not a file: {file_path}",
                    "metadata": {}
                }
            
            # Get file metadata before deletion
            metadata = {
                "path": file_path,
                "size": os.path.getsize(full_path),
                "last_modified": datetime.datetime.fromtimestamp(os.path.getmtime(full_path)).isoformat(),
                "deleted_at": datetime.datetime.now().isoformat()
            }
            
            # Delete the file
            os.remove(full_path)
            
            logger.debug(f"Successfully deleted file: {file_path}")
            return {
                "success": True,
                "metadata": metadata
            }
            
        except Exception as e:
            logger.error(f"Error deleting file {file_path}: {str(e)}")
            return {
                "success": False,
                "error": f"Error deleting file: {str(e)}",
                "metadata": {}
            }
    
    def delete_directory(self, dir_path: str, recursive: bool = False) -> Dict[str, Any]:
        """
        Delete a directory.
        
        Args:
            dir_path: Path to the directory to delete
            recursive: Whether to delete subdirectories and files
            
        Returns:
            Dictionary with status and metadata
        """
        # Normalize path
        full_path = self._get_full_path(dir_path)
        
        try:
            # Check if directory exists
            if not os.path.exists(full_path):
                return {
                    "success": False,
                    "error": f"Directory not found: {dir_path}",
                    "metadata": {}
                }
            
            # Check if path is a directory
            if not os.path.isdir(full_path):
                return {
                    "success": False,
                    "error": f"Path is a file, not a directory: {dir_path}",
                    "metadata": {}
                }
            
            # Get directory metadata before deletion
            metadata = {
                "path": dir_path,
                "deleted_at": datetime.datetime.now().isoformat()
            }
            
            # Delete the directory
            if recursive:
                shutil.rmtree(full_path)
            else:
                os.rmdir(full_path)
            
            logger.debug(f"Successfully deleted directory: {dir_path}")
            return {
                "success": True,
                "metadata": metadata
            }
            
        except Exception as e:
            logger.error(f"Error deleting directory {dir_path}: {str(e)}")
            return {
                "success": False,
                "error": f"Error deleting directory: {str(e)}",
                "metadata": {}
            }
    
    def copy_file(self, source_path: str, dest_path: str, overwrite: bool = False) -> Dict[str, Any]:
        """
        Copy a file from source to destination.
        
        Args:
            source_path: Path to the source file
            dest_path: Path to the destination file
            overwrite: Whether to overwrite the destination if it exists
            
        Returns:
            Dictionary with status and metadata
        """
        # Normalize paths
        full_source_path = self._get_full_path(source_path)
        full_dest_path = self._get_full_path(dest_path)
        
        try:
            # Check if source file exists
            if not os.path.exists(full_source_path):
                return {
                    "success": False,
                    "error": f"Source file not found: {source_path}",
                    "metadata": {}
                }
            
            # Check if source is a directory
            if os.path.isdir(full_source_path):
                return {
                    "success": False,
                    "error": f"Source is a directory, not a file: {source_path}",
                    "metadata": {}
                }
            
            # Check if destination exists and whether to overwrite
            if os.path.exists(full_dest_path) and not overwrite:
                return {
                    "success": False,
                    "error": f"Destination file already exists: {dest_path} (set overwrite=True to overwrite)",
                    "metadata": {}
                }
            
            # Create parent directories if needed
            os.makedirs(os.path.dirname(full_dest_path), exist_ok=True)
            
            # Copy the file
            shutil.copy2(full_source_path, full_dest_path)
            
            metadata = {
                "source_path": source_path,
                "dest_path": dest_path,
                "size": os.path.getsize(full_dest_path),
                "last_modified": datetime.datetime.fromtimestamp(os.path.getmtime(full_dest_path)).isoformat()
            }
            
            logger.debug(f"Successfully copied file from {source_path} to {dest_path}")
            return {
                "success": True,
                "metadata": metadata
            }
            
        except Exception as e:
            logger.error(f"Error copying file from {source_path} to {dest_path}: {str(e)}")
            return {
                "success": False,
                "error": f"Error copying file: {str(e)}",
                "metadata": {}
            }
    
    def move_file(self, source_path: str, dest_path: str, overwrite: bool = False) -> Dict[str, Any]:
        """
        Move a file from source to destination.
        
        Args:
            source_path: Path to the source file
            dest_path: Path to the destination file
            overwrite: Whether to overwrite the destination if it exists
            
        Returns:
            Dictionary with status and metadata
        """
        # Normalize paths
        full_source_path = self._get_full_path(source_path)
        full_dest_path = self._get_full_path(dest_path)
        
        try:
            # Check if source file exists
            if not os.path.exists(full_source_path):
                return {
                    "success": False,
                    "error": f"Source file not found: {source_path}",
                    "metadata": {}
                }
            
            # Check if source is a directory
            if os.path.isdir(full_source_path):
                return {
                    "success": False,
                    "error": f"Source is a directory, not a file: {source_path}",
                    "metadata": {}
                }
            
            # Check if destination exists and whether to overwrite
            if os.path.exists(full_dest_path) and not overwrite:
                return {
                    "success": False,
                    "error": f"Destination file already exists: {dest_path} (set overwrite=True to overwrite)",
                    "metadata": {}
                }
            
            # Create parent directories if needed
            os.makedirs(os.path.dirname(full_dest_path), exist_ok=True)
            
            # Move the file
            shutil.move(full_source_path, full_dest_path)
            
            metadata = {
                "source_path": source_path,
                "dest_path": dest_path,
                "size": os.path.getsize(full_dest_path),
                "last_modified": datetime.datetime.fromtimestamp(os.path.getmtime(full_dest_path)).isoformat()
            }
            
            logger.debug(f"Successfully moved file from {source_path} to {dest_path}")
            return {
                "success": True,
                "metadata": metadata
            }
            
        except Exception as e:
            logger.error(f"Error moving file from {source_path} to {dest_path}: {str(e)}")
            return {
                "success": False,
                "error": f"Error moving file: {str(e)}",
                "metadata": {}
            }
    
    def create_temp_file(
        self, 
        content: Union[str, Dict, List], 
        prefix: str = "temp_", 
        suffix: str = ".txt",
        encoding: str = "utf-8"
    ) -> Dict[str, Any]:
        """
        Create a temporary file with the given content.
        
        Args:
            content: Content to write to the file
            prefix: Prefix for the temporary file name
            suffix: Suffix for the temporary file name
            encoding: Encoding to use when writing the file
            
        Returns:
            Dictionary with file path and metadata
        """
        try:
            # Create temp directory if it doesn't exist
            temp_dir = os.path.join(self.base_dir, self.output_dir, "temp")
            os.makedirs(temp_dir, exist_ok=True)
            
            # Generate a unique file name
            timestamp = datetime.datetime.now().strftime("%Y%m%d%H%M%S")
            file_name = f"{prefix}{timestamp}{suffix}"
            file_path = os.path.join("temp", file_name)
            
            # Write the content to the file
            result = self.write_file(file_path, content, encoding=encoding)
            
            if result["success"]:
                logger.debug(f"Successfully created temporary file: {file_path}")
                result["path"] = file_path
                return result
            else:
                return result
            
        except Exception as e:
            logger.error(f"Error creating temporary file: {str(e)}")
            return {
                "success": False,
                "error": f"Error creating temporary file: {str(e)}",
                "metadata": {}
            }
    
    def _get_full_path(self, path: str) -> str:
        """
        Get the full absolute path from a relative path.
        
        Args:
            path: Relative path
            
        Returns:
            Absolute path
        """
        # Check if path starts with output directory
        if path.startswith("output/") or path.startswith("output\\"):
            # Path is relative to base directory
            return os.path.abspath(os.path.join(self.base_dir, path))
        
        # Check if path already starts with the base directory
        base_dir_abs = os.path.abspath(self.base_dir)
        if os.path.abspath(path).startswith(base_dir_abs):
            # Path is already relative to base directory
            return os.path.abspath(path)
        
        # Path is assumed to be relative to output directory
        return os.path.abspath(os.path.join(self.base_dir, self.output_dir, path))
    
    def _get_file_extension(self, file_path: str) -> str:
        """
        Get the file extension from a file path.
        
        Args:
            file_path: Path to the file
            
        Returns:
            File extension without the dot
        """
        return os.path.splitext(file_path)[1].lstrip(".").lower()
--------------------------------------------------------------------------------
        knowledge_retrieval_tool.py

Content of C:/AI PROJECT/My Langchain Crew 1\tools\knowledge_retrieval_tool.py:
"""
Knowledge Retrieval Tool Module

This module provides tools for retrieving information from the knowledge repository.
It enables agents to access shared knowledge, documentation, and previously stored
information to support their decision making and task execution.
"""

import logging
import os
from typing import Dict, Any, List, Optional, Union

from core.knowledge_repository import KnowledgeRepository

logger = logging.getLogger(__name__)

class KnowledgeRetrievalTool:
    """
    Tool for retrieving information from the knowledge repository.
    
    This tool provides methods to search for and retrieve relevant knowledge
    from the shared knowledge repository, supporting various types of queries
    and filtering options.
    """
    
    def __init__(self, config: Dict[str, Any], knowledge_repository: KnowledgeRepository):
        """
        Initialize the knowledge retrieval tool.
        
        Args:
            config: Configuration dictionary with retrieval settings
            knowledge_repository: The knowledge repository to retrieve from
        """
        self.config = config
        self.knowledge_repository = knowledge_repository
        self.max_results = config.get("max_results", 5)
        self.similarity_threshold = config.get("similarity_threshold", 0.7)
        
        logger.debug("Initialized KnowledgeRetrievalTool")
    
    def search_knowledge(
        self, 
        query: str, 
        max_results: Optional[int] = None, 
        filter_by_type: Optional[str] = None,
        filter_by_source: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """
        Search the knowledge repository for relevant information.
        
        Args:
            query: The search query
            max_results: Maximum number of results to return (overrides config)
            filter_by_type: Filter results by content type (e.g., "document", "execution_results")
            filter_by_source: Filter results by source (e.g., "web", "user", "agent")
            
        Returns:
            List of relevant knowledge items
        """
        max_results = max_results or self.max_results
        
        # Create filter metadata if needed
        filter_metadata = {}
        if filter_by_type:
            filter_metadata["type"] = filter_by_type
        if filter_by_source:
            filter_metadata["source"] = filter_by_source
        
        # Execute the search with the repository
        try:
            results = self.knowledge_repository.search_knowledge(
                query=query,
                k=max_results,
                filter_metadata=filter_metadata if filter_metadata else None
            )
            
            logger.debug(f"Knowledge search for '{query}' returned {len(results)} results")
            return results
            
        except Exception as e:
            logger.error(f"Error during knowledge search: {str(e)}")
            return [{
                "content": f"Error during knowledge search: {str(e)}",
                "metadata": {"type": "error", "source": "knowledge_retrieval_tool"}
            }]
    
    def get_relevant_knowledge(
        self, 
        task_description: str, 
        max_results: Optional[int] = None
    ) -> List[Dict[str, Any]]:
        """
        Get knowledge relevant to a specific task.
        
        Args:
            task_description: Description of the task
            max_results: Maximum number of results to return
            
        Returns:
            List of relevant knowledge items
        """
        max_results = max_results or self.max_results
        
        try:
            results = self.knowledge_repository.get_relevant_knowledge(
                task_description=task_description,
                k=max_results
            )
            
            logger.debug(f"Relevant knowledge search for task returned {len(results)} results")
            return results
            
        except Exception as e:
            logger.error(f"Error retrieving relevant knowledge: {str(e)}")
            return [{
                "content": f"Error retrieving relevant knowledge: {str(e)}",
                "metadata": {"type": "error", "source": "knowledge_retrieval_tool"}
            }]
    
    def get_agent_knowledge(
        self, 
        agent_role: str, 
        specialization: Optional[str] = None, 
        max_results: Optional[int] = None
    ) -> List[Dict[str, Any]]:
        """
        Get knowledge relevant to a specific agent role and specialization.
        
        Args:
            agent_role: The agent's role
            specialization: Optional specialization
            max_results: Maximum number of results to return
            
        Returns:
            List of relevant knowledge items
        """
        max_results = max_results or self.max_results
        
        try:
            results = self.knowledge_repository.get_agent_knowledge(
                agent_role=agent_role,
                specialization=specialization,
                k=max_results
            )
            
            logger.debug(f"Agent knowledge search for {agent_role} returned {len(results)} results")
            return results
            
        except Exception as e:
            logger.error(f"Error retrieving agent knowledge: {str(e)}")
            return [{
                "content": f"Error retrieving agent knowledge: {str(e)}",
                "metadata": {"type": "error", "source": "knowledge_retrieval_tool"}
            }]
    
    def retrieve_by_id(self, knowledge_id: str) -> Optional[Dict[str, Any]]:
        """
        Retrieve a specific knowledge item by its ID.
        
        Args:
            knowledge_id: The ID of the knowledge item to retrieve
            
        Returns:
            Knowledge item if found, None otherwise
        """
        try:
            # Check if this is a team composition ID
            if knowledge_id.startswith("task_"):
                result = self.knowledge_repository.get_team_composition(knowledge_id)
                if result:
                    return {
                        "content": str(result),
                        "metadata": {
                            "type": "team_composition",
                            "task_id": knowledge_id
                        }
                    }
            
            # Check if this is an execution results ID
            if knowledge_id.startswith("execution_"):
                result = self.knowledge_repository.get_execution_results(knowledge_id)
                if result:
                    return {
                        "content": str(result),
                        "metadata": {
                            "type": "execution_results",
                            "task_id": knowledge_id
                        }
                    }
            
            # Check if this is an external knowledge ID
            if knowledge_id.startswith("knowledge_"):
                result = self.knowledge_repository.get_external_knowledge(knowledge_id)
                if result:
                    return {
                        "content": result.get("content", ""),
                        "metadata": {
                            "type": "external_knowledge",
                            "knowledge_id": knowledge_id,
                            "source": result.get("source", "unknown")
                        }
                    }
            
            logger.warning(f"Knowledge item with ID {knowledge_id} not found")
            return None
            
        except Exception as e:
            logger.error(f"Error retrieving knowledge item by ID: {str(e)}")
            return {
                "content": f"Error retrieving knowledge item: {str(e)}",
                "metadata": {"type": "error", "source": "knowledge_retrieval_tool"}
            }
    
    def get_recent_tasks(self, limit: int = 10) -> List[Dict[str, Any]]:
        """
        Get a list of recent tasks.
        
        Args:
            limit: Maximum number of tasks to return
            
        Returns:
            List of recent tasks with descriptions and IDs
        """
        try:
            recent_tasks = self.knowledge_repository.list_recent_tasks(limit=limit)
            
            logger.debug(f"Retrieved {len(recent_tasks)} recent tasks")
            return recent_tasks
            
        except Exception as e:
            logger.error(f"Error retrieving recent tasks: {str(e)}")
            return [{
                "task_id": "error",
                "description": f"Error retrieving recent tasks: {str(e)}",
                "type": "error"
            }]
    
    def format_knowledge_for_context(
        self, 
        knowledge_items: List[Dict[str, Any]], 
        include_metadata: bool = False
    ) -> str:
        """
        Format knowledge items into a string suitable for inclusion in a context.
        
        Args:
            knowledge_items: List of knowledge items to format
            include_metadata: Whether to include metadata in the formatted result
            
        Returns:
            Formatted knowledge string
        """
        if not knowledge_items:
            return "No relevant knowledge found."
        
        formatted_parts = ["Here is relevant information that might help:"]
        
        for i, item in enumerate(knowledge_items, 1):
            content = item.get("content", "")
            metadata = item.get("metadata", {})
            source = metadata.get("source", "Unknown source")
            knowledge_type = metadata.get("type", "information")
            
            formatted_parts.append(f"\n--- Relevant Information {i} (from {source}) ---")
            formatted_parts.append(content)
            
            if include_metadata:
                meta_str = "\nMetadata: "
                meta_items = []
                for key, value in metadata.items():
                    if key not in ["source", "content"]:
                        meta_items.append(f"{key}: {value}")
                
                if meta_items:
                    formatted_parts.append(meta_str + ", ".join(meta_items))
        
        return "\n".join(formatted_parts)
    
    def add_knowledge_to_repository(
        self, 
        content: str, 
        source: str, 
        metadata: Optional[Dict[str, Any]] = None
    ) -> bool:
        """
        Add new knowledge to the repository.
        
        Args:
            content: The content to store
            source: Source of the knowledge (e.g., "web", "user", "agent")
            metadata: Additional metadata about the content
            
        Returns:
            True if successful, False otherwise
        """
        try:
            self.knowledge_repository.store_external_knowledge(
                source=source,
                content=content,
                metadata=metadata or {}
            )
            
            logger.debug(f"Added new knowledge from {source} to repository")
            return True
            
        except Exception as e:
            logger.error(f"Error adding knowledge to repository: {str(e)}")
            return False

    def combine_knowledge(
        self, 
        knowledge_items: List[Dict[str, Any]], 
        query: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Combine knowledge from multiple items.
        
        Args:
            knowledge_items: List of knowledge items to combine
            query: Optional context for the combination
            
        Returns:
            Combined knowledge
        """
        if not knowledge_items:
            return {
                "content": "No knowledge items to combine.",
                "metadata": {"type": "combined", "item_count": 0}
            }
        
        # Simply concatenate the contents for now
        # In a more advanced implementation, this could use an LLM to synthesize information
        combined_content = []
        sources = set()
        types = set()
        
        for item in knowledge_items:
            content = item.get("content", "")
            metadata = item.get("metadata", {})
            source = metadata.get("source", "Unknown")
            item_type = metadata.get("type", "information")
            
            combined_content.append(f"From {source}:")
            combined_content.append(content)
            
            sources.add(source)
            types.add(item_type)
        
        combined_metadata = {
            "type": "combined",
            "item_count": len(knowledge_items),
            "sources": list(sources),
            "content_types": list(types)
        }
        
        # Add query context if provided
        if query:
            combined_content.insert(0, f"Combined knowledge related to: {query}")
            combined_metadata["query"] = query
        
        return {
            "content": "\n\n".join(combined_content),
            "metadata": combined_metadata
        }
--------------------------------------------------------------------------------
        web_search.py

Content of C:/AI PROJECT/My Langchain Crew 1\tools\web_search.py:
"""
Web Search Tool Module

This module provides tools for searching the web, retrieving, and processing web content.
It integrates with search providers and offers web scraping capabilities to fetch
and extract information from websites.
"""

import os
import logging
import json
import time
from typing import Dict, Any, List, Optional, Union
import urllib.parse
import re
import html

import requests
from bs4 import BeautifulSoup

# Optional import for Tavily API if available
try:
    from tavily import TavilyClient
    TAVILY_AVAILABLE = True
except ImportError:
    TAVILY_AVAILABLE = False

logger = logging.getLogger(__name__)

class WebSearchTool:
    """
    Tool for searching the web and retrieving relevant information.
    
    This tool integrates with search providers like Tavily or falls back to
    a basic web search implementation when specialized APIs aren't available.
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        Initialize the web search tool.
        
        Args:
            config: Configuration dictionary with search tool settings
        """
        self.config = config
        self.search_provider = config.get("search_provider", "tavily")
        self.max_results = config.get("max_results", 5)
        self.search_timeout = config.get("search_timeout", 30)
        self.enable_scraping = config.get("enable_scraping", True)
        self.user_agent = config.get("user_agent", "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36")
        
        # Initialize search providers
        self._initialize_search_providers()
        
        logger.debug(f"Initialized WebSearchTool with provider: {self.search_provider}")
    
    def _initialize_search_providers(self):
        """Initialize the configured search providers."""
        # Initialize Tavily if available and configured
        self.tavily_client = None
        if self.search_provider == "tavily":
            if TAVILY_AVAILABLE:
                api_key = self.config.get("tavily_api_key") or os.getenv("TAVILY_API_KEY")
                if api_key:
                    try:
                        self.tavily_client = TavilyClient(api_key=api_key)
                        logger.info("Initialized Tavily search client")
                    except Exception as e:
                        logger.error(f"Error initializing Tavily client: {str(e)}")
                        self.search_provider = "basic"
                else:
                    logger.warning("Tavily API key not found, falling back to basic search")
                    self.search_provider = "basic"
            else:
                logger.warning("Tavily package not available, falling back to basic search")
                self.search_provider = "basic"
    
    def search(self, query: str, max_results: int = None, **kwargs) -> List[Dict[str, Any]]:
        """
        Search the web for the given query.
        
        Args:
            query: The search query
            max_results: Maximum number of results to return (overrides config)
            **kwargs: Additional search parameters
            
        Returns:
            List of search results with URL, title, and snippet
        """
        max_results = max_results or self.max_results
        
        # Log the search
        logger.info(f"Searching for: {query} (provider: {self.search_provider})")
        
        try:
            # Use the appropriate search provider
            if self.search_provider == "tavily" and self.tavily_client:
                return self._search_tavily(query, max_results, **kwargs)
            else:
                return self._search_basic(query, max_results, **kwargs)
                
        except Exception as e:
            logger.error(f"Error during web search: {str(e)}")
            return [{
                "url": "",
                "title": "Error during search",
                "content": f"An error occurred: {str(e)}",
                "source": "error"
            }]
    
    def _search_tavily(self, query: str, max_results: int, **kwargs) -> List[Dict[str, Any]]:
        """
        Search using the Tavily API.
        
        Args:
            query: The search query
            max_results: Maximum number of results to return
            **kwargs: Additional Tavily-specific parameters
            
        Returns:
            List of search results
        """
        include_answer = kwargs.get("include_answer", True)
        search_depth = kwargs.get("search_depth", "basic")
        
        try:
            # Execute the search
            search_result = self.tavily_client.search(
                query=query, 
                search_depth=search_depth,
                max_results=max_results,
                include_answer=include_answer
            )
            
            # Extract the results
            results = []
            
            # Add the Tavily-generated answer if available
            if include_answer and "answer" in search_result and search_result["answer"]:
                results.append({
                    "url": "",
                    "title": "AI-Generated Answer",
                    "content": search_result["answer"],
                    "source": "tavily_answer"
                })
            
            # Add the individual search results
            for result in search_result.get("results", []):
                results.append({
                    "url": result.get("url", ""),
                    "title": result.get("title", ""),
                    "content": result.get("content", ""),
                    "source": "tavily"
                })
            
            return results
            
        except Exception as e:
            logger.error(f"Error with Tavily search: {str(e)}")
            # Fall back to basic search
            logger.info("Falling back to basic search")
            return self._search_basic(query, max_results, **kwargs)
    
    def _search_basic(self, query: str, max_results: int, **kwargs) -> List[Dict[str, Any]]:
        """
        Basic web search implementation using a public search API or direct requests.
        
        Args:
            query: The search query
            max_results: Maximum number of results to return
            **kwargs: Additional parameters
            
        Returns:
            List of search results
        """
        # This is a placeholder for a basic search implementation
        # In a production environment, you would integrate with a public search API
        
        # Encode the query for URL
        encoded_query = urllib.parse.quote(query)
        
        # We'll use a publicly accessible search service for demonstration
        # Note: This is not a reliable or production-ready approach
        search_url = f"https://html.duckduckgo.com/html/?q={encoded_query}"
        
        try:
            # Send the request
            headers = {"User-Agent": self.user_agent}
            response = requests.get(search_url, headers=headers, timeout=self.search_timeout)
            response.raise_for_status()
            
            # Parse the response
            soup = BeautifulSoup(response.text, "html.parser")
            
            # Extract search results
            results = []
            result_elements = soup.select(".result")[:max_results]
            
            for element in result_elements:
                title_elem = element.select_one(".result__title")
                link_elem = element.select_one(".result__url")
                snippet_elem = element.select_one(".result__snippet")
                
                title = title_elem.get_text().strip() if title_elem else "No title"
                url = link_elem.get_text().strip() if link_elem else ""
                snippet = snippet_elem.get_text().strip() if snippet_elem else "No snippet available"
                
                # Clean up the URL
                if url and not url.startswith(("http://", "https://")):
                    url = "https://" + url
                
                results.append({
                    "url": url,
                    "title": title,
                    "content": snippet,
                    "source": "basic_search"
                })
            
            return results
            
        except Exception as e:
            logger.error(f"Error with basic search: {str(e)}")
            # Return an empty result with the error
            return [{
                "url": "",
                "title": "Search failed",
                "content": f"The search failed with error: {str(e)}",
                "source": "error"
            }]
    
    def get_webpage_content(self, url: str, extract_main_content: bool = True) -> Dict[str, Any]:
        """
        Retrieve and extract content from a webpage.
        
        Args:
            url: The URL of the webpage to retrieve
            extract_main_content: Whether to extract just the main content (vs. entire HTML)
            
        Returns:
            Dictionary with URL, title, and content
        """
        if not url or not url.startswith(("http://", "https://")):
            return {
                "url": url,
                "title": "Invalid URL",
                "content": "The provided URL is invalid or empty.",
                "success": False
            }
        
        try:
            # Send the request
            headers = {"User-Agent": self.user_agent}
            response = requests.get(url, headers=headers, timeout=self.search_timeout)
            response.raise_for_status()
            
            # Parse the response
            soup = BeautifulSoup(response.text, "html.parser")
            
            # Extract title
            title = soup.title.get_text() if soup.title else "No title"
            
            if extract_main_content:
                # Extract the main content
                # This is a simplified approach and may not work for all websites
                # A production implementation would use more sophisticated content extraction
                
                # Remove script and style elements
                for script in soup(["script", "style", "nav", "footer", "header", "aside"]):
                    script.extract()
                
                # Find the main content
                main_content = None
                
                # Try common content containers
                for container in ["main", "article", "div[role='main']", "#content", ".content", "#main", ".main"]:
                    content_elem = soup.select_one(container)
                    if content_elem and len(content_elem.get_text(strip=True)) > 200:
                        main_content = content_elem
                        break
                
                # If no main content found, use the body
                if not main_content:
                    main_content = soup.body
                
                # Extract text content
                if main_content:
                    paragraphs = main_content.find_all(["p", "h1", "h2", "h3", "h4", "h5", "h6", "li"])
                    content = "\n".join([p.get_text().strip() for p in paragraphs])
                else:
                    # Fallback to raw text from body
                    content = soup.body.get_text(separator="\n", strip=True)
            else:
                # Use the entire HTML
                content = str(soup)
            
            # Clean up the content
            content = re.sub(r'\s+', ' ', content).strip()
            content = html.unescape(content)
            
            return {
                "url": url,
                "title": title,
                "content": content,
                "success": True
            }
            
        except Exception as e:
            logger.error(f"Error retrieving webpage content from {url}: {str(e)}")
            return {
                "url": url,
                "title": "Error retrieving content",
                "content": f"An error occurred: {str(e)}",
                "success": False
            }
    
    def search_and_summarize(
        self, 
        query: str, 
        max_results: int = None,
        summarize_results: bool = True,
        fetch_full_content: bool = False
    ) -> Dict[str, Any]:
        """
        Search the web and optionally summarize the results.
        
        Args:
            query: The search query
            max_results: Maximum number of results to return
            summarize_results: Whether to summarize the results
            fetch_full_content: Whether to fetch full content for each result
            
        Returns:
            Dictionary with search results and optionally a summary
        """
        # Perform the search
        search_results = self.search(query, max_results)
        
        # Fetch full content if requested
        if fetch_full_content and self.enable_scraping:
            for i, result in enumerate(search_results):
                if result.get("url") and result["source"] != "error" and result["source"] != "tavily_answer":
                    page_content = self.get_webpage_content(result["url"])
                    if page_content["success"]:
                        search_results[i]["content"] = page_content["content"]
        
        response = {
            "query": query,
            "results": search_results,
            "timestamp": time.time()
        }
        
        # No built-in summarization in this simplified version
        if summarize_results:
            response["summary"] = "Summarization capability requires integration with an LLM."
        
        return response
--------------------------------------------------------------------------------
        __init__.py

Content of C:/AI PROJECT/My Langchain Crew 1\tools\__init__.py:
"""
Tools package.
"""
--------------------------------------------------------------------------------
    utils/
        config.py

Content of C:/AI PROJECT/My Langchain Crew 1\utils\config.py:
"""
Configuration Module

This module handles configuration loading, validation, and access throughout the
system. It supports loading from YAML files, environment variables, and provides
default values for missing configurations.
"""

import os
import logging
import yaml
from typing import Dict, Any, Optional, List, Union
import json

logger = logging.getLogger(__name__)

class Config:
    """
    Configuration manager for the system.
    
    Handles loading configuration from various sources, provides access
    to configuration values, and validates configuration settings.
    """
    
    def __init__(self, config_path: Optional[str] = None):
        """
        Initialize the configuration manager.
        
        Args:
            config_path: Optional path to a YAML configuration file
        """
        self.config_data = {}
        self.config_path = config_path
        
        # Load default configuration
        self._load_defaults()
        
        # Load from config file if specified
        if config_path:
            self._load_from_file(config_path)
        
        # Override with environment variables
        self._load_from_env()
        
        # Validate the configuration
        self._validate_config()
        
        logger.debug(f"Configuration initialized. Path: {config_path if config_path else 'default'}")
    
    def _load_defaults(self):
        """Load default configuration values."""
        self.config_data = {
            # General settings
            "general": {
                "data_dir": "data",
                "output_dir": "output",
                "log_level": "INFO",
                "verbose": False
            },
            
            # LLM settings
            "llm": {
                "default_model": "gpt-4o",
                "research_model": "gpt-4o",
                "planning_model": "gpt-4o",
                "coordination_model": "gpt-4o",
                "specialist_model": "gpt-4o",
                "execution_model": "gpt-3.5-turbo",
                "review_model": "gpt-4o",
                "default_temperature": 0.2,
                "api_request_timeout": 30
            },
            
            # Agent settings
            "agent_factory": {
                "default_model": "gpt-4o",
                "max_iterations": 10,
                "verbose": True
            },
            
            # Team manager settings
            "team_manager": {
                "analysis_model": "gpt-4o",
                "agent_factory": {
                    "default_model": "gpt-4o"
                }
            },
            
            # Agent coordinator settings
            "agent_coordinator": {
                "coordination_model": "gpt-4o",
                "max_coordination_retries": 3,
                "task_scheduler": {
                    "max_parallel_tasks": 3,
                    "prioritize_by_complexity": True
                }
            },
            
            # Knowledge repository settings
            "knowledge_repository": {
                "data_dir": "data",
                "embedding_model": "text-embedding-3-small",
                "chunk_size": 1000,
                "chunk_overlap": 100
            },
            
            # Task scheduler settings
            "task_scheduler": {
                "max_parallel_tasks": 3,
                "prioritize_by_complexity": True
            },
            
            # Agents settings
            "agents": {
                "base_agent": {
                    "max_retries": 3,
                    "retry_delay": 2,
                    "max_history": 10
                },
                "research_agent": {
                    "auto_save_results": True,
                    "max_search_results": 5,
                    "include_sources": True
                },
                "specialist_agent": {
                    "domain_knowledge": {},
                    "best_practices": []
                },
                "planner_agent": {
                    "planning_depth": "medium",
                    "include_contingencies": True
                },
                "executor_agent": {
                    "execution_timeout": 120,
                    "validate_results": True
                },
                "reviewer_agent": {
                    "review_criteria": [
                        "correctness",
                        "completeness",
                        "efficiency",
                        "maintainability"
                    ]
                }
            },
            
            # Tools settings
            "tools": {
                "web_search": {
                    "search_provider": "tavily",
                    "max_results": 5
                },
                "code_generation": {
                    "language_support": [
                        "python",
                        "javascript",
                        "java",
                        "csharp",
                        "apex"
                    ]
                },
                "knowledge_retrieval": {
                    "max_results": 5,
                    "similarity_threshold": 0.7
                }
            }
        }
    
    def _load_from_file(self, config_path: str):
        """
        Load configuration from a YAML file.
        
        Args:
            config_path: Path to the YAML configuration file
        """
        try:
            if os.path.exists(config_path):
                with open(config_path, 'r') as f:
                    file_config = yaml.safe_load(f)
                    
                    if file_config:
                        # Recursively update the config with values from the file
                        self._update_nested_dict(self.config_data, file_config)
                        logger.info(f"Loaded configuration from {config_path}")
            else:
                logger.warning(f"Configuration file not found: {config_path}")
        except Exception as e:
            logger.error(f"Error loading configuration from file: {str(e)}")
    
    def _load_from_env(self):
        """Load configuration from environment variables."""
        try:
            # Look for environment variables with the prefix TEAM_AGENTS_
            prefix = "TEAM_AGENTS_"
            for key, value in os.environ.items():
                if key.startswith(prefix):
                    # Remove the prefix and convert to lowercase
                    config_key = key[len(prefix):].lower()
                    
                    # Split by double underscore to represent nested keys
                    path = config_key.split("__")
                    
                    # Try to parse as JSON for complex values
                    try:
                        parsed_value = json.loads(value)
                    except json.JSONDecodeError:
                        parsed_value = value
                    
                    # Update the config at the specified path
                    self._set_nested_value(self.config_data, path, parsed_value)
                    
                    logger.debug(f"Loaded configuration from environment: {key}")
            
        except Exception as e:
            logger.error(f"Error loading configuration from environment: {str(e)}")
    
    def _update_nested_dict(self, d: Dict[str, Any], u: Dict[str, Any]):
        """
        Recursively update a nested dictionary.
        
        Args:
            d: Dictionary to update
            u: Dictionary with updates
        """
        for k, v in u.items():
            if isinstance(v, dict) and k in d and isinstance(d[k], dict):
                self._update_nested_dict(d[k], v)
            else:
                d[k] = v
    
    def _set_nested_value(self, d: Dict[str, Any], path: List[str], value: Any):
        """
        Set a value in a nested dictionary given a path.
        
        Args:
            d: Dictionary to update
            path: List of keys forming the path
            value: Value to set
        """
        if len(path) == 1:
            d[path[0]] = value
            return
            
        if path[0] not in d:
            d[path[0]] = {}
        elif not isinstance(d[path[0]], dict):
            d[path[0]] = {}
            
        self._set_nested_value(d[path[0]], path[1:], value)
    
    def _validate_config(self):
        """Validate the configuration and ensure required values are present."""
        # Check for required LLM models
        if not self.get("llm.default_model"):
            logger.warning("No default LLM model specified, using gpt-4o")
            self._set_nested_value(self.config_data, ["llm", "default_model"], "gpt-4o")
        
        # Check for data directory
        data_dir = self.get("general.data_dir")
        if not data_dir:
            data_dir = "data"
            self._set_nested_value(self.config_data, ["general", "data_dir"], data_dir)
        
        # Create data directory if it doesn't exist
        if not os.path.exists(data_dir):
            try:
                os.makedirs(data_dir, exist_ok=True)
                logger.info(f"Created data directory: {data_dir}")
            except Exception as e:
                logger.error(f"Failed to create data directory: {str(e)}")
    
    def get(self, key_path: str, default: Any = None) -> Any:
        """
        Get a configuration value by its key path.
        
        Args:
            key_path: Dot-separated path to the configuration value
            default: Default value to return if key not found
            
        Returns:
            The configuration value or default if not found
        """
        path = key_path.split('.')
        value = self.config_data
        
        try:
            for key in path:
                value = value[key]
            return value
        except (KeyError, TypeError):
            return default
    
    def set(self, key_path: str, value: Any):
        """
        Set a configuration value by its key path.
        
        Args:
            key_path: Dot-separated path to the configuration value
            value: Value to set
        """
        path = key_path.split('.')
        self._set_nested_value(self.config_data, path, value)
    
    def save(self, file_path: Optional[str] = None):
        """
        Save the configuration to a YAML file.
        
        Args:
            file_path: Path to save the configuration to (defaults to original path)
        """
        save_path = file_path or self.config_path
        
        if not save_path:
            logger.warning("No file path specified for saving configuration")
            return
            
        try:
            with open(save_path, 'w') as f:
                yaml.dump(self.config_data, f, default_flow_style=False)
                
            logger.info(f"Configuration saved to {save_path}")
        except Exception as e:
            logger.error(f"Error saving configuration to file: {str(e)}")
    
    def to_dict(self) -> Dict[str, Any]:
        """
        Get the entire configuration as a dictionary.
        
        Returns:
            The configuration dictionary
        """
        return self.config_data.copy()
    
    def __str__(self) -> str:
        """String representation of the configuration."""
        return yaml.dump(self.config_data, default_flow_style=False)


def load_config(config_path: Optional[str] = None) -> Config:
    """
    Load configuration from the specified path or default locations.
    
    Args:
        config_path: Optional explicit path to configuration file
        
    Returns:
        Config instance
    """
    # If no path specified, try standard locations
    if not config_path:
        potential_paths = [
            "config.yaml",
            "config.yml",
            os.path.join("config", "config.yaml"),
            os.path.expanduser("~/.team_agents/config.yaml")
        ]
        
        for path in potential_paths:
            if os.path.exists(path):
                config_path = path
                break
    
    # Load the configuration
    return Config(config_path)
--------------------------------------------------------------------------------
        logging_utils.py

Content of C:/AI PROJECT/My Langchain Crew 1\utils\logging_utils.py:
"""
Logging Utilities Module

This module provides logging configuration and utilities for the entire application.
"""

import logging
import os
import sys
from typing import Optional

def setup_logging(log_level: int = logging.INFO, log_file: Optional[str] = None):
    """
    Setup logging configuration.
    
    Args:
        log_level: The logging level to use
        log_file: Optional file path to write logs to
    """
    # Create formatter
    formatter = logging.Formatter(
        "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    )
    
    # Setup console handler
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(formatter)
    
    # Setup root logger
    root_logger = logging.getLogger()
    root_logger.setLevel(log_level)
    root_logger.addHandler(console_handler)
    
    # Add file handler if specified
    if log_file:
        os.makedirs(os.path.dirname(log_file), exist_ok=True)
        file_handler = logging.FileHandler(log_file)
        file_handler.setFormatter(formatter)
        root_logger.addHandler(file_handler)
    
    # Set third-party loggers to WARNING level to reduce noise
    logging.getLogger("httpx").setLevel(logging.WARNING)
    logging.getLogger("httpcore").setLevel(logging.WARNING)
    logging.getLogger("openai").setLevel(logging.WARNING)
--------------------------------------------------------------------------------
        prompt_templates.py

Content of C:/AI PROJECT/My Langchain Crew 1\utils\prompt_templates.py:
"""
Prompt Templates Module

This module contains standardized prompt templates for various agent roles and functions.
These templates provide consistent prompting patterns for the language models
while allowing for customization based on specific needs.
"""

# Team composition and analysis prompt
TEAM_COMPOSITION_PROMPT = """
You are an expert AI system designer tasked with creating the optimal team of AI agents for a specific task. 
Your job is to analyze the task requirements and determine the most effective team composition.

Task Description:
{task_description}

Please determine the most effective team of AI agents to complete this task. 
Consider the following:
1. The primary skills and expertise required
2. The specific roles needed in the team
3. The optimal number of agents
4. Any specialized knowledge required

For each agent, specify:
- Role (research, specialist, planner, executor, reviewer)
- Specialization domain
- Importance level (1-10, with 10 being most essential)
- Brief description of responsibilities
- Required skills

Format your response as a valid JSON object with the following structure:
{{
  "team_name": "A descriptive name for the team",
  "team_goal": "The primary goal of this team",
  "required_agents": [
    {{
      "role": "role_name",
      "specialization": "domain_specific_expertise",
      "importance": integer_value,
      "description": "Brief description of this agent's responsibilities",
      "required_skills": ["skill1", "skill2", ...]
    }},
    // More agents as needed
  ],
  "additional_context": "Any additional context or considerations"
}}

{format_instructions}
"""

# Task breakdown prompt
TASK_BREAKDOWN_PROMPT = """
You are a professional task planning system that breaks down complex tasks into manageable subtasks.

Task Description:
{task_description}

Your job is to decompose this task into a series of subtasks that can be assigned to our team of AI agents.
Each subtask should be clear, focused, and accomplishable by a single agent.

Available Agents:
{available_agents}

For each subtask, provide:
1. A clear description
2. The agent it should be assigned to (from the list above)
3. The complexity level (low, medium, high)
4. Dependencies on other subtasks (if any)

Format your response as a JSON array of subtask objects:
[
  {{
    "id": "subtask_1",
    "description": "Description of the first subtask",
    "assigned_agent": "agent_id",
    "complexity": "medium",
    "dependencies": []
  }},
  {{
    "id": "subtask_2",
    "description": "Description of the second subtask",
    "assigned_agent": "agent_id",
    "complexity": "high",
    "dependencies": ["subtask_1"]
  }},
  // More subtasks as needed
]

Ensure that the task breakdown:
- Covers all aspects of the main task
- Respects logical dependencies between subtasks
- Distributes work evenly among available agents
- Specifies clear success criteria for each subtask
"""

# Result synthesis prompt
RESULT_SYNTHESIS_PROMPT = """
You are an expert synthesis system responsible for combining and summarizing the results of multiple AI agents working on a task.

Original Task:
{task_description}

Below are the execution results from each agent. Your job is to synthesize these into a coherent, comprehensive response.

Execution Results:
{execution_results}

Please create:
1. A comprehensive summary of the work completed
2. The key findings or outputs from the various agents
3. A final, consolidated result that addresses the original task effectively

Your synthesis should be well-structured, eliminate redundancies, resolve any contradictions between agents, and present a unified solution. Focus on clarity and completeness.
"""

# Coordination prompt
COORDINATION_PROMPT = """
You are an AI coordination system responsible for managing the collaboration between multiple specialized agents.

Your job is to:
1. Ensure clear communication between agents
2. Resolve any conflicts or contradictions in their outputs
3. Keep the agents focused on the main task
4. Identify when additional information or clarification is needed

When coordinating:
- Maintain a neutral perspective
- Focus on extracting the most valuable insights from each agent
- Facilitate productive collaboration
- Ensure the team makes progress toward the goal

Please coordinate effectively to achieve the optimal outcome for the given task.
"""

# Research agent prompt
RESEARCH_AGENT_PROMPT = """
You are a Research Agent with exceptional information gathering and synthesis abilities. Your primary responsibility is to find, analyze, and summarize information relevant to the task at hand.

As a Research Agent, you should:
1. Gather comprehensive information about the topic or question
2. Evaluate sources for credibility and relevance
3. Synthesize information into clear, concise summaries
4. Identify key insights, patterns, and facts
5. Present information in a structured, easily digestible format
6. Highlight areas where additional research may be needed

When conducting research:
- Be thorough and comprehensive
- Consider multiple perspectives and sources
- Distinguish between facts and opinions
- Prioritize recent and authoritative information when available
- Acknowledge limitations in available information

Use the available tools to search for information, and provide well-organized responses with proper citations where applicable.
"""

# Specialist agent prompt
def get_specialist_agent_prompt(specialization):
    """Get a prompt template customized for a specific specialization."""
    
    # Base prompt for all specialists
    base_prompt = """
    You are a Specialist Agent with deep expertise in {specialization}. Your primary responsibility is to apply your specialized knowledge to solve problems within your domain.

    As a {specialization} Specialist, you should:
    1. Apply domain-specific knowledge and best practices
    2. Provide expert analysis and recommendations
    3. Answer technical questions with precision and clarity
    4. Identify potential issues or challenges
    5. Suggest optimal solutions based on current industry standards
    
    When addressing tasks in your domain:
    - Be precise and technical when appropriate
    - Explain complex concepts clearly
    - Consider practical implementation details
    - Adhere to best practices and standards in {specialization}
    - Acknowledge limitations in your approach
    
    Use your specialized knowledge to provide high-quality, implementable solutions.
    """
    
    # Specialization-specific additions
    specialization_additions = {
        "salesforce_admin": """
        Additional guidance for Salesforce Administration:
        - Focus on Salesforce platform configuration, user management, and security
        - Provide solutions using declarative tools (workflows, process builder, flows) when possible
        - Consider scalability and maintainability of solutions
        - Recommend appropriate Salesforce features and limitations
        - Follow Salesforce best practices for administration and configuration
        """,
        
        "salesforce_developer": """
        Additional guidance for Salesforce Development:
        - Write clean, efficient Apex code following best practices
        - Design Lightning components and pages with user experience in mind
        - Implement appropriate testing and error handling
        - Consider governor limits and performance implications
        - Recommend appropriate Salesforce APIs and integration patterns
        - Follow Salesforce development standards and security practices
        """,
        
        "salesforce_integration": """
        Additional guidance for Salesforce Integration:
        - Design robust integration patterns between Salesforce and external systems
        - Consider authentication, data synchronization, and error handling
        - Recommend appropriate APIs (REST, SOAP, Bulk, Streaming) for each use case
        - Implement solutions with scalability and performance in mind
        - Address security considerations for integrated systems
        - Optimize for transaction volume and data size
        """,
        
        "web_developer": """
        Additional guidance for Web Development:
        - Write clean, efficient, and maintainable code
        - Consider browser compatibility and responsive design
        - Implement appropriate security measures
        - Optimize for performance and accessibility
        - Follow current web development standards and best practices
        - Consider both frontend and backend aspects of web solutions
        """,
        
        "data_scientist": """
        Additional guidance for Data Science:
        - Apply appropriate statistical methods and machine learning algorithms
        - Clean and preprocess data effectively
        - Create clear visualizations that communicate insights
        - Evaluate model performance with appropriate metrics
        - Consider practical implementation and ethical implications
        - Explain technical concepts in an accessible manner
        """,
        
        "cybersecurity": """
        Additional guidance for Cybersecurity:
        - Identify potential security vulnerabilities and threats
        - Recommend robust security controls and mitigations
        - Consider defense in depth and principle of least privilege
        - Address both technical and procedural security measures
        - Stay aligned with current security standards and best practices
        - Balance security requirements with usability considerations
        """
    }
    
    # Get specialization-specific additions or use a generic addition
    addition = specialization_additions.get(specialization.lower(), """
    Apply your specialized knowledge in {specialization} to provide expert solutions and recommendations.
    Consider industry best practices, current standards, and practical implementation details.
    """)
    
    # Combine base prompt with specialization-specific additions
    return base_prompt.format(specialization=specialization) + addition.format(specialization=specialization)

# Planner agent prompt
PLANNER_AGENT_PROMPT = """
You are a Planner Agent with exceptional strategic thinking and organizational abilities. Your primary responsibility is to create structured plans for completing complex tasks.

As a Planner Agent, you should:
1. Analyze tasks to understand requirements and constraints
2. Break down complex tasks into manageable steps
3. Identify dependencies between different steps
4. Estimate complexity and resource requirements
5. Create clear, sequential plans with specific action items
6. Anticipate potential challenges and include contingencies

When creating plans:
- Be comprehensive and thorough
- Ensure logical sequencing of steps
- Consider resource constraints and dependencies
- Provide clear success criteria for each step
- Balance detail with readability
- Create plans that are adaptable to changing circumstances

Your plans should be clear, actionable, and effective at guiding task completion.
"""

# Executor agent prompt
EXECUTOR_AGENT_PROMPT = """
You are an Executor Agent with exceptional implementation and problem-solving abilities. Your primary responsibility is to carry out specific tasks and implement solutions.

As an Executor Agent, you should:
1. Implement solutions based on specifications and requirements
2. Write high-quality code when needed
3. Execute tasks with precision and attention to detail
4. Troubleshoot and resolve issues that arise during implementation
5. Optimize solutions for efficiency and effectiveness
6. Document your work clearly for others to understand

When executing tasks:
- Follow specifications and requirements closely
- Implement practical, working solutions
- Test your work thoroughly
- Consider edge cases and handle errors appropriately
- Comment and document your implementations
- Focus on delivering functional results

Use your technical skills to implement effective solutions to the problems at hand.
"""

# Reviewer agent prompt
REVIEWER_AGENT_PROMPT = """
You are a Reviewer Agent with exceptional analytical and quality assessment abilities. Your primary responsibility is to evaluate, critique, and improve the work of others.

As a Reviewer Agent, you should:
1. Thoroughly examine work products for quality and correctness
2. Identify errors, inconsistencies, or areas for improvement
3. Provide constructive feedback with specific recommendations
4. Ensure adherence to requirements and standards
5. Suggest optimizations and enhancements
6. Verify that solutions effectively address the original problem

When reviewing:
- Be thorough and meticulous
- Provide specific, actionable feedback
- Balance criticism with positive reinforcement
- Consider both technical correctness and usability
- Maintain high standards while being realistic
- Prioritize issues by importance

Your reviews should help improve quality while being constructive and respectful.
"""

# Dictionary of role-specific prompts
ROLE_PROMPTS = {
    "research": RESEARCH_AGENT_PROMPT,
    "planner": PLANNER_AGENT_PROMPT,
    "executor": EXECUTOR_AGENT_PROMPT,
    "reviewer": REVIEWER_AGENT_PROMPT
}

def get_prompt_template_for_role(role: str) -> str:
    """
    Get the appropriate prompt template for a specific role.
    
    Args:
        role: The role identifier, which may include specialization (e.g., 'specialist_salesforce')
        
    Returns:
        Prompt template string
    """
    # Split role into base role and specialization if present
    parts = role.split('_', 1)
    base_role = parts[0].lower()
    
    # If this is a specialist role and has a specialization
    if base_role == "specialist" and len(parts) > 1:
        specialization = parts[1]
        return get_specialist_agent_prompt(specialization)
    
    # Otherwise, get the template for the base role
    return ROLE_PROMPTS.get(base_role, RESEARCH_AGENT_PROMPT)
--------------------------------------------------------------------------------
        __init__.py

Content of C:/AI PROJECT/My Langchain Crew 1\utils\__init__.py:
"""
Utils package.
"""
--------------------------------------------------------------------------------
